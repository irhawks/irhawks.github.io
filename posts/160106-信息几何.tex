---
title : 信息几何简介
date  : 2016-01-06
tags  : 信息几何, 统计, 微分流形
---

\subsection{认识信息几何}

信息几何的方法其实是将统计理论中的参数问题变成额外的一个空间，在这个空间上建立统计函数之间的距离，相当于仍然是使用测度的理论研究问题。这种方法自然对于参数的生成有重要的启示。启示我们为什么要选择这样的参数，这什么参数有这些形态。在扩大的空间当中，自然而然地可以非常方便地研究统计系统的重多的要素。在机器学习中也有更多的应用。

然而单纯起来看，并非信息是几何的，而是因为分布函数之间的距离就是可以度量的。这样的话，未必形成微分流形，甚至是更一般的内容也可以，比如离散分布与离散参数的问题。总而言之，关键在于考察“所有可能的参数所形成的空间”，而不是“某个参数下的分布”所起的作用吧。

信息几何有几种经典的方法。第一是基于流形上的Riemann度量的方法，第二种是基于$\alpha$联络与对偶几何的方法。还可以是基于曲率度量的方法，或者基于信息散度(divergence)的方法。散度在信息什么几何中充当距离函数，用来度量两个点之间的分离度或者差异，但散度不是严格意义上的距离函数。

信息几何的数学形式可以按照如下的思路构造。首先，给出参数分布族$p(x,\theta)$，其中$\theta \in \Theta$是参数，$x$是样本空间$X$中的随机变量，$p(x;\theta)$是$x$的概率密度函数。$\theta$是一个$n$维向量而$\Theta$是$\RR^n$的开集，$\theta$可以看成是流形$S$上面的坐标系，每点关联一个概率密度函数。然后定义　
\[ g_{ij} = E[\partial_i \log p(x;\theta) \partial_j \log p(x;\theta)],
i,j=1,2,\cdots,n \]
其中$E$表示概率密度$p(x;\theta)$的期望，$\partial_i = \frac{\partial}{\partial \theta_i}$。用Fisher信息矩阵$g_{ij}$表示黎曼度量。然后定义流形$S$上的一族联络$\Delta^{(\alpha)}$，称之为$\alpha$-联络，定义为：
\[ \langle \Delta_A^{(\alpha)}B, C \rangle = E[(ABl)(Cl)] + 
    \frac{1-\alpha}{2} E[(Al)(Bl)(Cl)],
\]
其中$A$，$B$，$C$为流形$S$的三个向量场，$ABl=A(Bl)$，$l=l(x;\theta)=\log p(x;\theta)$，$\alpha$为实参数。$\alpha$-联络相比于黎曼联络有更广泛的适用条件。不过$\alpha$-联络不满足度量性。

在统计推断中，指数分布族占有极其重要的地位。从流形的观点看，指数分布族具有对偶平坦的何结构。特别地，正态分布族的函数的流形的高斯曲率是$-1/2$，因此是一个双曲面。

在信息几何中，两个非常重要的概念是散度和投量。信息几何在神经网络学习、热力学的流形、以及控制系统、Birkhoff系统、都有应用。


\subsection{信息几何与统计学派}

典型的信息几何是针对于参数分布族的。而统计推断的两大学派（频率学派与贝叶斯学派）的统计推断都常都是针对特定的参数的。信息几何只依赖于参数分布族的特点，使得信息几何不会受到两个学派关于概率的哲学本质的争论的问题。两种学派在具体怎样推断参数上面有一些区别。

经典统计只利用总体与样本的信息，而Bayesian统计还利用先验信息（集中在参数$\theta$的先验分布上）。经典学派的观点上，概率是大量独立重复实验下事件发生频率的稳定值，离开重复实验，概率就无从谈起。但是贝叶斯学派认为在无重复实验的条件下概率可以凭主观认识及以经验确定。

注：不过，度量不确定性有几种不同的方式，可以是概率，也可以是模糊。这样的话，关于不确定性的信息处理其实就有许多个不同的哲学出发点。

我们来看数学上的不同。在参数统计模型中通常含有未知参数$\theta \in \Theta$，其中$\Theta$是参数空间。在经典统计中，样本分布族通常以$f(x;\theta)$出发，对$\theta$进行统计推断（参数估计与假设检验等）。在经典统计中$f(x;\theta)$称为是似然函数。Bayesian统计保存了样本分布$f(x;\theta)$，但是解释有所不同。Bayesian统计认为$\theta$是取值于$\Theta$的随机变量，样本分布$f(x;\theta)$是给定某$\theta$的时候$X$的条件分布，因此可以记为$f(x \vert \theta)$。从数学上看，$f(x \vert \theta)$与$f(x;\theta)$都可以看成是$x$与$\theta$都在变化的时候的分布函数，也就是多元函数的形态，但是多元函数所满足的条件有所不同。这一点在概率论定义条件分布时候有所体现。

参数估计通常是点估计或者区间估计。两种不同的统计方法都有点估计和区间估计。从信息几何的观点来看，Bayes网络是一种特殊的概率分布族；因为引入了条件独立性而降低了流形的统合度，从而简化了统计流形上的Riemann度量矩阵。
