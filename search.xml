<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[Pandoc's test for pandoc-crossref]]></title>
      <url>%2Fblog-pandoc-crossref%2F</url>
      <content type="text"><![CDATA[pandoc-crossref filter Pandoc crossref Homepage is sec. 1.1. Build status pandoc-crossref is a pandoc filter for numbering figures, equations, tables and cross-references to them. Input file (like demo.md) can be converted into html, latex, pdf, md or other formats. Optionally, you can use cleveref for latex/pdf output, e.g. cleveref pdf, cleveref latex, and listings package, e.g. listings pdf, listings latex pandoc-citeproc and pandoc-crossref Since pandoc-crossref uses the same citation syntax as pandoc-citeproc, you have to run former before latter. For example: pandoc -F pandoc-crossref -F pandoc-citeproc file.md -o file.html Image labels Figure 1: Caption See Figure~fig. 1. Subfigures It’s possible to group figures as subfigures. Basic syntax is as follows: a b Figure 2: Figure 1: Caption of figure. a — subfigure 1 caption, b — subfigure 2 caption. a — subfigure 1 caption, b — subfigure 2 caption &lt;div id=&quot;fig:figureRef&quot;&gt; ![subfigure 1 caption](image1.png){#fig:figureRefA width=40%} ![subfigure 2 caption](image2.png){#fig:figureRefB width=40%} Caption of figure &lt;/div&gt; References to subfigures will be rendered as figureNumber (subfigureNumber), e.g., in this particular example, [@fig:figureRefA] will produce fig. 1 (a). Fig 1.(a) : fig. 2 (a) . Equation labels \[ math \qquad(1)\] To label a display equation, append { #eq:label} (with label being something unique to reference this equation by) immediately after math block. Math block and label can be separated by one or more spaces. You can also number all display equations with autoEqnLabels metadata setting (see below). Note, however, that you won’t be able to reference equations without explicit labels. See Equation~eq. 1. Table labels Table 1: Caption a b c 1 2 3 4 5 6 To label a table, append { #tbl:label} at the end of table caption (with label being something unique to reference this table by). Caption and label must be separated by at least one space. See Table~tbl. 1. Code Block labels There are a couple options to add code block labels. Those work only if code block id starts with lst:, e.g. { #lst:code}. caption attribute will be treated as code block caption. If code block has both id and caption attributes, it will be treated as numbered code block. Listing 1: Listing caption main :: IO () main = putStrLn &quot;Hello World!&quot; List Codelst. 1 Table-style captions Enabled with codeBlockCaptions metadata option. If code block is immediately adjacent to paragraph, starting with Listing: or :, said paragraph will be treated as code block caption. Listing: Listing caption main :: IO () main = putStrLn "Hello World!" &lt;pre&gt; Listing: Listing caption main :: IO () main = putStrLn &quot;Hello World!&quot; &lt;/pre&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Test the layout of images]]></title>
      <url>%2Fblog-hexo-image-test%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Bay]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello world from Hexo with NexT theme]]></title>
      <url>%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Solr搜索介绍（继续）]]></title>
      <url>%2Fsolr-tutorial%2F</url>
      <content type="text"><![CDATA[Solr继续 Solr 5.0之后就不再以.war包的格式发布了。而是以一个单独的linux进程发布（daemon）。在其目录下面可以找到init.d目录中的solr，通过该脚本可以启动/opt/solr目录下面的solr工具。但是之后的Solr可能还能够部署到容器当中，但是不是官方所支持的了。 是这样配置的，首先将Solr的tgz后下载之后解压到一个文件夹当中。然后将bin/init.d中的solr文件复制到/etc/init.d目录之下，并需要修改里面的脚本文件。特别是其中的SOLR_INSTALL_DIR变量。然后将solr.in.sh脚本复制到/etc/default目录之下。注意设置RUNAS=&quot;root&quot;变量的值，以及SOLR_ENV的值。设置好之后应该就可以通过service solr start启动服务了。这个时候可以通过netstat命令看到7983端口与8983端口已经被监听了。然后打开localhost:8983也可以进入Solr的管理界面。 快速开始教程参考http://lucene.apache.org/solr/quickstart.html。Lucene/Solr的架构见http://www.solr.cc/blog/?p=167。 要使用快速开始，就不能够使用linux daemon的方式直接启动Solr，必须能够加载example里面的collection名称（core名称）。启动的时候，命令改成bin/solr start -e cloud -noprompt，其中的-e选项后面跟例子名称，比如cloud。在这种方式之下启动，我们可以看到管理台界面的各个collection了。然后就可以使用post工具提交待索引的文档（XML、JSON等格式了）。http://blog.csdn.net/near1024/article/details/44105935上面列出了PDF、CSV、XML、JSON、PPT等格式。 之后我们登录控制台，在控制台当中找到getting started的collection，在collection里面选择query，查询一个词，比如2006，在右边就可以返回结果了。https://lucene.apache.org/solr/quickstart.html上面的教程我们可以完全参考，以尝试如何进行POST，QUERY等操作。里面还介绍了如何通过HTTP来进行查询与得到查询结果。还可以找到Solr的各种高级搜索的表达式。详细参考Solr Reference Guide。Solr的集群，则应该参考Admin Guide。 Solr的slorconfig.xml solrconfig.xml文件用于控制许多影响Solr的行为的参数。配置Solr的时候，许多时候是在同solrconfig.xml文件打交道。或者我们可以通过Config API来间接地修改solrconfig.xml中的值。 solrconfig.xml的功能包括但不限于： request handlers，处理API与响应 listeners，监听特定的查询事件，用于触发特定代码的执行 Request Dispatcher，管理HTTP通信 Admin Web Interface 关于复制与副本的问题（详见Legacy Scaling and Distribution） solrconfig.xml文件位于每个collection（收藏）的conf/目录之下。典型的例子是server/solr/configsets目录中的配置，它适合于很多的场合。 Solr的官方文档对于solrconfig.xml的介绍见https://cwiki.apache.org/confluence/display/solr/Configuring+solrconfig.xml。 Solr中的core（核心）指的是一个单独的索引，以及相关的事务日志与配置文件（solrconfig.xml与Schema文件等）构成的整体。一个Solr在工作的时候可以与多个核心相关联。 通过bin/solr脚本可或者一些API可以创建核心。与核心相关的属性，包括索引文件的存储目录、配置文件、核心的名称等，可以在core.properties文件中得到定义。任何core.properties可以在机器当中的任何位置，因为Solr将会在solr_home下面查找相关的文件。在Solr的单机模式（standalone）下，solr.xml文件必须放在solr_home目录之下，在SolrCloud模式下，solr.xml可以从ZooKeeper当中加载。ZooKeeper当中找不到的时候返回solr_home当中。在旧版本的Solr当中，cores必须被定义在solr.xml文件中的&lt;cores&gt;里面，但是现在Solr支持从solr.xml配置文档中自动发现cores。这样可以动态地创建cores与collections。 我们可以参考server/solr/solr.xml文件。 在建立Solr的集群的时候，不同的机器上的核心具有不同的名称，比如所谓的replica1、replica2、replica3核心。有多个核心可以共同组成一个集群。由于访问Solr的时候必须显式指定core的名称，所以，三台机器配置相同域名的时候，不能使用Nginx做负载均衡。这个时候，要通过Solrj提供的SolrCloudClient，通过ZooKeeper地址进行访问。 Solr连接的时候存在许多的问题，比如SolrClient首次连接ZooKeeper的时候会出现超时。另外Solr原生对中文的支持较差，只能单个分词，因此我们可能需要使用其它的分词器比如ICUTokenizer替代Solr默认的Tokenizer。另外，如果Solr的日志量太大的话，可以使用CONSOLE设置日志级别为WARN，或者控制单个日志文件的大小。 Solr的集群恢复，最坏的情况下需要二倍于当前core的存储空间。此外，默认可能Solr在多核的情况下只能使用一个CPU。此外，我们还可以看到GC吞吐量过低（只有85%这样的级别），这个时候可以设置HEAP大小，使之达到98%这样的级别。还有Out of Memory等问题，见http://www.cnblogs.com/davidwang456/p/5241429.html。详细内容，要学习http://iamyida.iteye.com/category/338597。后者也介绍了Jetty、Tomcat等容器的配置。 http://iamyida.iteye.com/category/338597里面介绍，创建collection的方式是这样的，先决条件是我们在server/solr目录下面有一个solr.xml文件，以后我们就把server/solr目录简称为solr目录了。之后我们创建一个collection1这样的文件夹，进一步在文件夹里面创建一个conf文件夹。进一步地，将server/solr/configsets/basic_configs/conf/solrconfig.xml文件复制到server/solr/collection1/conf目录下面。 然后在Solr的管理控制台中选择添加core，里面指定名称，solr的路径，dataDir、config、schema.xml等文件。自己遇到的一个问题是： Error CREATEing SolrCore &#39;collection1&#39;: Unable to create core [collection1] Caused by: Unknown parameters: {enablePositionIncrements=true} 浏览器的方式创建core，形如 http://localhost:8080/solr/admin/cores?action=CREATE&amp;name=core2&amp;instanceDir=/opt/solr/core2&amp;config=solrconfig.xml&amp;schema=schema.xml&amp;dataDir=data name：就是你的core名称， instanceDir就是你的core根目录，举个例子，linux下可能是/opt/solr/core2,windows下可能是C:/solr/core2 config,schema即core的两个重要的配置文件的名称，只要你core目录结构按规范创建好了，就会按照你指定的配置文件名称去conf目录下去找，dataDir表示你的core的数据目录，该用户主要用来存放你当前core的索引数据。创建好之后就可以post了。 一种不用自己配的方法是利用examples里面的collection1，将其内容复制到solr的目录里面，但是这种方法其实也不好。 注意Java当中很多地方显示的是错误的信息，比如表面上是因为解析不了enablePositionIncrements属性的问题，但是事实上，我们要看ThreadDump里面的详细的错误信息才行（Java的错误的可读性，感觉非常差，Bug也非常多）。 最后，自己决定查看solr的reference manual。http://mirrors.cnnic.cn/apache/lucene/solr/ref-guide/apache-solr-ref-guide-6.0.pdf。 为了方便用户往solr中添加索引，Solr为用户提供了一个post.jar工具，用户只需要在命令行下运行post.jar并传入一些参数就可以完成索引的增删改操作，对，它仅仅是一个供用户进行Solr测试的工具而已。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache Nutch的介绍与基本使用]]></title>
      <url>%2Fapache-nutch%2F</url>
      <content type="text"><![CDATA[Nutch本是一个单独的程序，通过程序可以进行全文的挖掘并定制有关的服务。挖掘出来之后还可以使用Solr进行索引。这样就产生了各个页面。但是另外一方面，Java的程序包又都可以通过包的形式调用，因此在Scala当中也可以使用。但是要在Scala当中使用的话，显然是需要读Nutch的API文档及其用法的。 关于Nutch 2015年1月，Apache Nutch v2.3已经发布了，建议所有使用2.X系列的用户和开发人员升级到这个版本。这个版本提供了一个基于Apache Wicket的Web管理界面，解决了143个问题，提供了Maven依赖，升级到Gora v0.5，支持的底层存储为： Apache Hadoop 1.0.1 &amp; 2.4.0 Apache Cassandra 2.0.2 Apache HBase 0.94.14 Apache Accumulo 1.5.1 MongoDB 2.12.2 Apache Solr 4.8.1 Apache Avro 1.7.6 同时请注意，Gora对SQL的支持已经过时了。 Nutch的创始人是Doug Cutting，他同时也是Lucene、Hadoop和Avro开源项目的创始人。 Nutch诞生于2002年8月，是Apache旗下的一个用Java实现的开源搜索引擎项目，自Nutch1.2版本之后，Nutch已经从搜索引擎演化为网络爬虫，接着Nutch进一步演化为两大分支版本：1.X和2.X，这两大分支最大的区别在于2.X对底层的数据存储进行了抽象以支持各种底层存储技术。 在Nutch的进化过程中，产生了Hadoop、Tika、Gora和Crawler Commons四个Java开源项目。如今这四个项目都发展迅速，极其火爆，尤其是Hadoop，其已成为大规模数据处理的事实上的标准。Tika使用多种现有的开源内容解析项目来实现从多种格式的文件中提取元数据和结构化文本，Gora支持把大数据持久化到多种存储实现，Crawler Commons是一个通用的网络爬虫组件。 大数据这个术语最早的引用可追溯到Nutch。当时，大数据用来描述为更新网络搜索索引需要同时进行批量处理或分析的大量数据集。现在，大数据的含义已经被极大地发展了，业界将大数据的特性归纳为4个“V”。Volume数据体量巨大，Variety数据类型繁多，Value价值密度低，商业价值高，Velocity处理速度快。 Hadoop是大数据的核心技术之一，而Nutch集Hadoop之大成，是Hadoop的源头。学习Hadoop，没有数据怎么办？用Nutch抓！学了Hadoop的Map Reduce以及HDFS，没有实用案例怎么办？学习Nutch！Nutch的很多代码是用Map Reduce和HDFS写的，哪里还能找到比Nutch更好的Hadoop应用案例呢？ Building A Search Engine With Nutch And Solr In 10 Minutes (编译) 首先下载Solr并安装，然后使用java -jar的方式运行起来Solr，得到Solr的管理台界面（为https://localhost:8983/solr/admin）。http://www.lucidimagination.com/Downloads/Lucidworks-for-Solr/Installer。 然后下载Nutch并安装，设置好JAVA_HOME与NUTCH_JAVA_HOME。http://zillionics.com/resources/articles/NutchGuideForDummies.htm。 之后找到一个nutch-site.xml文件，配置如下： &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;http.agent.name&lt;/name&gt; &lt;value&gt;nutch-solr-integration&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;generate.max.per.host&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;plugin.includes&lt;/name&gt; &lt;value&gt;protocol-http|urlfilter-regex|parse-html|index-(basic|anchor)|query-(basic|site|url)|response-(json|xml)|summary-basic|scoring-opic|urlnormalizer-(pass|regex|basic)&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置好之后运行nutch。除此之外，还要包括有URL的seed.txt文件。弄好之后启动，就开始进入到Nutch的挖掘的模式了。最后我们需要将数据推送到Solr，这需要在启动Nutch的时候进行Solr的地址的配置。 HBase的JUJU配置脚本可见https://10.0.8.119/services/?store=~bigdata-dev/trusty/apache-hbase。 注意在安装Nutch之前要安装无论是单机模式还是集群模式的HBase，而HBase的集群模式又需要单独配ZooKeeper等软件组件。这是比较大的工作了。之后自己可能需要调整一下，或者制作几个镜像文件。 nutch 2.3是其src镜像文件，但是事先不需要我们编译。解压之后，首先配置conf/nutch-site.xml文档。修改为 &lt;property&gt; &lt;name&gt;storage.data.store.class&lt;/name&gt; &lt;value&gt;org.apache.gora.hbase.store.HBaseStore&lt;/value&gt; &lt;description&gt;Default class for storing data&lt;/description&gt; &lt;/property&gt; 然后修改ivy/ivy.xml文档： &lt;dependency org=&quot;org.apache.gora&quot; name=&quot;gora-hbase&quot; rev=&quot;0.3&quot; conf=&quot;*-&gt;default&quot; /&gt; 之后再修改conf/gora.properties文档，确保HBaseStore是默认的存储 gora.datastore.default=org.apache.gora.hbase.store.HBaseStore 之后使用ant编译即可。官方配置教程见http://wiki.apache.org/nutch/Nutch2Tutorial. 实际上nutch的存储后端未必是需要HBase，但是Apache Nutch2的官方教程中默认就是使用HBase而不是MongoDB的，因此我们还是不得不配置HBase。而且使用HBase作为存储后端的话，必须在Nutch运行之前先启动HBase。注意几个组件Nutch、Solr、Gora、HBase之间的关系。运行中如果出现HBase找不到，应该参考http://stackoverflow.com/questions/16401667/java-lang-classnotfoundexception-org-apache-gora-hbase-store-hbasestore。在ivy/ivy.xml中添加gora-hbase的依赖。 https://gist.github.com/xrstf/b48a970098a8e76943b9上面介绍了一种ElasticSearch + Nutch + HBase的解决方案。 Nutch的基本使用（Short User Guide） 前面的ant runtime重新编译好之后，在bin目录下就可以找到nutch命令了。 接下来我们首先新建一个seed.txt文件。比如在urls/seed.txt中存储文件的内容。seed.txt中存放初始URL，比如 http://nutch.apache.org/ 之后在conf/regex-urlfilter.txt文件中输入如下的内容： +^http://([a-z0-9]*\.)*nutch.apache.org/ 之后就可以使用nutch命令进行挖掘了。注意一个nutch往往代表一个爬虫而已，nutch带有它的庞大的运行时。在conf/nutch-site.xml文件中还可以设置此次爬虫的名子 &lt;property&gt; &lt;name&gt;http.agent.name&lt;/name&gt; &lt;value&gt;My Nutch Spider&lt;/value&gt; &lt;/property&gt; 接下来我们就考虑Solr与Nutch的集成吧。基于Solr实现站内搜索。封装及扩展性较好，提供了较为完备的解决方案，因此在门户社区中采用此方案，后期加入Compass方案。 由于搜索引擎功能在门户社区中对提高用户体验有着重在门户社区中涉及大量需要搜索引擎的功能需求，目前在实现搜索引擎的方案上有集中方案可供选择： 基于Lucene自己进行封装实现站内搜索。工作量及扩展性都较大，不采用。 调用Google、Baidu的API实现站内搜索。同第三方搜索引擎绑定太死，无法满足后期业务扩展需要，暂时不采用。 Solr是一个基于Lucene的Java搜索引擎服务器。Solr 提供了层面搜索、命中醒目显示并且支持多种输出格式（包括 XML/XSLT 和 JSON 格式）。它易于安装和配置，而且附带了一个基于 HTTP 的管理界面。Solr已经在众多大型的网站中使用，较为成熟和稳定。Solr 包装并扩展了 Lucene，所以Solr的基本上沿用了Lucene的相关术语。更重要的是，Solr 创建的索引与 Lucene 搜索引擎库完全兼容。通过对Solr 进行适当的配置，某些情况下可能需要进行编码，Solr 可以阅读和使用构建到其他 Lucene 应用程序中的索引。此外，很多 Lucene 工具（如Nutch、 Luke）也可以使用Solr 创建的索引。注意solr是可以以.war的形式注入到tomcat的服务器中接受后者的托管的。（不知道现在还行不行）。 ElasticSearch是与Solr可以相类比的功能，Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能。具体特点见http://www.cnblogs.com/chowmin/articles/4629220.html。基于Lucene的还有许多产品，包括直接Lucene、Katta、Hadoop contrib/index、Lucanda、HBasene。 Nutch与Solr的集成的教程可见http://blog.csdn.net/lzjzy520/article/details/41597089。主要在于将Nutch的conf/schema.xml文件拷贝到Solr的server/solr/collection1/conf目录下面，名子保证是schema.xml。然后在其中的field结点里面添加一行 &lt;field name=&quot;_version_&quot; type=&quot;long&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; ./bin/crawl ~/urls/ TestCrawl http://localhost:8983/solr/ 2 ～/urls 是存放了种子url的目录 TestCrawl 是crawlId，这会在HBase中创建一张以crawlId为前缀的表，例如TestCrawl_Webpage。 http://localhost:8983/solr/ , 这是Solr服务器 2，numberOfRounds，迭代的次数 过了一会儿，屏幕上出现了一大堆url，可以看到爬虫正在抓取！ 刚开始的时候可以不指定solr，而是bin/nutch crawl ./urls testcrawlid 2这样的形式。 注：The Nutch-Selenium plugin on Github was made for the Nutch 2.x branch; 注：AFAIK Solr 5.x uses managed-schema in default which will be created on the fly based on the input documents. However you can copy your schema.xml file content to the 注：http://blog.csdn.net/lzx1104/article/details/42029981介绍了Solr 4.9以上的managed-solr的功能。如果使用了ManagedIndexSchemaFactory，Solr会从“managedSchemaResourceName”指定的文件名中加载schema，而不是从schema.xml;如果指定的文件（managed-schema）不存在，将会从schema.xml中加载并创建文件，并将schema.xml重命名为schema.xml.bak. 不要编辑managed schema – 外部的修改会被忽略，并被修改schema 的RestAPI调用所覆盖。 mutable = true修改schema 的RestAPI调用被允许，否则会报错。 注：nutch的crawl命令是一个完整的从索引到爬取的过程命令。比如 crawl ./urls/ testcrawl http://10.0.8.68:8983/solr/collection1/ 1 Nutch 1.x 命令介绍：http://www.cnblogs.com/xia520pi/p/3663506.html nutch的readdb命令是“org.apache.nutch.crawl.CrawlDbReader”的别称，返回或者导出Crawl数据库（crawldb）中的信息。 readlinkdb是“org.apache.nutch.crawl.LinkDbReader”的别称，导出链接库中信息或者返回其中一个URL信息。 inject是“org.apache.nutch.crawl.Injector”的别称，注入新URL到crawldb中。 generate是“org.apache.nutch.crawl.Generator”，从Crawldb中抓取新的Segment。 fetch是“org.apache.nutch.fetcher.Fetcher”的代称，它负责一个segment的爬取。 parse是“org.apache.nutch.parse.ParseSegment”的代称，它对一个segment运行ParseSegment。 readseg是“org.apache.nutch.segment.SegmentReader”的代称，它读取并导出Segment数据。 updatedb是“org.apache.nutch.crawl.CrawlDb”的代称，用fetch过程中获取的信息更新crawldb。 invertlinks是“org.apache.nutch.crawl.LinkDb”的代称，它用从segment中获取到的信息更新linkdb。 index是“org.apache.nutch.indexer.Indexer”的代称，创建一个segment的索引，利用crawldb和linkdb中的数据对索引中的页面打分。 merge是“org.apache.nutch.indexer.IndexMerger”的代称，它合并多个segment索引。 mergedb是“org.apache.nutch.crawl.CrawlDbMerger”的代称，合并多个CrawlDb，URLFilter可选择性地过滤指定内容。 可以合并多个DB到一个中。当你分别运行爬虫并希望最终合并DB时，它会相当有用。可选择地，可以运行当前URLFilter过滤数据库中的URL，以滤去不需要的URL。当只有一个DB时也很有用，它意味着你可以通过这个工作去滤掉那些DB中你不想要的URL。 mergelinkdb是“org.apache.nutch.crawl.LinkDbMerger”的代称，用于合并多个linkdb，可以选择性的使用URLFilter来过滤指定内容。 mergesegs是“org.apache.nutch.segment.SegmentMerger”的代称，用于合并多个segment，可以选择性地输出到一个或者多个固定大小的segment中。 dedup是“org.apache.nutch.indexer.DeleteDuplicates”的别名，它segment indexes中去掉重复的页面。 plugin是“org.apache.nutch.plugin.PluginRepository”的代称，用于从插件库中加载一个插件并执行其主方法。 solrindex是“org.apache.nutch.indexer.solr.SolrIndexer”的代称，用于对抓取的内容进行索引建立，前提是要有solr环境。 注意我们使用的crawl命令中的testcrawl就是crawlId，该ID可以用于readdb等命令中，比如 nutch readdb -crawlId testcrawl -stats ### 如果我们后端使用的HBase，那么就可以从HBase中读到相应crawlId的数据库了。 解决No IndexWriters activated - check your configuration的问题：见http://stackoverflow.com/questions/17649567/nutch-message-no-indexwriters-activated-while-loading-to-solr/25945844#25945844。 nutch solrindex -crawlid doubanmovie Nutch 2.x的命令接口 Nutch1与Nutch2的接口发生了很大的变化，许多教程解释都已经不能再用了。参考http://wiki.apache.org/nutch/bin/nutch%20solrindex，来获得详细一点的针对Nutch2的命令的介绍。 ### 我们从DMOZ开放式分类目录添加URL。 ### 首先我们必须下载并且解压缩这个DMOZ所有网页的列表 ### 这是一个200多MB的文件，所以这会消耗几分钟 wget http://rdf.dmoz.org/rdf/content.rdf.u8.gz gunzip content.rdf.u8.gz ### 接下来我们选择这些网页当中随机的一些子集 ### 我们使用随机的子集所以所有在跟着这一个教程做的人就不会伤害到同样的网站 ### DMOZ包含了大约三百万个URL。我们从每5000个URL中选择出一个，因此我们就有大约1000个URL ### 这里我们从50000个URL中选择出一个，因此总共选择大约100个，可以节省很多时间 nutch org.apache.nutch.tools.DmozParser content.rdf.u8 -subset 5000 &gt; dmoz/seed.txt ### 最后，我们用这些选出的URL来初始化crawlId（在Nutch 2中改成了crawlId而不是db文件， ### crawlId存在相应的hbase库当中 nutch inject ./dmoz/ -crawlId dmozcrawl ### 要获取，我们首先要从数据库里产生一个获取的列表， ### 生成的任务中，-topN表示选择的URL数 ### -batchId表示我们所生成的这些初始网页的任务名，接下来在fetch等操作的时候可以指定任务名 ### topN是每一级所获取的网页数，限制topN可以减少抓取的数目 nutch generate -crawlId dmozcrawl -topN 100 ### 在以下面的命令在这个分段里进行获取 ### 可以改成前面-batchId指定的参数，以代替fetch nutch fetch -all -crawlId dmozcrawl -threads 2 ### 获取之后parse有关条目 nutch parse -all -crawlId dmozcrawl ### 当这一切完成以后，我们就以获取回来的结果更新数据库 nutch updatedb -all -crawlId dmozcrawl ### 进行索引，在新的nutch里面，已经没有invertindex了，只有index了 nutch index -all -crawlId dmozcrawl nutch solrindex http://10.0.8.68:8983/solr/test/ -all -crawlId dmozcrawl nutch solrindex http://10.0.8.68:8983/solr/collection1/ sec200 -crawlId dmozcrawl ### 爬完之后，在nutch里面可以进行查询诊断，其中的faq是关键词 ### 该脚本尝试过，不能正常工作 nutch org.apache.nutch.searcher.NutchBean faq ### 提交之后，我们将可以在solr控制台中看到有关文档的数目。 ### 任何时候都能运行的测试命令 nutch parse http://www.precastdesign.com/ nutch indexchecker http://www.precastdesign.com/ Nutch加MongoDB加ElasticSearch的配置 见http://www.jeepshoe.org/82645084.htm。 一：nutch2.x与nutch1.x的主要区别：数据访问层的抽象 nutch 2.x—-gora-core-0.3—-gora-hbase—-hbase gora-core-0.3 apache-gora提供了对nosql访问的统一接口。（注解：在上述链接里可以看到对其他数据库的支持） gora-hbase 针对hbase实现了gora的接口 有了这两步nutch2.x就可以运行在Hbase上了。 支持nosql的优势： 当获取了外链要进行url排重的时候，以前基于hdfs的时候是读取之前全部的url用mapreduce实现排重（好沉重的赶脚），支持了nosql只需要一步查找即可。 这里Hadoop与HBase的集成主要是将HBase安装到Hadoop当中，然后HBase的rootdir配置成hdfs的方式（即HBase的数据进一步存储在HDFS文件系统当中）。这里在设置hbase-env.sh与hbase-site.xml的时候进行配置的。另外，注意HBase也完全可以与Hadoop割离开，从而仅仅是使用Hadoop的后端而已。当然，HBase还要进一步与ZooKeeper集成。 在配置的时候特别注意Hadoop的版本与HBase的版本的一致性。 Solr的一个错误的处理 在使用nutch的时候，提交的的时候出现： Expected content type application/octet-stream but got text/html;charset=iso-8859-1 http://stackoverflow.com/questions/24089769/solr-realtime-get-remotesolrexception-expected-mime-type-application-xml-but-go上面给出来了一个回答。 在使用Tomcat部署Solr后，Collection1的地址为：http://182.92.160.44:8080/solr/#/collection1，但使用SolrJ进行索引的时候，应该使用http://182.92.160.44:8080/solr/collection1，即无中间的#号。 一个crawl命令可能封装了太多的过程。接下来我们以dmoz为例，一个命令一个命令地执行，看看是什么样的结果。 首先使用solr命令的solr create -c test来创建一个默认的collection。然后进入nutch的环节。依次执行如下的命令： Scala下面使用Nutch https://blog.knoldus.com/2012/03/14/intercepting-nutch-crawl-flow-with-a-scala-plugin/。 Nutch 2.0的REST接口，见https://wiki.apache.org/nutch/NutchRESTAPI。Nutch教程，比较华丽的版本http://www.cnblogs.com/xia520pi/p/3615554.html.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[随机微分方程的一种引入方法]]></title>
      <url>%2Fstochastic-differential-equation-intro%2F</url>
      <content type="text"><![CDATA[我们该怎样引入随机微分方程呢？大概是这样的，首先考虑常的微分方程ODE为\(x&#39;=V(x)\), \(x\in \Omega\subseteq\mathbb{R}^n\)，然后此方程刻划物理现象的时候作为物体运动的轨迹，其解\(x(t), t\geq 0\)是关于\(t\)的光滑的曲线。但是在许多应用中，从实验所观测到的轨迹不如确定性方程所描述的那样光滑。因此有必要改正ODE为SDE。 也就是变成微分 \[d X(t) = V(X(t)) d t + G(X(t))\xi(t)\] 的形式。其中的\(G(X)\)是\(n\times m\)的矩阵。\(\xi\)是\(m\)维的白噪声。但是问题在于，在数学上如何严格定义白噪音。作为一个随机过程，其解又是什么意思？ 直观的解释是使用连续随机过程来处理随机微分方程。每个\(X\)表示是一个随机变量，而\(X(t)\)整体表示的是求解一族随机过程本身。因此也就变成了求随机变量分布或者密度与时间的参数的关系。比如线性单自由度体系的运动方程 \[mX&#39;&#39;(t) + cX&#39;(t) + kX(t) = Y(t), X(0) = X_0, X&#39;(0) = X&#39;_0\] 中，引入\(X_1(t) = X(t)\)，就写成使用状态变量描述动态系统的方法。这种方法是系统工程与现代控制理论的重要的手段。在振动工程中有许多方便的应用。 公式化定义 考虑具有随机初始条件的简单随机微分方程 \[X&#39;(t) = f(X(t),t) , t\in T; X(t_0) = X_0\] 式中的\(f\)是均方连续且均方有界的函数。\(X_0\)是已知的随机变量。给定一个随机过程\(X(t)\)，如果它满足 \(X(t)\)在\(T\)上均方连续 \(X(t_0) = X_0\) \(f(X(t),t)\)是\(X(t)\)在\(T\)上的均方导数，则称\(X(t)\)是方程的一个均方解。易证方程与积分方程\[X(t) = X_0 + \int_{t_0}^t f(X(s),s)\d s\]是等价的。其中的积分是均方积分。这样对随机微分方程的求解经常可以从随机积分方程入手。 具有随机初始条件的齐次线性常微分方和可以描述为： \[X&#39;(t) = A(t) X(t), t\in T, X(t_0) = X_0\] 式中的\(A(t)\)是\(n\times n\)的确定性的实矩阵，且各元素均在\(t\)上连续。\(X_0\)则是已知的某个随机变量，比如服从正态分布的随机变量。其对应的具有确定初始条件的方程是 \[x&#39;(t) = A(t) x(t), t\in T, x(t_0) = x_0\] 由常微分方程理论我们就知道这样的常微分方程具有唯一解\(x(t) = H(t,t_0)x_0\)。其中\(H\)是\(n\times n\)的矩阵，它与系统矩阵\(A(t)\)对应确定性方程的基本解矩阵。当\(A(t)=A\)是常数矩阵的时候，\(H(t,t_0)\)可以显式地表示成矩阵指数 \[H(t,t_0) = \mathrm{e}^{(t-t_0)A}\] 类似地，我们考察随机微分方程具有和常微分方程类似形式的解，那么应该有\(X(t) = H(t,t_0), X(0)=X_0\)。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速了解Modelica与OpenModelica建模2-ModelicaML与方程]]></title>
      <url>%2Fmodelica-modeling-2%2F</url>
      <content type="text"><![CDATA[ModelicaML ModelicaML同样地用于系统建模。不过不是语言的方式，而是首先以UML类似的模型表示出相应关系，然后这种模型被转换成Modelica的代码。转换代码后就可以执行，模拟出结果。ModelicaML是UML Profile的一个具体的扩展。 ModelicaML的一个开发的方法是在Papyrus UML环境下进行。在此环境之下，通过Acceleo工具生成Modelica的代码，经过M2T工具生成Modelica的.mo文件，之后可以通过任何一个符合Modelica语言要求的模拟工具中运行出来结果。安装Modelica Development Tool的Eclipse插件之后，新建Papyrus工程，在模型语言（Diagram Language）提供的UML、SysML、ModelicaML、Profile中选择ModelicaML，这样就进入了ModelicaML的建模的环境了。之后我们就可以使用ModelicaML来完成建模了（UML本身可以用于元建模，这个时候，UML规范本身就是元元建模工具了）。 Modelica使用类UML的图形表示模型。有结构图、需求图、行为图等描述方法。注意到Modelica本身也是一种元模型规范。Modelica中的元素被看成是prototype，所有的类都是继承自该原型。ModelicaML充分利用了Modelica语言的特性，可以在状态图中使用Modelica的谓词语言与条件判断，同时，也增强了UML建模算法的能力（算法流程以及代数方程）。 另外，运行Modelica Script是使用runScript命令。Script可能不是Modelica语言规范的一部分，因为像System Modeler之类的工具的脚本是基于Wolfram语言的（比如典型的用中括号而非小括号调用函数）。OpenModelica还具有交互式模拟的能力。在运行的图表中，如果有ModelicaML的需求文档，能够对比需求目标与设计目标的差距（是不是比软件工程中的过设计与欠设计在功能方面的东西更直观？），另外，根据需要，可以建立可视化的模拟过程演示，包括3D力学系统的功能演示。 OpenModelica还提供了OMPython这样一个环境，可以整合Python语言工作区以及Modelica模拟语言。Modelica3D则能够实现3D图形模拟同步的演示，模拟流体、力学系能各种模型的结构化展示，而不仅是模拟出来函数图表。 OPENPROD提出了使用Modelica建模Cyber-Physical模型的一些开发方法，与模型驱动方法以及软件生命周期都有结合。里面还使用了业务流程控制、需求捕获、PIM与PSM的转换等概念。注意ModelicaML也是OMG规范的一种建模的格式。此外还有MetaModelica，需要注意的是，OpenModelica的编译器本身也是通过15万行的MetaModelica代码实现。 loadFile、loadModel之类的函数是所谓的CORBA API函数。 通过Modelica来理解多领域建模 自己之前一直想不清楚控制理论与控制工程是怎样运行的。今天看到一个关于Modelica多领域建模的图表自己一下子就明白了。 这个图表是这样的，首先有一个电源驱动，然后进入电机的控制系统，电机系统最后与机械系统相连（电动力控制运行系统）。机械系统之后有一个所谓的角速传感器，这个传感器可以完成反馈。结果，这个传感器的信号就可以经过PID控制系统反馈到电力系统当中，通过调整输入电压、电流等方式间接地影响力学系统的转速等参数。这样的系统中涉及到电力系统、机械系统与控制系统三个领域，但是共同服务于一个现代电机。大概许多现代的系统都是多领域的吧。 Simulink是典型的使用因果关系建模的软件，系统中所有的信号都具有流向。但是Modelica的典型的方式是使用结构建模，通过方程约束完成建模。Simulink的这种建模思路需要人工做更多的处理。和Simulink一样，Modelica也支持子系统的建模。 Modelica可以看成是强类型的语言。在数组与矩阵运算模仿Matlab的同时，也可以进行非常多的强类型检查活动（似乎强类型以及静态类型成为最近程序语言的热点发展方向之一了）。 Modelica作为面向对象的语言，支持继承的概念，似乎因此我们可以扩展PNlib中的一些类，实现多个参数的建模过程（比如增加PetriNet中变迁的能力。(Fritzson 2011)是一本不错的介绍Modelica的入门书籍，讲解如何建模的。 英文中有simulation与emulation这两个东西。语义上似乎还有一些不同。在Modelica的领域，建模是与数学建模密切相关的。因为建模包括了物理系统、数学系统、语言的、心理的等几个领域。而数学与物理建模在科学与工程中起着重要的作用。Modelica的建模，通常可以从数学建模中分成静态与动态模型、定性与定量模型、连续与离散模型这一分类开始：比如说，Modelica通常是动态模型，能定性也能宣，能描述连续性也能描述离散性质。（甚至大概Verilog也是此类模拟语言吧，不过Verilog似乎只模拟信号系统，而不模拟物理系统的特性–不妨把不同系统的建模与模拟当成是本辑笔记第二卷与第三卷的内容）。 Modelica的特点可以总结如下：声明式为主，也支持过程式；支持多领域综合，使用面向对象的语言并且保留了矩阵运算的方便性。此外，还可以与ModelicaML，以及可视化组件相结合。Modelica具有一些函数式的风格（至于支持方程，应该是属于等式编程语言那一类）。Modelica内在是并行的，其函数有作用域的（不像Matlab），然后其类型系统受到Abadi/Cardelli的影响（其实面向对象语言大部分地方也是声明性的）。 Modelica语言规范可以从其官网上下载。不过其语言规范不是很有意思，因为Modelica提供了ModelicaML作为其抽象语法的另一种描述形式。后者或许看起来更直观一些（应参考Modelica最近的语言规范3.3版）。 Modelica的方程描述能力 Modelica中的方程典型的形式是代数方程与左边为方程导数，右边为导数值的形式。另外的形式就是一个复杂的加减乘除的四则表达式。不知道是否支持隐式方程与复杂的导数方程（比如高阶导数以及导数的平方？） 下面是几种容许的约束形式： apollo.gravity = moon.g * moon.mass / ( apollo.altitude + moon.radius ) ^ 2; apollo.thrust = if (time &lt; thrustDecreaseTime) then force1 else force2; red + blue + green = 1; 和SysML相比，Modelica虽然在描述模型的精确行为上很强大，但是在描述复杂系统中的继承关系、需求等的进候并不像SysML那样强大。为此就有了所谓的ModelicaML。该图表扩展了SysML的许多内容。比如，在基本Diagram概念增加了Simulation Diagram，在Structure Diagram中做了增强，在行为描述中添加了Equation Diagram。其余的大部分则与SysML保持了相同。 比如说，ModelicaModel也被认为是一种特殊的Class。 Fritzson, Peter A. 2011. Introduction to Modeling and Simulation of Technical and Physical Systems with Modelica. Wiley IEEE. http://gen.lib.rus.ec/book/index.php?md5=acecd4ecbcf6468f282ca96f5e4759b3.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[快速了解Modelica与OpenModelica建模1-基本知识]]></title>
      <url>%2Fmodelica-basics%2F</url>
      <content type="text"><![CDATA[Modelica里面倒是有不少的面向对象的建模的工具，也支持PetriNet的描述。而且最近也有相关的论文的发表(Proß et al. 2012)。OpenModelica上面的PNlib工具包倒好像是不错的。 OpenModelica是其一个实现。OpenModelica环境由若干个子系统构顶成。包括文本模型与图形模型编辑器、编译器调试器与执行环境、笔记本、优化器以及Eclipse插件。其中的编译子系统用于将Modelica语言编译成C代码。面向Eclipse的插件被称为MDT。最基本的方式自然是安装之后点击OMShell进入文本编辑环境。里面输入Modelica的代码。OMShell命令会打开一个新的窗格，使用OMShell-terminal命令可以直接在Linux终端中进入OpenModelica的环境。这时进入的就是交互式模式。 model A Integer t= 1.5; end A; instantiateModel(A); model C Integer a; Real b; equation der(a) = b; der(b) = 12.0; end C 模型是Modelica中的基本元素，许多内容也就围绕着模型的定义来。模型可以用文件来定义，一般使用后缀.mo。使用loadFile命令就可以从文件中加载模型。使用system命令则可以执行操作系统的Shell的代码。 比如下面是使用Modelica写的冒泡排序的代码： function bubblesort input Real[:] x; output Real[size(x,1)] y; protected Real t; algorithm y := x; for i in 1:size(x,1) loop for j in 1:size(x,1) loop if y[i] &gt; y[j] then t := y[i]; y[i] := y[j]; y[j] := t; end if; end for; end for; end bubblesort; 从上面可以看出Modelica的代码风格做得非常“冗余”。每个循环与条件语句必须显式被结束，每个函数体与模块也必须带显式的结尾处理。函数体中的输入、输出、局部变量与算法体必须各自区分开。 实际上Modelica的输出是通过基于CORBA的客户端实现的。更好的方式是通过readFile实现将文件中的函数等对象加载到当前工作区。在OMShell中，使用cd()函数可以返回当前工作路径，添加字符串参数之后可以切换工作路径。 OpenModelica有一些标准模型，它们使用loadModel()函数加载。比如loadModel(Modelica)，加载Modelica的标准库。下面是一个模拟运行的示例文件： loadFile(&quot;/usr/share/doc/omc/testmodels/dcmotor.mo&quot;) list(dcmotor) // 列出模型源代码 instantiateModel(dcmotor) //对模型进行实例化，得到实例化后的代码 simulate(dcmotor, startTime=0, stopTime=10.0) 模拟之后我们可以得到一系列变量，然后用它们来画图。val(variableName, time)函数就是用于得到模拟结果中的变量在特定时间的值的。 比如我们看如下的代码： loadFile(&quot;/usr/share/doc/omc/testmodels/BouncingBall.mo&quot;); list(BouncingBall); simulate(BouncingBall, stopTime=3.0); plot({h,flying}); 在OMShell中运行的代码可以保存成.mos格式（Modelica script）。然后通过runScript命令来运行。（使用writeFile可以将字符串写入特定文件）。 接下来我们演示一个开关的模拟的例子： model Switch Real v; Real i; Real i1; Real itot; Boolean open; equation itot = i+i1; if open then v=0; else i=0; end if 1-i1=0; 1-v-i=0; open = time &gt;= 0.5; end Switch; simulate(Switch, startTime=0, stopTime=1); val(itot,0); 类似于Matlab，可以使用clear()清楚当前工作区，使用list()查看加载的模型。在OpenModelica当中，控制结构、函数、变量、类型都是非常正常的概念，还可以使用typeOf()函数查看变量的类型。Modelica实现模拟主要是通过simulate函数。函数既可以输出成特定的模拟结果，也可以只保存特定的变量。也可以使用并行模拟（启动omc的时候指定并行的参数）。 Model的library又称package，使用package来定义，里面可以添加一些注释。 package Modelica annotation(uses(Complex(version=&quot;1.0&quot;),ModelicaServices(version=&quot;1.1&quot;))); end Modelica; 在加载模块的时候，如果指定了对指定包的依赖关系，那么指定包也会加载上去： model M annotation(uses(Modelica(version=&quot;3.2.1&quot;))); end M; instantiateModel(M) instantiateModel(Modelica.Electrical.Analog.Basic.Ground) //只加载其中的模块 list(Modelica) //查询名为Modelica的模块的模型。 quite() //退出Modelica环境 Modelica的模型可以转换成Matlab的模型，只需要一个exportDAEtoMatlab()函数就可以完成转换了。 omc命令是modelica的编译器。它可以读取一个.mo文件然后编译模型。另外，omc也可以执行.mos格式的脚本命令，以非交互的方式运行。还可以在运行中执行调试工作。 OMEdit是图形化的编辑模型的界面。里面可以使用预定义的模型、用户定义的模型，组件接口，以及模拟过程，还可以绘制图形。 在Model里面也可以定义algorithm。以调试算法。OpenModelica支持文学编程方法。在交互式Notebookk 就可以实现。 面向Eclipse的MDT支持Modelica与MetaModelica的开发。在相关网站上可以下载到OpenModelica的插件。之后就可以在Eclipse环境下进行工作了。也有高亮，也可以绘制出来图形。还可以进行调试等工作（使用GDB）。也有一些3D库，可以完成3D图形的建模等工作。除此之外，还可以方便地调用外部的C函数，或者调用Python的函数。另外，从Python中也可以调用Modelica的函数，使用OMPython。 关于Modelica Modelica当然是一种通用的建模与模拟的软件。但是其建模的方式也有其特殊之处。首先是使用了面向对象的技术，一个模型可以看成是一个对象，并且像编程语言那样使用class关键字来声明。然后变量有相应的类型。模型中的恒等式可以使用DAE（微分代数方程，连续情形）或者Event triggerg来表示（离散时间）。比如如下的VanDerPol的方程模型： class VanDerPol &quot;Van Der Pol振子模型&quot; Real x(start=1) &quot;描述变量x&quot;; Real x(start=1) &quot;y变量&quot;; parameter Real lambda = 0.3; equation der(x) = y; der(y) = -x + lambda*(1-x*x)*y; // 微分方程约束 end VanDerPol; 另外，Modelica还可以处理连续与离散情形混合的情况，进行混合的建模。另外则是Modelica语言显著缩短了在建模的时候进行系统定义、系统分解、子系统建模、因果关系推测、实现以及模拟所花费的时间。 Simulink是基于信号流进行建模的语言。但是Modelica语言则是完全按照物理模型的结构来的，中间不需要刻意去写成信号流图的形式。因此，我们可以直观地画出电路图就可以模拟，而不用转换成Matlab那种信号流的模式。另外，Modelica也可以进行图形可视化的建模，通过拖动实现模块的组合。 比如如下的直流电机的建模： model DCMotor Resistor R(R=100); Inductor L(L=100); VsourceDC DC(f=10); Ground G; ElectroMechanicalElement EM(k=10,J=10,b=2); Inertia load; //器件与器件的性能参数 equation //连接方程，Modelica会根据连接方程自动推导函数关系，转化成ODE与DAE的形式 connect(DC.p, R.n); connect(R.p, L.n); connect(L.p, EM.n); connect(Em.p, DC.n); connect(DC.n, G.p); connect(EM.flange, load.flange); end DCMotor 中间的执行流程是图形或者文本模型经过处理变成Modelica的源代码。变成Modelica的模型。然后通过Translator变成混合DAE所描述的方程。然后使用分析器进行分析，再用优化器优化成C代码。最后编译并执行。模拟的时候，OpenModelica中也可以选择交互式模拟的方式。 Modelica在生物、机械、化学、工业中都有比较成功的应用。练习OpenModelica的时候，刚开始可以从图形化的OMedit开始，建立一个RLC电路的模拟。网上有相关教程： 打开OMEdit，文件菜单中选择新建模型，输入模型名RLCircuit（也就是新建Class，在OMEdit中也可以新建Modelica的元模型）。 在左侧的库中选择Modelica下面的电路元件，将它们按标准连接起来。 点击模拟即可。 Modelica与SysML、ModelicaML、UML也有合作。其中的ModelicaML就是为了支持软件与硬件建模而设计的UML Profile。还可以将UML/SysML映射到Modelica。 在Modelica语言中，类型有Boolean等。而变量可以加上constant或者parameter，表示不变的量或者变化的量（后者允许模拟的时候交互式调整）。class声明与model声明类似，但是class声明的可以被实例化，还有protected、public等修饰的变量。Modelica中函数也可以看成是特别的类。但是多了input/output、algorithm等块体。函数中也有protected的成员。record可以表示记录体结构、定义参数形式。Modelica也支持所谓的多继承。 最好可能还是从OMNotebook开始。因为里面有许多可视化。如果是离散的，那么可以在变量前面加上discrete修饰词。比如如下的离散模型： model SamplingClock Integer i; discrete Real r; equation when sample(2,0.5) then i = pre(i) + 1; r = pre(r) + 0.3; end when; end SamplingClock; 图形建模的时候有自己的规则。比如特别规定了connector为一种连接器类别。Modelica中定义了许多物理系统的连接器。使用connnect函数可以连接许多内容。连接器需指定连接方程，默认的方程是两端信号值相等。如果是flow函数，则表示流量相等，方向也是相同的。 在Modelica中不能被实例化的类称为partial class。DrControl是专门用于讲控制理论的一个建模的手册，可以方便地写出控制的方程来。 Proß, Sabrina, Bernhard Bachmann, Sebastian Janowski, and Ralf Hofestädt. 2012. “A New Object-Oriented Petri Net Simulation Environment Based on Modelica.” In Winter Simulation Conference, WSC ’12, Berlin, Germany, December 9-12, 2012, edited by Oliver Rose and Adelinde M. Uhrmacher, 300:1–300:13. WSC. doi:10.1109/WSC.2012.6465287.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[常见的数据结构的抽象]]></title>
      <url>%2Fdatatype-abstraction%2F</url>
      <content type="text"><![CDATA[为了编程的顺利进行，自然有一种控制复杂性的措施。而且复杂性的控制从编程语言一开始的时候就有了，成为所谓的内部模式：内建的数据结构，甚至是语言机制里面的内容。现在我们看一些常见的数据类型。 数组 按照Wiki的要求，应该按照数据结构和数据类型两个不同的角度讲数组array。作为数据结构的数组是由一系列元素（值或者变量）构成的，每个元素数数组由键或者索引来标识。按照要求，数组里的元素的存储应该可以按照数学公式来计算，也就是说，数组的标识不能是简单的字符串，而要使用一个域，特别是使用整数来标识。 数组在历史上出现得是非常早的，经常作为列表list以及字符串string的实现。在现代计算机当中，内存通常都是按照一维数组的方式来计算的。而现代计算机中的优化，特别是向量处理机，都是针对数组的操作而优化的。（数据结构就是数据结构，跟它们使用硬件或者软件实现并没有关系）。 数组的一个大优势在于所使用的下标可以在运行时候被计算出来。但是需要注意的是，在底层数据结构也可能非常复杂。数组可能用哈希表、链表、查找树等结构实现。总而言之，底层数据结构与顶层数据结构有很大的不同。1945年John von Neumann写了第一个数组排序的算法。 作为抽象数据类型的列表，包含的操作有： 创建一个空表； 测试当前列表是否为空； 添加一个元素到列表的第一个位置； 添加一个元素到列表的最后位置； 得到列表的第一个元素； 引用列表中除了第一个元素之外的其它元素。 对于特定类型的列表，具有如下的操作规范： nil: () \(\to\) L cons: E \(\times\) L \(\to\) L first: L \(\to\) E rest: L \(\to\) L with the axioms first (cons (e, l)) = e rest (cons (e, l)) = l for any element e and any list l. It is implicit that cons (e, l) \(\neg\) l cons (e, l) \(\neg\) e cons (e1, l1) = cons (e2, l2) if e1 = e2 and l1 = l2]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[维基上定义的传递系统]]></title>
      <url>%2Fwikipedia-transition-system%2F</url>
      <content type="text"><![CDATA[众所周知的是传递系统只是从系统转换的观点来看问题，其理论的根据跟抽象重写系统是一样的，但是可能说明的角度不一样吧。传递系统分成两类，带标签的和不带标签的系统。传递系统在应用于模型检查的时候经常使用带标签的形式。 Action Language是专门描述状态传递系统STS（state transition systems）的语言。经常用于形式化地创建一系列的模型。PDDL是著名的一种Action Language。 状态转移系统往往显得太过抽象。感觉好像跟动力系统理论和自动机理论都有一些差别。或许它们是研究离散状态的一种抽象理论吧。状态转移系统自然是关联着状态及其转移的。但是动力系统呢？ 目前，我们似乎可以这样关联状态转移与动力系统理论。所谓的系统，我们关注的还是系统的演化的特性，也就是系统的存在及其演化。那么，自然中心的问题是，系统是怎样随时间变化的？因而，首先的问题就是所谓的对于状态的定义。在动力系统中，状态是由一个实参量标识的，它可以对时间演化可微。而在状态转移系统中，状态是一种不同的数学结构，比如说，状态是一个有穷序列，而时间也是离散的。那么，基于这种认识，似乎结合起来看，所谓的系统理论，就是某个数学结构上面的参数的理论。就像是微分几何中，每一点附上一个特定的数学结构一样，系统理论是演化过程中的每一时间点附上一个状态–似乎系统理论研究的情况，都是底空间是低维的情况。 另外，状态转移系统中，虽然状态是连续的，但是状态转移的过程可以是连续的。 互模拟与LTS基础介绍 Bisimulation Given a labelled state transition system \((S,\Lambda, \to)\), a bisimulation relation is a binary relation \(R\) over \(S\) such that both \(R^{-1}\) and \(R\) are simulations. Equivalently \(R\) is a bisimulation if for every pair of elements \(p,q\) is \(S\) with \((p,q)\) in \(R\), for all \(\alpha\) in \(\Lambda\): * for all \(p&#39;\) in \(S\), \(p\overset{\alpha}{\rightarrow} p&#39;\) implies that there is a \(q&#39; \in S\) such that \(q \overset{\alpha}{\rightarrow} q&#39;\) and \((p&#39;, q&#39;)\in R\). * for all \(q&#39;\) in \(S\), \(q\overset{\alpha}{\rightarrow} q&#39;\) implies that there is a \(p&#39; \in S\) such that \(p \overset{\alpha}{\rightarrow} p&#39;\) and \((p&#39;, q&#39;)\in R\). Given two states \(p\) and \(q\) in \(S\), \(p\) is bisimilar to \(q\), written \(p \sim q\), if there is a bisimultion \(R\) such that \((p,q)\) is in \(R\). 也就是说，如果两个状态标记系统是互模拟的，那么我们称这两个系统是相互等价的。这个时候，\(p\)可以模拟\(q\)，而\(q\)也可以模拟\(p\)（但是反过来则不成立，因为还需要一些附加的条件）。我们可以证明，两个状态的相似性是一个等价关系。互模拟有多个定义，比较不动点的定义。可能是我们必须要熟悉的。 下面我们来看什么是transition systems. In theoretical computer science, a transition system is a concept used in the sutdy of computation. It is used to describe the potential behavior of discrete systems. It consists of states and transitions between states, which may be labeled with labels chosen from a set; the same label may appear on more than one transition. Transition systems coincide mathematically with abstract rewriting systems. and directed graphs. They differ from finite state automata in several ways: The set of states is not necessarily finite, or even countable. The set of transitions if not necessarily finite, or even countable. No “start” state or “final” states are given. Transition systems can be represented as directed graphs. transition system A transition system is a pair \((S,\rightarrow)\) where \(S\) is a set of states and \(\rightarrow\) is a set of state transitions, i.e., \(\rightarrow \in S\times S\). The fact that there is a transition from step \(P\) to state \(q\), i.e. \((p,q)\in\rightarrow\), is written as \(p\rightarrow q\). labelled transition system A labelled transition system is a tuple \((S,\Lambda,\rightarrow)\) where \(S\) is a set of states, \(\Lambda\) is a set of labels and \(\rightarrow\) is a set of labelled transitions (where \(\rightarrow \in S\times \Lambda\times S\)). The fact that \((p, \alpha, q)\in \rightarrow\) is written as \(p \overset{\alpha}{\rightarrow} q\). Labels can represent different things depending on the language of interest. Typical uses of labels include representing input expected , conditions that must be true to trigger the transition, or actions performed during the transition. Labelled transitions systems were originally introduced as named transition systems. 我们都知道状态机广泛用于系统的行为的建模，TS(Transition System)也是如此。状态与转换我们都容易理解，但是可能label就不那么容易理解了。labels可以表示发生这一转换的时候的各种来自环境的需求，比较发生转换的条件，转换的输出，转换的时候需要执行的代码等等。label集\(\Lambda\)实际上可以有复杂的结构，用于满足各种不同目的的状态转换系统建模的需求。 LTS在数学上等价于ARS（Abstract Rewritting System），而后者在数学与数理逻辑中被广泛用来表示逻辑推理的过程。但是考察的角度不一样。逻辑推理系统关心的重点与离散系统关心的重点不一样。虽然自己觉得ARS是逻辑学的研究的重点，但是觉得，在SC.3的笔记中引入ARS作为LTS的等价物也没有什么不妥，毕竟SC.3当然可以引入各种逻辑学的知识。 In mathematical logic and theoretical computer science, an abstract rewriting system (reduction system, abstract reduction system, abstract rewrite system, abbreviation ARS) is a formalism that captures the quintessential（精髓，精粹） notion and properties of rewriting systems. in its simplest form, an ARS is simply a set of “objects” together with a binary relation, traditionally denoted with \(\rightarrow\). this definition can be further refined if we index (label) subsets of the binary relation. Desipte its simplicity, an ARS is sufficient to describe important properties of rewriting systems link normal forms, termination, and various notions of confluence. ARS与LTS的定义就是特价的，只不过数学上关注的重点不太一样。假设\((A,\rightarrow)\)是一个ARS，那么数学上关心的是\(trans\)这个二元关系的传递闭包、反射闭包等。 ARS的定义可能引起人的混淆，因为有时候它就像是一个语法生成式，只不过，一个重写规则的左边与右边都是一个单独的对象，而不是不同的语法项。所以ARS中只有\(a\rightarrow b\)而没有\(a\rightarrow b c\)这样的形式。 下面我们介绍数学家对于ARS的研究兴趣。 reducible objects An object \(x\in A\) is called reducible in \((A,\rightarrow)\) if \(\exists y\in A\) such that \(x\rightarrow y\). otherwise it is called irreducible or a normal form. normal form Denoting that \(\overset{*}{\leftrightarrow}\) is the transitive closure of \(\leftrightarrow \cup =\), where \(\leftrightarrow\) is \(\leftarrow \cup \leftarrow^{-1}\), an object \(y\in A\) is called a normal form of \(x\) if \(x\overset{*}{\leftrightarrow} y\), where \(y\) is irreducible. If \(x\) has a unique normal form, then this is usually denoted with \(x\downarrow\). If every object has at least one normal form, the ARS is called normalizing. Word Problem Given \(x\) and \(y\in A\), are they equivalent under \(\overset{*}{\leftrightarrow}\) ? 接下来对于ARS，自然而然地引入所谓的Church-Rosser定理。因为\(\lambda\)演算具有这样的性质。不过，对于模型检查等应用来说，TS才是比较实用的工具。 下面我们就借助于TS来给bisimulation几种等价的，但是表述不同的定义 Relational definition of bisimulation Given a labelled transition system \((S, \Lambda, \rightarrow)\), a bisimulation is a binary relation \(R\) over \(S\) such that \(\forall \alpha \in \Lambda\), \[\begin{equation} R;\overset{\alpha}{\rightarrow} \subseteq \overset{\alpha}{\rightarrow};R \end{equation}\] and \[\begin{equation} R^{-1};\overset{\alpha}{\rightarrow} \subseteq \overset{\alpha}{\rightarrow};R^{-1} \end{equation}\] Fixpoint definition of bisimulation Given a labelled transition system \((S, \Lambda, \rightarrow)\), define \[\begin{equation} F: 2^{S\times S} \mapsto 2^{S\times S} \end{equation}\] to be a function from binary relations over \(S\) to binary relations over \(S\), as follows: let \(R\) be any binary relation over \(S\), \(F(R)\) is defined to be the set of all pairs \((p,q)\in S\times S\) such that \[\begin{equation} \forall \alpha\in\Lambda, p&#39;\in S, p\overset{\alpha}{\rightarrow} p&#39; \Rightarrow \exists q&#39; \in S, q\overset{q&#39;}{\rightarrow}, (p&#39;,q&#39;)\in R \end{equation}\] \[\begin{equation} \forall \alpha\in\Lambda, q&#39;\in S, q\overset{\alpha}{\rightarrow} q&#39; \Rightarrow \exists p&#39; \in S, p\overset{p&#39;}{\rightarrow}, (p&#39;,q&#39;)\in R \end{equation}\] Then, bisimilarity is defined to be the greatest fixed point of \(F\). 从博弈的角度也可以定义互模拟。另外，从余代数的角度的定义可能在理论上更坚实一些，因为余代数可以对共模拟的字义作出推广。因为TS的共模拟可以看成是共代数模拟的特殊的情况。因为TS可以给出编程语言的操作语义，所以LTS在编程语言中的设计当中也变得非常重要。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[信息几何简介]]></title>
      <url>%2Finformation-geometry%2F</url>
      <content type="text"><![CDATA[认识信息几何 信息几何的方法其实是将统计理论中的参数问题变成额外的一个空间，在这个空间上建立统计函数之间的距离，相当于仍然是使用测度的理论研究问题。这种方法自然对于参数的生成有重要的启示。启示我们为什么要选择这样的参数，这什么参数有这些形态。在扩大的空间当中，自然而然地可以非常方便地研究统计系统的重多的要素。在机器学习中也有更多的应用。 然而单纯起来看，并非信息是几何的，而是因为分布函数之间的距离就是可以度量的。这样的话，未必形成微分流形，甚至是更一般的内容也可以，比如离散分布与离散参数的问题。总而言之，关键在于考察“所有可能的参数所形成的空间”，而不是“某个参数下的分布”所起的作用吧。 信息几何有几种经典的方法。第一是基于流形上的Riemann度量的方法，第二种是基于\(\alpha\)联络与对偶几何的方法。还可以是基于曲率度量的方法，或者基于信息散度(divergence)的方法。散度在信息什么几何中充当距离函数，用来度量两个点之间的分离度或者差异，但散度不是严格意义上的距离函数。 信息几何的数学形式可以按照如下的思路构造。首先，给出参数分布族\(p(x,\theta)\)，其中\(\theta \in \Theta\)是参数，\(x\)是样本空间\(X\)中的随机变量，\(p(x;\theta)\)是\(x\)的概率密度函数。\(\theta\)是一个\(n\)维向量而\(\Theta\)是\(\RR^n\)的开集，\(\theta\)可以看成是流形\(S\)上面的坐标系，每点关联一个概率密度函数。然后定义 \[ g_{ij} = E[\partial_i \log p(x;\theta) \partial_j \log p(x;\theta)], i,j=1,2,\cdots,n \] 其中\(E\)表示概率密度\(p(x;\theta)\)的期望，\(\partial_i = \frac{\partial}{\partial \theta_i}\)。用Fisher信息矩阵\(g_{ij}\)表示黎曼度量。然后定义流形\(S\)上的一族联络\(\Delta^{(\alpha)}\)，称之为\(\alpha\)-联络，定义为： \[ \langle \Delta_A^{(\alpha)}B, C \rangle = E[(ABl)(Cl)] + \frac{1-\alpha}{2} E[(Al)(Bl)(Cl)],\] 其中\(A\)，\(B\)，\(C\)为流形\(S\)的三个向量场，\(ABl=A(Bl)\)，\(l=l(x;\theta)=\log p(x;\theta)\)，\(\alpha\)为实参数。\(\alpha\)-联络相比于黎曼联络有更广泛的适用条件。不过\(\alpha\)-联络不满足度量性。 在统计推断中，指数分布族占有极其重要的地位。从流形的观点看，指数分布族具有对偶平坦的何结构。特别地，正态分布族的函数的流形的高斯曲率是\(-1/2\)，因此是一个双曲面。 在信息几何中，两个非常重要的概念是散度和投量。信息几何在神经网络学习、热力学的流形、以及控制系统、Birkhoff系统、都有应用。 信息几何与统计学派 典型的信息几何是针对于参数分布族的。而统计推断的两大学派（频率学派与贝叶斯学派）的统计推断都常都是针对特定的参数的。信息几何只依赖于参数分布族的特点，使得信息几何不会受到两个学派关于概率的哲学本质的争论的问题。两种学派在具体怎样推断参数上面有一些区别。 经典统计只利用总体与样本的信息，而Bayesian统计还利用先验信息（集中在参数\(\theta\)的先验分布上）。经典学派的观点上，概率是大量独立重复实验下事件发生频率的稳定值，离开重复实验，概率就无从谈起。但是贝叶斯学派认为在无重复实验的条件下概率可以凭主观认识及以经验确定。 注：不过，度量不确定性有几种不同的方式，可以是概率，也可以是模糊。这样的话，关于不确定性的信息处理其实就有许多个不同的哲学出发点。 我们来看数学上的不同。在参数统计模型中通常含有未知参数\(\theta \in \Theta\)，其中\(\Theta\)是参数空间。在经典统计中，样本分布族通常以\(f(x;\theta)\)出发，对\(\theta\)进行统计推断（参数估计与假设检验等）。在经典统计中\(f(x;\theta)\)称为是似然函数。Bayesian统计保存了样本分布\(f(x;\theta)\)，但是解释有所不同。Bayesian统计认为\(\theta\)是取值于\(\Theta\)的随机变量，样本分布\(f(x;\theta)\)是给定某\(\theta\)的时候\(X\)的条件分布，因此可以记为\(f(x \vert \theta)\)。从数学上看，\(f(x \vert \theta)\)与\(f(x;\theta)\)都可以看成是\(x\)与\(\theta\)都在变化的时候的分布函数，也就是多元函数的形态，但是多元函数所满足的条件有所不同。这一点在概率论定义条件分布时候有所体现。 参数估计通常是点估计或者区间估计。两种不同的统计方法都有点估计和区间估计。从信息几何的观点来看，Bayes网络是一种特殊的概率分布族；因为引入了条件独立性而降低了流形的统合度，从而简化了统计流形上的Riemann度量矩阵。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World from the Hexo]]></title>
      <url>%2Fblog-hexo-1%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment Hexo的从入门到精通[12-15-2016 11:11:01 CST] 使用手册，http://www.tuicool.com/articles/Jva2iaA之类的。 插件开发所需要的知识，插件的体系结构http://blog.csdn.net/melordljm/article/details/51985157。 控制台 (Console) 部署器 (Deployer) 过滤器 (Filter) 生成器 (Generator) 迁移器 (Migrator) 处理器 (Processor) 渲染引擎 (Renderer) 标签 (Tag)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[守护进程的编写思路（C与Python）]]></title>
      <url>%2Fprogramming-daemon%2F</url>
      <content type="text"><![CDATA[参考http://www.netzmafia.de/skripten/unix/linux-daemon-howto.html。上面提到Linux守护进程应该做的基本的事情，守护进程主要包括了 从主程序中创建子进程 改变文件的umask任务 打开日志文件以记录日志 创建会话ID 将工作目录移动到一个安全的位置 关闭标准的文件描述符（守护进程不存在标准输入与输出的问题） 显然这是针对具体情况的需求建模的一部分。因为守护进程总是从系统中由一个脚本调用或者用户手动启动的。在启动的时候，守护进程和系统中其它的进程一样被对待。但是守护进程的目标要使得它能够独立于会话而存在。具体代码的执行还是由子进程完成的。在Linux当中，这是通过fork函数完成的。在守护进程的编写中，很大一部分代码全部是处理控制流的，特别是异常处理，这没有什么可问的：事实就是如此，我们也不得不面对。当然要接受这样的现实并写出大量异常处理的代码。编程的最本质的困难可能还是在于对于控制流的掌握把，至于具体的算法则是理论上的另外一方面的问题了。 进程成功创建子进程之后，父进程应该及时终止退出，然后由子进程执行任务。显然，这个时候子进程是沿着父进程的当前控制流继续执行的。接下来就是子进程的任务。 改变文件的掩码 为了能够写入由daemon所创建的文件，必须保持daemon在创建这些文件的时候有写入的权限。该权限是由umask来控制的，可以保证它们可以正确地读取或写入文件。umask可以在命令行当中运行，但是保险的方法还是通过编程接口。在linux系统中完成切换umask任务的是umask函数。设置umask为0可以对文件有完全的访问权限。 第三步是打开日志。但是该步骤是可选的。该可选的步骤可以导出许多有用的信息。 第四步是创建SID结构。目的是让这个进程的父进程去掉，成为一个orphan进程，以便不受到用户会话的影响。方法是创建一个SID。使用setsid函数。 pid_t pid, sid; /* Fork off the parent process */ pid = fork() if(pid &lt; 0) { exit(EXIT_FAILURE); } // fork process failed if(pid &gt; 0) { exit(EXIT_SUCCESS); } // succeed and exit parent process /* Change the file mode mask */ umask(0) /* Open any logs here */ /* Create a new SID for the child process */ sid = setsid(); if (sid &lt; 0) { exit(FAILURE); } // don&#39;t forget to enable your log 再一步是改变工作的目录。我们必须保证该目录存在。在按照FHS标准的系统中可以是/tmp的目录，但是保险的方法还是使用根目录作为当前的工作目录。使用chdir函数可以完成这样的任务。 if ( (chdir(&quot;/&quot;)) &lt; 0 ) { exit(EXIT_FAILURE); } // 失败返回-1 关闭标准文件描述符是最后的一步。这是因为守护进程根本就没有标准输入输出可以使用。使用的是close函数。如下： close(STDIN_FILENO); close(STDOUT_FILENO); close(STDERR_FILENO); 守护进程的执行逻辑 经过之上的步骤，终于算是符合了daemon的行为规范。接下来就需要写一系列的具体完成daemon的代码了。初始化守护进程中其中的第一步。常见的逻辑是： /* Daemon-specific initialization goes here */ /* The big loop */ while(1) { /* Do your task here */ sleep(30); } 也就是说，这个时候守护进程是一个循环的程序。 注意，日志一般应使用syslog的系统，使用syslog提供的机制。 使用Python写Linux的守护进程 现在更多地是使用脚本语言和面向对象的技术来完成基本任务的编写。所以接下来我们选择一个使用Python来写守护进程的一个脚本。参考http://blog.csdn.net/LikeHighTime/article/details/4602456}。原贴&lt;http://www.jejik.com/articles/2007/02/a_simple_unix_linux_daemon_in_python/。 其头部的关键是使用signal的库导入一些信号，并使用一些系统的头文件。之后则是创建一个Daemon的类。在该类中的初始化函数，daemonize化函数支撑函数的运行。 我们先来看Daemon的原型，用户的守护进程是从这个类继承过来的。 守护进程类原型有如下的几个重要的例子： init函数：该函数表示的是进入守护进程的时候的初始的设置。如下： def __init__(self, pidfile, stdin=&#39;/dev/null&#39;, stdout=&#39;/dev/null&#39;, stderr=&#39;/dev/null&#39;): self.stdin = stdin self.stdout = stdout self.stderr = stderr self.pidfile = pidfile daemonize函数，该函数用于执行UNIX的所谓的double-fork方法。该方法可见Stevens’ “Advanced Programming in the UNIX Environment” for details (ISBN 0201563177) http://www.erlenstar.demon.co.uk/unix/faq_2.html#SEC16。 def daemonize(self): try: pid = os.fork() if pid &gt; 0: # exit first parent sys.exit(0) except OSError, e: sys.stderr.write(&quot;fork #1 failed: %d (%s)/n&quot; % (e.errno, e.strerror)) sys.exit(1) # decouple from parent environment os.chdir(&quot;/&quot;) os.setsid() os.umask(0) # do second fork try: pid = os.fork() if pid &gt; 0: # exit from second parent sys.exit(0) except OSError, e: sys.stderr.write(&quot;fork #2 failed: %d (%s)/n&quot; % (e.errno, e.strerror)) sys.exit(1) # redirect standard file descriptors sys.stdout.flush() sys.stderr.flush() si = file(self.stdin, &#39;r&#39;) so = file(self.stdout, &#39;a+&#39;) se = file(self.stderr, &#39;a+&#39;, 0) os.dup2(si.fileno(), sys.stdin.fileno()) os.dup2(so.fileno(), sys.stdout.fileno()) os.dup2(se.fileno(), sys.stderr.fileno()) # write pidfile atexit.register(self.delpid) pid = str(os.getpid()) file(self.pidfile,&#39;w+&#39;).write(&quot;%s/n&quot; % pid) 该方法完成的就是之前的C语言的大部分的内容了。 之后是管理PID文件 def delpid(self): os.remove(self.pidfile) 开始进程函数start完成开启进程，让进程运行的任务。该函数检查相应的PID文件是否存在，存在表示进程已经在运行，所以就退出 def start(self): &quot;&quot;&quot; Start the daemon &quot;&quot;&quot; # Check for a pidfile to see if the daemon already runs try: pf = file(self.pidfile,&#39;r&#39;) pid = int(pf.read().strip()) pf.close() except IOError: pid = None if pid: message = &quot;pidfile %s already exist. Daemon already running?/n&quot; sys.stderr.write(message % self.pidfile) sys.exit(1) # Start the daemon self.daemonize() self.run() 停止函数是这样的： def stop(self): &quot;&quot;&quot; Stop the daemon &quot;&quot;&quot; # Get the pid from the pidfile try: pf = file(self.pidfile,&#39;r&#39;) pid = int(pf.read().strip()) pf.close() except IOError: pid = None if not pid: message = &quot;pidfile %s does not exist. Daemon not running?/n&quot; sys.stderr.write(message % self.pidfile) return # not an error in a restart # Try killing the daemon process try: while 1: os.kill(pid, SIGTERM) time.sleep(0.1) except OSError, err: err = str(err) if err.find(&quot;No such process&quot;) &gt; 0: if os.path.exists(self.pidfile): os.remove(self.pidfile) else: print str(err) sys.exit(1) 接下来可以类似地定义restart与run函数。在写用户自己的进程的时候，用户需要手动写自己的run函数。重载之后就可以了。注意守护进程是有自己的特定的PID文件的。一般是放在/tmp目录。但是也有一些系统进程。至于在运行的时候切换到其它的进程，则可以通过一些库来完成。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scheme语言概要]]></title>
      <url>%2Fscheme-lang%2F</url>
      <content type="text"><![CDATA[在人工智能语言中我们应该接触过Scheme。根据介绍，Scheme和CommonLisp是两种主要的Lisp方言之一，也就是说，在讲Lisp语言的时候，我们也包括了讲Lisp或者CommonLisp语言。Scheme语言的地位是由一系列的Lambda论文决定的。见https://en.wikipedia.org/wiki/History_of_the_Scheme_programming_language#The_Lambda_Papers。Scheme的后缀扩展名是.scm或者.ss。Scheme是动态强类型的语言，具有词法作用域，当然是函数式语言。此外，Scheme的特点是它是第一个实现了头等延续的语言（这里的延续指的是计算机程序的控制状态，头等延续指的是可以创建，保存、赋值程序的状态给一个变量，并根据需要恢复程序的运行上下文）。对于延续的介绍可见https://en.wikipedia.org/wiki/Continuation。 Scheme对于CommonLisp的设计产生了重要的影响。Scheme的开发其实是基于实现当时的Actor并发模型的思想。Scheme的最新标准是R7RS，制定于2013年。 描述Scheme的最佳的方式或许是这样的。首先，Scheme的语法风格来自于简洁的S-表达式。然后数据结构是基于表处理的，刚开始的时候我们会看到很多的表处理的模式（如果有可能的话，我们也可以在其它的编程语言中模仿它），这种表处理的模式导致了我们很容易在运行的时候动态地创建Scheme代码。另外就是，它支持头等函数。虽然声称Lisp是函数式语言，但是其实Lisp的基本思想其实并不是高阶函数，而是所谓的抽象重写系统。另外的特点，就是对于\(\lambda\)-演算和词法作用域的支持了。 语言核心中比较强大的应该是Scheme与Lisp语言中的Hygienic macro，也就是所谓的干净的宏了。这里的干净是指宏的名词不会引起词法作用域的冲突。最早的关于干净的宏的文章见于Kohlbecker在1986年的文章《Hygienic Macro Expansion》。现在看来，TeX系统中用的宏与Lisp语言中的差不多。它们都是词法意义上的，虽然行为上与惰性求值类似，但是其实不是一回事。使用宏的系统更像是基于规则的系统。Perl6与Julia语言也实现了像Lisp那样的宏。Elixir与Dylan语言中也可以。看来，我们得认真地对待Lisp的宏了。 对GNU Guiler的介绍[09-01-2015 09:59:38 CST] GNU Guile是GNU的一个Scheme语言的实现。我们知道，一个程序设计语言可以使用不同的后端。比如JBC(Java Bytecode)可以由Scheme、Python等语言的前端来生成。Guile最早的版本是在1993年发布的。相对于Scheme规范添加了许多的模块化扩展。 guile提供了libguile，用于支持将语言嵌入到其它的语言中（通过C API）。另外，使用C语言开发的许多的程序同时也可以移植到guile中。因为语言本身就是与后端的实现没有关系的。而在前端中嵌入代码又是十分正常的。guile语言的全名是GNU Ubiquitous Intelligent Language for Extensions。也就是说，本来的设计就是为了扩展的。实际上，该语言也被嵌入在GnuCash与Lilypond等语言中。 Guile系统实现的是所谓的R5RS，同时具有大部分的R6RS中的功能特性。SRFI的功能特性也具有一些。更多的是自己的扩充。目前有种将Emacs的脚本语言换成Scheme的计划。也许之后我们就可以比较自如地进行Scheme上面的Emacs编程了。 目前的几个Scheme实现，大多也是实现了R6RS，对于R7RS的支持都比较有限。所以我们目前还是以R6RS的标准为根据。下面我们打算介绍一下这个标准。R6RS有几个相关的标准，不只是核心语言，也包括一些库。但是Scheme的标准是出了名的精简。即使我们花时间全部读完成是值得的。 Scheme规范R6RS 导引的部分是这样的，首先Scheme实现了一等过程。也就是说，过程就像一个真正的值一样。注意，Scheme不是纯函数式的语言，所以它的函数解释为过程也非常自然。说是一等过程而不是一等函数还是比较自然一些。Scheme was one of the first programming language to incorporate first-class procedures as in the lambda calculusd, there by proving the usefulness of static scope rules and block structure in a dynamically typed language. 接下来我们要解释一下宏的概念。其实在函数的定义中，就是惰性的。求值发生在函数调用的时候。但是对于宏而言，其实是按名求值。在调用宏的时候，是把宏体做一个展开。TeX语言也是这样的一种模式。其实宏大概只是一种符号计算的方式而已。使用宏带来的一个明显的好处是我们可以方便地操纵程序语言的代码。 对Scheme语言的基本的描述 R6RS的第一节介绍的是其语义。也就是说，把词法与语法甚至放到无关紧要的位置。首先是按照Algol的语言特征，Scheme实现的是静态作用域。使用变量的时候，变量关联到的时在词法上与该变量相绑定的位置。 Scheme的类型是属于“manifest types”。也就是说，类型是与对象（或者称为值）绑定的，而不是变量。具有类型的是特定的值而不说变量属于某个类型。所以经常有人说Scheme是弱类型的语言甚至说它是无类型的语言。其实Python、Ruby、Smalltalk也是属于manifest types。与Scheme不同的是Haskell、Java、ML等强类型的语言。 所以这给我们提了一个醒，最好不要单纯地使用无类型与有类型来描述编程语言，也不使用强类型与弱类型来描述程序设计语言。最清晰的方法是使用宣告式类型或者隐式类型。其实类型化有一些专门的术语的，参考&lt;https://en.wikipedia.org/wiki/Manifest_typing&gt;我们可以知道manifest typing、latent typing、implicit typing、dynamic typing、subtyping等。 Scheme有自己的废料收集机制，所以所涉及的对象也不用在语言中显式地销毁。看过《编程原本》之后我们应当知道对象、实体、类型、值的区别。这里的Object的含义应该是跟C++中的是一样的。也就是说，对象是对占据特定存储的那种事物的抽象。在这一点上，Scheme与Python、Haskell、Java都是相同的。 另一个特点是过程作为一等对象。过程可以动态地创建，并且保存在特定的数据结构中。这一点与Haskell、ML、Ruby、Smalltalk都是相同的。也就是说动态创建过程的能力与它们是相同的。 Scheme特有的概念是所谓的一等延续。也就是特定的程序上下文可以保存下来。在执行过程调用之前，过程的参数会被积极求值。也就是说如果我们把一个表达式作为参数传递给了一个过程，那么是把这个表达式的结果传递给这个过程。C、Python、Ruby在内的多种语言都使用这种求值机制。Haskell与R语言是按需调用。也就是说是否对传入的表达式求值由子过程来决定。 Scheme的对象与值 Scheme的对象与值被组织成类型（而变量没有类型）。基本的类型有布尔型、数值、字符串、字符、符号、列表、数对等。使用#f和#t分别表示True和False。 之前我们读到过Scheme的设计原理。在数据类型中，Pair是最基本的元素。甚至List都是由Pair构成的。知道\(\lambda\)-演算的人都知道组合子，也就知道如何用组合子来表示真与假。 Scheme的表达式 表达式是Scheme的最重要的组成元素了。表达式求值之后得到一个value。其实表达式可以建模成一种抽象数据类型的。比如，表示值的那些字符串是一个表达式，对它们求值得到一个值；表达式可以有子表达式等。Scheme的表达式采用前缀记法。 在语法上，换行符并不会影响表达式的解析。这主要是为了编程的考虑。 变量、绑定、定义、过程 let用于声明一个局部的变量的过程。如 (let ( (x 23) (y 42) ) (+ x y)) 上面的表达式中，let的第一个参数是对于符号的定义的列表，第二项是相应的表达式。结果是按照赋的值求解第二个表达式。注意这里的变量是局部定义的。 如果要让变量的定义超过当前的作用域，需要使用define。define是一个定义而不是一个表达式，因为它不返回任何的值，并且只能在程序的顶层出现。 (define x 23) (define y 42) (+ x y) 在一个嵌套的环境中内层的符号与哪个值绑定当然是按照最邻近的原则。另外，按照词法作用域的准则。求值的结果是依赖于定义的环境而不是被调用的环境。 过程也使用define来定义。 (define (f x) (+ x 42)) (f 23) 在定义的时候，函数及其参数作为第二个参数，而后面定义的是函数的体。过程是与特定的对象有关的表达式的抽象。由于后面的体可以看成是一个宏体，所以我们可以非常方便地定义高阶函数： (define (apply_binop binop first second) (binop first second)) Scheme中虽然广泛采用了模式匹配。但是有些情况下的模式匹配仍然是会失败的，比如如下的代码： (* 失败的代码*) (define (apply_binop binop (first second)) (binop first second)) lambda表达式用于创建新的过程，过程中还可以包含闭包 ((lambda (x) (+ x 42)) 23) 上面的表达式都是过程调用，但是let与lambda开头的却不是过程调用。这是因为let与lambda并不是函数名称，而是Scheme语言的关键字。define也同样是如此。关键字后面跟的参数遵守怎样的规则是Scheme语言定义的。 宏与模式匹配 在Scheme中，宏是声明具有特定的模式的参数的方法。借助于宏我们可以实现与lambda、define一样的效果。定义宏使用的是define-syntax语句。 (define-syntax def (syntax-rules () ((def f (p ...) body) (define (f p ...) body)))) (def f (x) (+ x 42)) 上面的语法将使def成为一个具有和define相同的效果的关键字。上面的语句的理解方式是，define-syntex定义了一个语法糖def，这个语法糖的使用规则由syntax-rules语句来声明。syntex-rules指出，这个语法糖模式匹配(def f (p ...) body)。匹配到这个语法的时候，执行的动作是上面的define。 1.10引用与阻止求值 在介绍这一节的时候，感觉使用'表示阻止求值这种理解方式非常怪异。显得没有必要。但是其实把Scheme当成是一种自然语言就好了。这里的阻止求值其实就相当于自然语言中的引号。我们参考Quasi-quotation就知道了。既然它们是引号，自然里面的东西就不会再发生改变了。 &#39;23 (quote 23) 在通常语言里，括号里面的东西就是字符串。但是在Scheme中，括号里面的东西仍然是保持Scheme语言里面的结构的。所以虽然说是一种引用，但是括号里面的东西不是一堆字符串，而是Scheme中的语法结构。 1.12库机制与顶层调用 Scheme中的库使用library关键字。库里面的内容可以主动导出与主动导入。 (library (hello) (export hello-world) (import (rnrs base) (rnrs io simple)) (define (hello-world) (display &quot;Hello World&quot;) (newline))) Scheme的顶层程序第一行可以加一个Shell命令。以#!开头。 Scheme中的词法 在Scheme中语法定义是非常简单的。大约只有一页多。如 (define 加 +) (加 1 2) (define 真 #t) (define 假 #f) (define 非 not) (非 真) 这样可以把scheme真接改造成一个中文编程环境。我们需要注意的，是Scheme中的quote与quasi-quote的机制。因为这一机制在其它的语言中很少见（或者说不常见）。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Maude语言]]></title>
      <url>%2Fmaude-lang%2F</url>
      <content type="text"><![CDATA[Maude是一个使用重写逻辑的语言，由SRI开发。Maude的Rewritting Logic是对Equational Logic的一个扩展。Maude非常强调元编程的概念。Maude也可以看成是一种逻辑编程语言、Logic Programming Language、Extensible syntax Programming Language、Term-rewriting programming Language。 Maude语言和Mathematica是类似的，但是也许比Mathematica在语言的表现力方面上更强大。本身的计算也是基于模式的匹配，当然是非常自然的。这种项重写跟Mathematica的原理是类似的。 高级的编程语言大概都能应用于软件规约，以及逻辑编程语言也可以。Maude有一系列的模型检查的库，这可能是它具有优越性的地方http://maude.cs.illinois.edu/w/index.php?title=Maude_Tools。 Maude更强调的是元编程，元编程有多条路线，而Maude的元编程是通过反射实现的。所谓的反射，就是在运行的时候能够检查和修改程序的行为与结构。这其实是应用程序在运行的时候能够探查程序的结构的能力。 Java的反射是这样的： Object foo = Class.forName(&quot;complete.classpath.and.Foo&quot;).newInstance() Method m = foo.getClass().getDeclaredMethod(&quot;hello&quot;,new Class&lt;?&gt;[0]); m.invoke(foo); 其中的第一句是反射一个对象（通过字符串来找到一个类），而第二句是通过字符串查找一个方法，以及通过对象查找类的名子。很多语言都支持反射。虽然很多功能也可以不通过使用反射的方法来完成。反射的实现得依赖于特殊的函数。比如Python中， class_name = &quot;Foo&quot; method = &quot;hello&quot; obj = globals()[class_name]() getattr(obj, method)() eval(&quot;Foo().hello()&quot;) 其中第三句话是根据类名字符串查找这个类并新建一个这个类的对象，而第四句是从这个对象中找到名为hello的方法。最后一个是直接把字符串当成是程序代码执行。 R软件等也支持反射。反射的几个例子可见https://en.wikipedia.org/wiki/Reflection_%28computer_programming%29。可能在使用反射的时候，最大的问题在于完全破坏之前存在的编程模式，通过直接操纵编译器运行时系统的方法来编程。这样的话，虽然功能十分强大，但是又好像太过灵活。反射与Self-modifying code、self-hosting这些术语都有比较近的关系。 这里需要说明的是，虽然应用程序员接触得不多，但是支持反射的语言有一大堆，包括APL、Io、Java（通过java.lang.reflect包）、Lisp、Mathematica、C#、Maude、Python、R、POP-11、Ruby、Scheme等。也有上百种之多了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala编程概要（三）：进程控制与shell，函数式特性]]></title>
      <url>%2Fscala-process-and-shell%2F</url>
      <content type="text"><![CDATA[应该说，这种特性是可以让人大吼大叫的。简单的示例如下： import sys.process._ &quot;ls -al ..&quot; ! 之所以可以这样做，是因为sys.process包含一个从字符串到ProcessBuild对象的隐式类型转换。注意后面的!号操作符，以ProcessBuild类型为参数类型，返回的是被执行程序的返回值。如果需要返回的是程序的输出的字符串，可以使用!!代替!号。 如果需要把程序通过管道，scala支持使用#|运算符。比如： &quot;ls -al ..&quot; #| &quot;grep sec&quot; ! 这样显然具有优势，因为让scala可以编译检查程序的结构。除此之外，scala的运算符还有重定向#&gt;、#&gt;&gt;，#&lt;等。如下面的示例： import sys.process._ &quot;ls -al ..&quot; #&gt;&gt; new File(&quot;output.txt&quot;) ! &quot;grep Scala&quot; #&lt; new URL(&quot;http://horstmann.com/index.html&quot;) 这种特性确实是不错，貌似比Shell还要更强大一些。 注意!表示返回的结果，是一个整型的值而已。另外，Scala中的流程控制语句有p #&amp;&amp; q表示p成功则执行q，p #|| q表示p不成功则执行q。（一个规则是，相对于原来的shell操作符，我们只需要在前面加上一个#号就是scala脚本的操作符，而且与原来的shell操作符具有相同的优先级。 至于正规的方法，则是构造相应的Process对象，然后使用!操作符执行它。比如 val p = Process(cmd, new File(dirName), (&quot;LANG&quot;, &quot;en_US&quot;)) &quot;echo 41&quot; #| p ! 有兴趣的话，可以参考一下。因为scala提供了一个快速构建器fsc，所以shell的执行的速度也不是问题。 Scala中的正则表达式 正则表达式分析使用scala.util.matching.Regex类。在scala中，可以使用&quot;&quot;&quot;...&quot;&quot;&quot;作为原始的字符串，里面的符号不进行转义（与Python还有一些不同）。 val numPattern = &quot;[0-9]+&quot;.r /* 构造正则表达式对象，使用字符串的.r方法 * 该方法是在scala.util.matching.Regex中定义 */ val wsnumwsPattern = &quot;&quot;&quot;\s+[0-9]+\s+&quot;&quot;&quot;.r //然后使用findAllIn, findFirstIn等方法来匹配字符串 val m1 = wsnumwsPattern.findFirstIn(&quot;99 bottles, 98 bottles&quot;) //或者使用replace来替换字符串 val m2 = num.replaceFirstIn(&quot;99 bottles, 98 bottles&quot;, &quot;xx&quot;) 为了使正则表达式有提取的功能，可以使用PCRE中的字符串分组。比如 val numitemPattern = &quot;([0-9]+) ([a-z]+)&quot;.r val numitemPattern(num, item) = &quot;99 bottles&quot; num == &quot;99&quot; item == &quot;bottles&quot; 这样，编程实践中的系统调用接口、正则表达式，文件IO、XML我们就都已经提到了。 Scala中的特质 相当于java中的interface，但是进行了一些哲学的修正。比如使用with，表示的含义是“一个类与其它的特质运算，得到新的类，然后由某个类来继承它”。 但是在scala中，特质可以包含具体的实现的方法。java的接口是不能做到这一点的。但是求是地看，让特质具有具体的行为之后，如果特质发生了改变，所有的混入了该特质的类都必须重新编译。 特质在处理日志、异常处理的时候也占有一席之地，甚至还是一种不错的解决办法。另外一种解决日志与异常处理的任务的方法是使用高阶函数。虽然直观上，显然高阶方法与注解器更为高级（其中高阶函数更高级）。由此我们大概可以抽象出异常处理的几种编程的模式，或者甚至是理论。 如果想要使用特质来处理日志与异常处理，那么就需要仔细阅读Scala中有关特质、特质扩展类、自身类型（self type）的一些知识点。 Scal中的操作符[07-02-2015 10:26:53] 摘自《快学Scala》中的教程。对于Haskell之类的操作语言，理解操作符的使用是很自然的事情。因为在这样的语言中，计算被移到语言的更后端的层次，而在C语言一类的命令式语言中，操作符被当成是编译器语法的一部分，直接写在语言里。显然是后者更好。但是这两种方式的不同，也给学习新的语言造成了一些障碍。 Scala中的操作符的使用与语法的解析是没有关系的。我们参考Scala的语法的手册就可以知道。所以操作符的使用带来了比较大的灵活性。 Scala中的标识符与操作符的重载是实现内置领域特定语言的一个重要的方式。前面我们提到了sys.process._也可以看成是DSL的一类。 在Scala中，命名采取统一的规则，变量，函数、类的名称都统称为标识符。编译器不再对标识符作进一步的语法使用上的区分。在Scala中，选择标识符是比较自由的。还可以使用unicode，或者其它的非空白符。 在Scala中，可以作为操作符的字符是相当多了，除了一些语法上的禁忌之外。比如三种括号已经有特定的含义了，我们不能重载为操作符。但是苦寒经的ASCII字符与Unicode的数学符号都可以作为操作符（注意不是所有的Unicode符号，只有Unicode的数学符号这一类）。 另外，Scala使用左单引号括起来的部分作为一个单独的标识符（就像latex的\csname ... \endcsname一样。这使得在单引号里面，几乎所有的字符都可以当成是标识符。 在Scala中，任何一个带有两个参数的方法都可以写成是a 标识符 b的形式。Scala也知道这是一个二元方法调用。要注意的是，中间的方法必须以a.method(b)的形式声明。所以a op b表示op是a的一个方法，这个方法的参数是b。 另外，由于操作符也可以使用-&gt;这样的名子，所以就实现了操作符的方法调用。 类似于二元操作符的是后置的操作符，后置的操作符实际上是一个类的无类的方法。比如1 toString。这两种约定是自然的语法糖特性，没有什么特殊的。 值得注意的是对于前置一元操作符的处理。前置的一元的操作符实际上调用的是相应的unary_op方法。比如-a实际上调用的是a.unary_-方法。在操作符中，有些以=号结尾的操作符具有特定的赋值的含义，所以我们不应该在操作符中使用=号，除非我们在语义上有赋值区需求。当然，我们实际上可以自定义具有=号的操作符，scala也会认识相应的方法。但是一般而言，还是尽可能保持等号的特殊的含义。 在Scala当中，操作符的优先级是预定义好的，由操作符的首字母来决定，有些语言，如OCaml当中，操作符的优先级的次序是我们可以自己指定的。但是这种方法在Scala中不适用。除了赋值操作符之外，Scala的优先级由操作符的首字母来决定。也就是按照各个字符的列表来确定操作符。操作符有三类，中置操作符、后置操作符，前置操作符。统一的规定是，中置操作符优先级高于后置的。 在具有相同的优先级的时候，操作符的结合性才发挥作用。在Scala中，用户定义的所有的操作符都是左结合的操作符（大多数代数运算均如此）。而在内置语言中，以冒号结尾的操作符以及赋值操作符是右结合的。这样，自然而然地，构造列表的::操作符是右结合的。 对于右结合的二元操作符a rop b，调用的方法是b.rop(a)。即方法属于后一个类，不是属于前一个类。 函数调用方法扩展 语法特性f(arg1, arg2, ...)不只是用于直接定义的函数的调用与语法。它们也可以用于函数之外的值。除了函数与方法调用之外，这种形式的语法还被当成是f.apply(arg1,arg2)的语法糖。而f(arg1, arg2, ...) = value这种形式，还对应于如下调用f.update(arg1, arg2, ..., value)。即这种语法是一个语法糖。Scala在遇到这样的符号的时候会自动查询函数调用、方法调用，以及apply方法。 为什么需要使用apply方法？答案是，在Java当中，创建新的对象都要使用new方法。但是这种方法对于不变对象而言是非常不好的。所以，一般而言，都在类的伴生对象中定义一个apply方法，这个apply方法的实现是new ClassName(args)这样的形式。（这样可以直接使用ClassName(args)来构造一个类的对象。（另外，实例类也具有类似的效果）。使用apply方法来构造一个对象，可以看成是Scala的一个设计模式。 unapply方法，看起来很违背常识。但是在编程语言的世界中，尤其是函数式语言的世界中，一个apply方法就是一个把参数变成对象的一个映射（其实是附带算子的），所以，自然而然地，我们考虑参数的逆映射，也就是把一个对象分解成构造它的时候的参数。unapply方法在模式匹配的时候特别有用。比如，我们要匹配对象Fraction(a,b)的时候，必然需要从对象中找到a和b的值。这个时候就需要unapply方法（从而我们知道，模式匹配并不是什么神奇的东西，本质上就是一个方法调用，这个方法调用把一个类变成相应的值）。当然，模式匹配不仅要从对象中解出来值，还要检查对象的类型。但是至少从对象中提取出来值这部分，是通过unapply方法完成的。 注：这里我们对模式匹配要做的工作有了进一步的认识。但是同时要指出，模式匹配的时候，还是要处理额外的一些问题，比如模式匹配如果失败了怎么办？一般而言，这需要一种处理不确定性的方法。比如，返回的值可能是Maybe(3,4)这样的形式（在Scala中，是Some((3,4))这样的形式）。 注：Scala的实例类case class自动地生成apply与unapply方法。实际上，Scala的unapply还被用于实现其它的许多的功能。比如说，赋值语句的模式匹配，如val Number(n) = &quot;1729&quot;，可以把整数1729的值赋给n。等等。详细可以参考《快学Scala》当中的第十一章操作符的最后一节。 注：使用提取符实际上已经可以构造一个表格的DSL，就像LaTeX那样。所以也许我们该来试验一下。比如在表格里面通过运算符重新构造出HTML或者LaTeX格式的表格。 下面是自己写的一个测试用例，允许用户使用Table() | &quot;abc&quot;这样的形式构造表格。 class Table(var elem : String) { def |(element : String) = new Table(elem + &quot;&amp;&quot; + element) def ||(element: String) = new Table(elem + &quot;\n&quot;+element) } object Table { def apply(e:String) = new Table(e) def unapply(input: Table): Option[String] = Some(input.elem) } var t = Table(&quot;abc&quot;) | &quot;String&quot; println(t.elem) t match { case Table(e) =&gt; println(&quot;Succeed: &quot; +e) case _ =&gt; println(&quot;failed&quot;) } 注意，第一点是把伴生对象中定义apply与unapply方法。第二是unapply的返回类型是Option[TYPE]，而且返回的值要用Some(VALUE)代替。这样才能得到正确的值。自己是尝试写这样的代码，肯定还有一些缺陷。等以后再来写一个完整的表格分析工具。 总结：本小节尝试的是操作符与模式匹配的构建。 高阶函数的使用 其实是这一种思维方式的训练。函数式语言编程中广泛使用这些方法。具体来说的模式有：把函数作为值来返回；需要的时候直接定义一个表达式作为函数；以及使用通配符来实行柯里化；函数式语言的控制抽象等。其中有一些课题明显是所有的高级语言的共性，比如说控制抽象。 Scala的高阶函数的机制引入了类型推导的概念。不然我们在构造高阶函数的时候，将写出大量的类型声明代码。 匿名函数的语法是(x : Doube) =&gt; 3 * x。注意使用=&gt;来表示计算（因为不同的语言实现\(\lambda\)-函数的方式都有所不同。可以把这个函数赋给一个变量。变量自然是有类型的。如果有可能，我们还可以让一个变量指向不同的函数。 高阶函数在编程语言中，往往被看成是轻量级的函数。第一个是作用域可以非常局部，比如说，直接在map的参数当中生成，第二是其意义往往只有一次，比如说，让一个数组增加三倍，并不值得先单独写一个乘以3的函数，然后慢慢传过去。 注意在语法上Array(3,4).map((x:Double) =&gt; 3 * x)的效果，可以用Array(3,4).map{ (x: Double) =&gt; 3 * x}以及Array(3,4) map { (x:Double) =&gt; 3 * x}来代替。至少使用大括号使得层次更加明显。另外，其实这里的(x:Double) =&gt; 3 * x可以换成更简单的3*_这个匿名函数。 在数值计算中，高阶函数的使用也有一些意义。比如我们有一组函数，需要求出一组函数在某个点处的值。这个时候使用map当然是最直观的。但是使用 val valueAt = (f: (Double) =&gt; Double, x : Double) =&gt; f(x) valueAt(3.0+_, 1.0) 这样的形式显然更为简单。 注：上式中我们还了解了多参数的匿名函数的语法，以及把函数作为参数的用法。如果有可能，我们还可以写出f at 1.0这样的中缀的形式。是否是很吸引人呢？ 常见的高阶函数 很多的高阶函数都应用的集合类型上面。常见的有map、foreach、filter、reduceLeft等。这里在处理数据的时候我们再来了解。 《快学Scala》的作者还提到了闭包。不过，闭包是任何的编程语言的结构体的共同的特性。本质是如果变量没有在这个过程体中定义，或者是在调用的上下文中并没有原来的变量的值的时候，在过程体中的变量的值该如何绑定。比如说，定义函数 def scale(x) : x*factor 当中，实际上factor没有出现在函数体中。那么factor一般是一个外部变量。但是关键的是，如果编译器遇到它的时候，在要执行scale的时候，factor该怎样取得值呢？这种问题就是所谓的闭包。 当然，在scala的匿名函数完成是可以使用闭包的。调用的时候，闭包内的变量被绑定到调用的时候的作用域所确定的同名子的变量。这也是闭包的标准的使用策略。基本上任何语言都是这样。 闭包应该属于编程理论中的“名子，作用域”中讨论的一个概念。它并非是函数式语言所特有的。但是在函数式语言中，闭包的使用更加重要。 沟通函数式语言与命令式语言的编程任务 我们在函数式语言中，知道函数可以像变量一样赋值，这样可以完成非常强大的任务。但是对于那些函数式不是一等公民的语言中，怎么样才能完成同样的任务呢？ 非面向对象的语言有自己的方法。比如C语言可以通过指针把函数传递过去。但是考虑到封装的要求，这样也许不是一个好的办法（虽然C语言也支持源文件级别的封装等。 面向对象的语言的通行的做法，根据《快学Scala》中的介绍，是这样的，为了把一个函数参数传给另外一个函数或者对象，我们得把相关的动作方法放在一个实现某个接口的类当中，然后将该类的一个实例传递给另一个方法。当然，这种方法与函数式语言通用性相比还存在一些缺陷。比如在Java中，类是由编译期确定的，所以我们不能在运行期创建新的函数。仅仅为了封装单个方法而设计的接口我们称为是SAM（single abstract method）类型。（这也是Java程序员的叫法）。 在事件驱动与GUI上面，比如为了使按钮在被点击的时候递增一个计数器，我们使用： var counter = 0 val button = new JButton(&quot;Increment&quot;) button.addActionListener(new ActionListener { override def actionPerformed(event: ActionEvent){ counter += 1 } }) 这当然是一段比较长的代码。而且非常冗余。因为我们只是要让计数器加一这个函数传递过去而已。一个比较合理的做法是这样的： button.addActionListener((event : ActionEvent) =&gt; counter +=1) 我们注意到，面向对象的语言中，很少提到动态创建那些有新的方法的未知的类。动态类型的语言中能够做到这一点，自编译的语言也可以。但是似乎面向对象的实践中从来没有认真考虑过在运行的时候创建具有新的方法与成员的类。 在上面的转换代码中还应当注意，在函数式语言中添加一个函数是完全没有问题的。但是Scala有自己的情况：要使得代码能够与Java代码互操作。所以，在Scala中，为了启用上面的语法，还是需要提供一个隐式类型转换函数。示例如下： implicit def makeAction(action: (ActionEvent)=&gt; Unit) = new ActionListener { override def actionPerformed(event: ActionEvent) { action(event) } 这样做的实际结果，还是使得在函数式的代码在编译的时候，被转换成一个新的类。（不过，这个类似乎是在可以运行的时候动态创建的）。 柯里化函数 在Haskell语言中，所有的函数都是自动柯里化的。Scala是函数式的语言，自然应当提供对于柯里化支持。在Scala中，柯里化的函数有自己的定义的语法，比如： def mul(x: Int)(y:Int) = x*y 柯里化函数式多个参量的函数的互换也经常使用（柯里化与反柯里化）。在一些需要传递高阶函数的地方，经常需要从已有的函数构造柯里化函数。如前所说，我们已经使用_来构造柯里化函数了。 至于Scala中有没有反柯里化，自己现在不太清楚。但是原则上，Scala应该禀承函数式语言的一贯的思维，认为多参数的函数根本不是编程语言中什么根本性的特质。我们完全可以把多参数的函数看成是一个单参数的函数的多次应用，正如我们在数学当中看到的那样。只提供多参数的函数的参数的一部分，是非常自然的数学思维，也应该成为编程的一种思维。 《快学Scala》中给出了一个常见的编程的实践：我们想测试两个序列在给定的某个对比的条件下是否是相同的。这里使用的是corresponds函数。使用示例是一个判断字符串序列在忽略大小写的意义下是否是等同的。 val a = Array(&quot;hello&quot;, &quot;world&quot;) val b = Array(&quot;Hello&quot;, &quot;World&quot;) a.corresponds(b)(_.equalsIgnoreCase(_)) 分析这个编程任务，我们知道，本质上还是两个对象之间的比较，所以应该有一个二元的函数。但是我们又需要在某个标准下面才能得到结果。因此，二元运算不是得到true或者false，而是还得接受一个提供判别标准的函数。所以，corresonds的类型是： def corresponds[B] (that: Seq[B]) (p:(A,B) =&gt; Boolean) : Boolean 定义了这样的一个柯里化的函数，这种设计既保持了语义的自然，实现起来也比较简洁。但是注意，这里的corresponds是Array[B]类别中预定义的函数，所以使用a op b这样的形式是没有问题的。但是，如果我们想使两个Double型的变量具有a add b这样的调用形式，那么原则上我们要为Double类添加一个add方法，但是这可能又要修改Scala的库，所以可能是不能实现的。（因为要保持这个类，同时又能为类单独添加新的方法，似乎是一种矛盾）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala编程概要（四）：控制抽象, 集合, 模式匹配, 编译器]]></title>
      <url>%2Fscala-overview-4%2F</url>
      <content type="text"><![CDATA[Scala的控制抽象 Haskell有自己的抽制抽象。使用的是单体。但是在Scala中，没有必要做得那么纯函数式。所以为了调用控制流，Scala使用了() =&gt; Unit类型。比如说，我们要在某个线程当中创建一个过程： runInThread() { () =&gt; println(&quot;Hi&quot;); Thread.sleep(1000); println(&quot;Bye&quot;) } 其中定义的runInThead函数是： def runInThread( block : () =&gt; Unit) { new Thread { override def run() { block() } }.start() } 注意，由于可以使用大括号代替小括号，所以我们能够看到，调用runInThread，就好像是在过程体中写出一系列的函数一样。 实现runInThread的更简洁的形式，应该是这样的： runInThread { println(&quot;Hi&quot;) Thread.sleep(10000) println(&quot;Bye&quot;) } 相对于上面的带有明显的高阶函数构造过程的实现，只有一点困难，就是我们如何省略掉() =&gt;。Scala实际上鼓励后者的这种方式，称为是换名调用。为了实现上述调用代码，对runInThread的定义变成： def runInThread(block : =&gt; Unit) { new Thread { override def run() { block } }.start() } 显然，定义的时候省略了参数()就可以做到。这样的话，可以构造出很多类似于控制流的语句。这样以来，看起来我们可以定义很多自己的控制流，比如do..until，runInAnotherMachine {}这样的控制语句。带参数的控制流当然也是可以定义的，因为我们可以与柯里化的函数结合使用。实际上，scala的if语句就是通过这里实现的。 until的实现见如下的代码： def until(condition : =&gt; Boolean) (block: =&gt; Unit) { if (!condition) { block until(condition) (block) } } 在上面的代码中，除了柯里化函数定义外，我们尤其应当注意，为了使每次until的时候都能对condition求值一次，我们必须使condition惰性化。所以，condition是() =&gt; Boolean这样的形式。调用的时候，使用 var x = 10 until (x=10) { x -= 1 println(x) } 不过，上面的语句中，仍然没有做到在until的第一个体里面声明变量x，而是得在until的外面声明变量，这种用法也不是完全的漂亮。 最后是Scala函数中return的使用。return确实是显式地终止函数。但是为了使用return，就相当于破坏了Scala的类型返回推导。因此，我们在定义有return的函数的时候，必须指定返回的类型。（其实应该还是能推导出来，但是可能没有通用的方案）。编程语言如果实现太高级，那么程序员的习惯可能难以适应（除了Haskell这样的语言）。 Scala的集合操作 相当一部分语言处理的任务是在列表、元组、字典这样的数据结构中实现的。它们就是一组数。在数学上看来自然是没有不同的。但是在编程中，似乎不同的方法需要单独处理一下。而且面对复杂的操作可能，也需要合适的抽象。 Scala的任何一种集合（列表、元组、字典）要么是可变的，要么是不可变的。而且所有类型的集合，都可以不用使用new方法来创建。因为它们都有apply方法。不可变的集合是非常理想的，因为在多线程的应用程序中使用他们也不会造成问题（不可变数据结构在单线程中的优势可能不明显，但是在多线程中，这种设计的优势是显而易见的）。 Scala优先采用不可变的集合类型。内置的List、Set、Map也都是不可变的。为了使用可变的数据结构，必须导入scala.collection.mutable包，以便使用mutable.Map得到可变的映射。（以及使用Map得到不可变的映射）。 不可变的序列Seq被定义为一个trait，而这个特质被许多类进一步采用。比如Vector、Range、List、Stream、Stack、Queue。Vector的优点是支持随机的访问。向量是树形的结构实现，向量中的元素每个节点可以有不超过32个子节点。这样访问100万的元素的向量，只需要跳转四下。但是在链表中访问某个元素却比较复杂（线性访问）。 试想象如下的代码 Range(0,1000000000)(100000000) 在这样的代码中，我们要首先生成一个序列（当然，Range其实是惰性的，只在有需要的时候才生成）。但是我们要想取得某个位置的元素的值，如果是Iterable的话，还是需要迭代到相应的值。这样，我们定义Range当然没有问题，但是要访问后面的值的时候，就得逐个向前走。特别是，如果Iterable的对象是一个File流，那么原则上，访问第\(n\)个元素的时候，也访问了之间的元素。因此Seq的朴素的实现，效率并不高。 Scala的可变序列也继承自Seq这个trait。具体的成员有IndexedSeq、ArrayBuffer、Stack、Queue、PriorityQueue、LinkedList、DoubleLinkedList。（回忆之前我们讲过，Scala对于递归函数、默认参数、带名参数、变长参数都有支持）。 集合的操作类型有很多。而且Scala也引入了对它们的模式匹配。所以是一个比较大的课题（大概Python中的集合类型也可以作为编程实践中的一大部分）。 在可变类型结构中，有时候我们会使用list(3)=5这样的方法。注意，Scala没有为集合类型重新定义一个[]的操作符，而且也没有必要。在Scala当中，这样的元素具有apply方法，所以可以直接应用它来进行赋值的操作。 Java与Scala的集合类型的相互转换，以及互操作这里也不介绍了。目前是没有什么收益的。 另外，即使有不可变的集合，大多数的并发编程的任务还是要求比较高级的线程安全特性。在Scal中，引入了相应的集合的Synchronized版本，比如SynchronizedSet。在并发库中，提供了ConcurrentHashMap等类。而且，相应的也有并行的版本。比如 for (i &lt;- (0 until 100).par) print(i+&quot; &quot;) 这里，通过一个par方法把循环变成并行的版本。 注：七周七并发中提到了多种并发的模型，而《程序设计语言实践之路》中提到了创建线程的多种语法（比如，有的使用begin块来实现并行的代码，有的是通过并行循环，有的是加工时启动Ada。fork/join，隐含接收与早回复的模式也是实现并行常见的）。基本上这六种包含了在语言设计中实现并发或并行的所有的使用模式。不同的编程语言支持的模式也不相同。 Scala的模式匹配与样例类 Scala的模式匹配的机制是比较强大的。具体地说，模式匹配可以用于match、类型检查，获取变量，匹配表达式类型。可以在模式匹配中添加守卫，使用通配符等。 模式匹配可以匹配变量的值，是也是最基本的方式。也可以用于匹配一个类型。 给模式添加守卫的方法示例如下： ch match { case &#39;+&#39; =&gt; sign = 1 case &#39;-&#39; =&gt; sign = -1 case _ if Character.isDigit(ch) =&gt; digit = Character.digit(ch,10) case _ =&gt; sign = 0 第三句就是加入了一个守卫。注意，守卫出现在动作的前面。另外，模式匹配是从上到下执行的，遇到成功的匹配就跳出余下的匹配。 注意Scala的命名模式。Scala的变量以小字字母开始。大写字母开头的符号表示的是一个常量。如果一个常量以小写字母开头，那么必须在使用的时候前后加上左单引号。 表达式的类型也可以参与匹配： obj match { case x : Int =&gt; x case s : String =&gt; Integer.parseInt(s) case _ : BigInt =&gt; Int.MaxValue case _ =&gt; 0 } 这里相当于添加了类型限定符。模式匹配在语法上是比较一致的。但是因为匹配的变量、常量、类型、实例类的不同，有些语句可能在编译器就决定了，有些可能被推迟到生成运行期的匹配的代码。 模式匹配与apply/unapply的用法之间已经介绍过了。但是模式匹配还可以用于变量的声明，以及用在for循环当中。所有这些，都应当视为学习模式匹配的重点。 偏函数 在模式匹配语句没有在所有的情况下有定义的时候，很容易导致偏函数。在Scala中，任何一个偏函数，类型是PartialFunction[A,B]。偏函数就是不在所有的位置都有定义的函数。使用偏函数的时候，如果使用得不恰当，会自动抛出异常。 Scala的注解特性 目前了解到，注解可以以不同的方法实现就可以了。而且在Scala中，注解可以为类、方法、字段、局部变量、参数、表达式、类型参数以及各种类型定义添加注解。这样的多种多样的注解，可能导致我们无法简单地使用高阶函数来统一理解注解。 Scala不同的一点在于，Scala的注解可以影响编译的过程。通过注解，可能往类里面自动地添加一些方法。在Scala中，注解是annotation.Annotation的扩展。而注解可以有不同的类型，如StaticAnnotation、ClassfileAnnotation等。 Scala的注解广泛用于和Java的互操作、优化执行。以及添加额外的检查，实现条件编译等。 Scala的泛型，类型参数 Scala的类、特质、方法、函数都可以有类型参数。类型参数放在名称的后面，用中括号括起来。可以使用类型界定&lt;:等。 类型界定的重点集中在隐式类型转换与自动类型推导上。 Scala的类型系统还是比较复杂的。包括类与特质、元组类型、函数类型、带注解的类型、参数化类型、单例类型、类型投影、复合类型、中置类型、存在类型等。但是一般而言，这么多类型强调的是对于不同情况的适应，而非建立类型系统的一般的框架。所以我们先跳过对于Scala的类型系统、类型运算关系的介绍。但是实现依赖注入、抽象类型等的时候，我们可能必须返过来仔细阅读有关Scala类型系统的介绍。 与面向对象中的继承、多态（特别是多态）混合的时候，类型系统变得更复杂。 学过Haskell我们就知道类型构造器与数据构造器。实际上，Scala语言也有这样的概念。不过，相关的概念放在编译器特性当中了。这使得我们在学习Scala编译器系统的时候才能比较全面地看待Scala的类型系统。 Scala的解析器库 Scala的解析器库是编写内部DSL的一个非常好的应用（注意，内部DSL虽然是离不开宿主环境的，但是仍然是从字符串中读取内容，否则就不是DSL了）。 Scala的DSL的实现非常优雅，得益于它的操作符系统，以及正则表达式匹配。原则上我们也可以用操作符机制来自己写解析器库，但是Scala的解析器库提供了一个高级的选择。 学习解析器生成自然是每个编程者的目标，但是目前自己的困境是没有理解DSL领域的一般的实践的规则。也就是说，写DSL有哪些实践，又有哪些应用，哪些应用是常见的。我们不是任意地写一个解析器，然后生成一个不成熟的实践。 Scala的编译器[09-11-2015 23:07:38 CST] 现在Scala的编译器是github上面的一个项目。在Scala项目中，Scala语言本身占了很多。其实是5.9%的Java语言和少部分的Python与Shell语言。 另外，安装sbt请参考http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Linux.html。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala编程概要（二）：基本结构，常用模式]]></title>
      <url>%2Fscala-sentences%2F</url>
      <content type="text"><![CDATA[设计模式在软件编程的各个方面都有应用。MVC与分布式一般算成是架构模式，而写文档注释也有一定的模式可以遵守。另外，我们也可以设计出一些使用的模式，以便在开发软件之后，可以让用户按照指定的模式使用软件。 Scala的for语句 在scala当中，for并不是经典的控制流语句而已。在for里面可以加一些过滤器，同时，也可使用yield来生成一个集合。这种控制语句应该是与Map-Reduce相互配合的。而且为了支持新的范式，也需要修改for语句的行为。 对于非递归的函数，scala不需要指定返回的类型。这是因为，虽然hindley-Milner算法能够推断出递归函数的返回的类型，但是在面向对象的语言中却并不是总是可以行得通的。所以，在处理递归函数的返回类型上，Scala并没有使用Hindley-Milner类型推断算法。 另外，Scala的函数参数也可以使用默认参数，或者使用变长的参数（变长的参数的处理与Java是类似的）。 不返回值的函数，一般都是使用Unit作为返回类型。 Scala中捕获异常可以采用模式匹配的方法。这比Java精简了不少。 另外，在数据流编程当中，一种方法是使用if守卫加上yield和for产生序列，比如for (elem &lt;- a if elem % 2 == 0) yield 2 * elem。但是对于函数式语言实践而言，最经常使用的是filter-map-reduce的方法，比如a.filter( _ % 2 == 0).map(2*_)或者甚至是a.filter { _ % 2 == 0 } map { 2 * _ }这样的序列化的形式。另外，很大一部分时间编程语言都是在做查找和排序的操作。这种情况下，Scala对数组采用了很多的方法。比如整型数组的Array(1,2,3,4,5).sum方法，以及ArrayBuffer(1,7,2,9).sorted(_&lt;_)方法。 在类型系统比较丰富的语言中，不熟悉类型系统的编程者可能觉得语法很奇怪。不过，其实也没有什么好奇怪的。学完类型系统就会觉得是自然而然的。 Scala中的映射 Scala中，其实又被称为字典，在Scala中称为哈希表。哈希表是应用非常广泛的数据结构。Scala用Map来记其名子。比如 val scores = Map(&quot;Alice&quot; -&gt; 10, &quot;Bob&quot; -&gt; 3, &quot;Cindy&quot; -&gt; 8) 在Scala中，哈希表具有Map(T1, T2)这样的数据类型，而且这里的哈希表是不可变元素。要使用可变的映射，数据结构应该变成scala.collection.mutable.Map。或者要从头开始建立哈希表的时候，使用scala.collection.mutable.HashMap[String, Int]这样的形式。 在Scala中，函数与映射在语法上类似。比如scores(&quot;Bob&quot;)可以取到相应键的值。如果相应的键不存在，则抛出异常就可以了。另外，可以使用score.contains之类的方法检查映射中是否包含指定的键。另外，使用getOrElse()方法，可以执行，如果包含相应键就返回值，否则就返回一个指定的值的方法。 如果映射是可变的，可以使用score(&quot;Bob&quot;) = 10或者scores(&quot;Fred&quot;) = 7这样的语法来更新已有的键的值，或者创建一个新的键值对。或者使用+=方法来把新的关系加上去，如 scores += (&quot;Bob&quot; -&gt; 10, &quot;Fred&quot; -&gt; 7) socres -= &quot;Alice&quot; 对于不可变映射而言，不能重新赋值，但是可以通过+与-方法生成与原来映射相关的一个新的映射。假如不可变映射与一个var相关联，还可以重新给var赋值。虽然表面上看起来，创建新的映射效率比较低，但是实际上，函数式语言中正好相反。在函数式语言中，递归与不可变元素的使用反而是效率比较高的。取遍映射中的所有的键值对可以使用for方法，比如 for ((k,v) &lt;- 映射) 处理k与v 之所以能够在for语句中实现这一点，主要是因为for语句里面能够模式匹配。另外，也可以使用score.keys与score.values之类的返回相应的键与值。总而言之，这是映射这种数据结构的通用的方法。 另外，要想混用Java与Scala中的映射，必须要经过一个类型转换。比如 import scala.collection.JavaConversions.mapAsScalaMap val scores : scala.collection.mutable.Map[String, Int] = new java.util.TreeMap[String, Int] import scala.collection.JavaConversions.propertiesAsScalaMap val props : scala.collection.Map[String, String] = System.getProperties() 反过来的类型转换，提供的是相反的隐式类型转换的值。这时候导入的是 import scala.collection.JavaConversions.mapAsJavaMap 另外一种常见的数据结构是元组。Scala的元组是一个多类型的参数类。另外，可以使用模式匹配来将元组中相应位置的值赋给相应的变量。元组的一个作用是通过具体的元组的部长乘积，构造出对偶的数组。比如 val symbols = Array(&quot;&lt;&quot;, &quot;-&quot;, &quot;&gt;&quot;) val counts = Array(2, 10 ,2) val pairs = symbols.zip(counts) for ((s, n) &lt;- pairs) Console.print(s*n) 在上面的式子中，pairs是如Array((&quot;&lt;&quot;, 2), (&quot;-&quot;,10), (&quot;&gt;&quot;,2))之类的有序组。对于二元序组来说，可以通过toMap方法将其转换成相应的映射。 注，在scala中，无参函数调用也不必带()，其实也许是因为本来函数与变量以及类的名子空间都是在同一个当中，所以，实际上，根据名子就知道它是函数，是变量还是方法，根本没有必要区分。而且，一个函数中实际上也可以带有相关的参数（惰性求值）。编译器如有可能，总是应该完成大部分的工作，应该具有常识，应该具有智能。 Scala中的类的使用 Scala中的类的风格大部分是与Java相通的。但是Scala作为一种更高级的语言，应该使用那些支持的高级的特性来完成类的声明与定义。 对于getter/setter(取值器与改值器），有时候需要特别的处理，比如不允许改值。这种方式下，还是要使用private关键字来修饰变量，并且自己手动写getter/setter方法。注意，可以使用this来引用类的成员。在默认情况下，Scala为其每一个字段都提供getter/setter方法，除非成员被声明为private。要想查看Scalac到底生成了哪些代码，可以使用javap来查看生成的class文件。另外，其实getter/setter方法默认是与变量同名的一个无参函数。因此可以手工地使用def age来定义取到成员变量的一个值。 如果不允许类中的名子被修改，那么更好的办法是使用val代替var。 按照JavaBeans中的要求，所有的属性都要有getFoo与setFoo这样的方法。为此，可以使用scala中的scala.reflect.BeanProperty包提供的@BeanProperty修饰器，来完成相应的操作。具体用法是： class person { @BeanProperty var name : String = _ } 这样除了生成一般的方法之外，还生成getName与setName方法。此外，注解也可以以 class Person (@BeanProperty var name : String) 这样的方式被使用。 与Java一样，Scala中的类的构造器也可以有多个。不过，在Scala中，构造器的名子为this（在Java中就是类的同名的函数）。构造器有主构造器与辅构造器之分。我们可以通过某些方法指定。默认Scala会生成一个无参的主构造器。 Scala的设计者认为每敲一个键都是珍贵的，所以可以把主构造器与类定义结合在一起。也就是说，在定义类的时候，就可以定义传入类的相关的参数。如 class Person (val name : String){} 这样的紧凑形式。 另外，Scala也支持嵌套类的使用，使用的方式与java不太一样。 注：java中，#运算符代表的是一个类型投影，比如说，Network#Member，会得到Network中的嵌套类Member。 Scala中的对象 scala中的对象直接实现了单件的模式。因为既然被定义为一个对象，那么所有的该对象的变量都是共同的操作。与类相比，对象只是没有有参构造函数，以及对象的构造器在该对象第一次被使用的时候调用。为了使类具有类似于静态方法的效果，可以给类定义一个伴生的对象。这个时候，类可以调用伴生对象的方法。不过，访问的时候必须显式地指明伴生对象。而且Scala中强制要求伴生对象的定义必须与类的定义放在一起。 对象的常用的方法是继承一个抽象类，并且实例化方法。比如，绿色是一种取特殊的值的颜色，那么绿色就成为一个对象。扩展了抽象类的方法。 Scala应用程序 与Java一样，scala程序的运行是从一个对象的main方法开始。main方法的类型是Array[String] =&gt; Unit。除了直接写main方法之外，我们也可以自己扩展App特质，然后把程序代码放在构造器方法体内。 object Hello extends App { println(&quot;hello, World!&quot;) } 还可以在App构造器内使用args.length得到参数的长度，以及得到相关的参数。应当注意，程序的体是放在App特定的构造器里面，所以println函数不用放在方法中，就好像是直接使用类的成员传递一样。 包管理是构造大型应用程序的一部分，属于封装。在Java中，包总是以绝对路径的方式被访问，但是在Scala中可以是相对路径。此外，包名可以放在不同的文件中。由于Java虚拟机的局限，包可以包含类、对象与特质，但是不能直接包含函数或者变量定义。为了解决这种困难，可以使用“包对象”的概念，也就是使用 package com.horstmann.impatient pacakge object people { val defaultName = &quot;John Q. Public&quot; } package people { class Person { var name = defaultName } } 这样的方式来定义一个包对象。由于Person类既在com.horstmann.impatient.people包的作用域中，而该作用域下定义了defaultName成员，所以可以在Person类中访问defaultName。 包以象是Scala的一个小把戏。在内部，包对象被编译成带有静态方法和字段的JVM类，名为package.class，位于相应的包下面。 另外，引入包的时候可以引入包中的所有的名称（使用下划线），也可以引入单独的名称（比如引用包中的一个类）。在Scala中，包引入可以放在任何作用域里面，不必放在文件的顶部。这样可以只在运行的时候才引用相应的包。Java程序员的实践比较依赖于IDE。因为他们不喜欢把包中的所有的对象都引入文件，而IDE正好可以让它们选择引用哪些包，并且为相应的引入生成长长的import语句。 如果要引入包中的几个对象，可以使用选取器，如 import java.awt.{Color, Font} 或者重命名要导入的成员以解决可能的冲突 import java.util.{HashMap =&gt; JavaHashMap} import scala.collection.mutable._ 总而言之，在scala程序员中，把包中的所有的对象都导入进来是很普遍的。 Scala的面向对象的机制 首先，scala的类的机制与java类似，另外，scala中重写一个非抽象的方法的时候必须使用override修饰符。 与java中一样，调用超类的方法也使用super关键字。 如果需要类型检查，可以按照如下的方式： if (p.isInstanceOf[Employee]) { val s = p.asInstanceOf[Employee] ... } 注意scala是静态的语言，所以运行期中的type(a) == int这样的代码显然是不容许的（即使容许，求值也会发生在编译期）。因此，使用了isInstanceOf作为一个有参数的构造器。与其直接使用类型运算符，在scala中，不如使用模式匹配这种轻量级的类型运算符。比如在检查变量的类型的时候，使用 p match { case s : Employee =&gt; ... case _ =&gt; //otherwise } 我们或许可以把模式匹配看成轻量级的类型运算。另外，可能令人感到困惑的是，因为是静态类型，难道程序员不是知道所有的变量的类型了么？为什么还需要做检查变量的类型这样看起来无意义的工作呢？ 剩下的编程实践 一种编程语言有理论的部分和实践的部分两个大类。在理论的部分，几乎只能是执行某些计算。然而一个有实际意义的语言，通常的编程主题有文件Io、进程控制等。访问操作系统接口往往也是必要的。 文件的本质，在Haskell中显示的比较紧。但是在通常的编程语言中，理解的层次往往只是文件当成是一个可以随时读取的对象。随着读取的进行，每次都往前移动。现在我们知道，我们完全可以把文件当成是一个惰性数据结构。 随着软件产业的发展，有一些主题在编程语言中也变得流行起来。除了文件IO，访问操作系统函数接口之外，还有的普遍的操作有XML、序列化，异常处理等。 Scala的序列化来自于java.io.Serializable。但是在scala中，要声明一个类是可以序列化的，使用的方法是注解。比如 @SerialVersionUID(42L) class Person extends Serializable 注意，由于scala包直接包含了Serializable，所以不需要引入额外的序列化的包。另外，scala的所有的集合类都是可以序列化的。 注：自己在Python中曾看到“注解”或者装饰器其实就是一个高阶函数。并且，使用了注解后，每次调用这个类，这个类都与这个高阶函数相绑定。也许序列化函数也应该这样。虽然注解可能在语言习惯上不是太好，但是确实是非常有效。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala编程概要（一）：文档，注释，面向对象]]></title>
      <url>%2Fscala-tutorial-intro%2F</url>
      <content type="text"><![CDATA[虽然每次都是从头开始看Java与Scala的初级的教程，但是每次看的时候重点不一样，对于语言的理解也不一样。这一次的时候，强调的是，我们如何从初学者成为能够熟练运用一门语言的开发者？为了做到这一点，我们需要付出哪些努力？ 现在的看法是这样的。第一，我们应该按照写书的方式写Scala的程序。所以，如何从应用程序中生成文档，以及介绍这个文档是最基本的。所以，在初学者的第一章的时候就应该学习使用scaladoc来写文档，以便能够注释出来自己所写的东西，表达出来自己所写的东西是什么样的意思。第二，或许是对于某些语言，使用REPL环境。但是学习一个语言可能更关键的是学习它适应的设计模式，与常见的实践，就像写学术文档一样写程序。 Scala的一些灵活的约定 Scala的语法是高度自动化的。第一是，方法与成员的用法看起来没有什么区别。尤其是，如果方法没有区别，那么方法可以不用带圆括号。这种情况下，与编程语言的文法本质更接近了一步：所有的出现的都是一个token，只是不同的token有不同的含义。比如res2.toUpperCase虽然看起来调用的是成员，但是实际上是一个方法。 第二是变量与常量的自动的声明。比如使用val与var，而不用带有复杂的类型声明，甚至不用知道类型是什么。不过，Scala与Python之类的还有区别。因为在Python中，运行期间可以得到一个成员的类型，并且把类型当成是一个变量。在命令式的语言中，使用变量自然是很正常的，因为使用常量，看起来也做不了什么有意义的事情（其实这种观念很可能是不正常的，因为在一定作用域的限制下，不使用变量也能够做很多的事情，特别是很多的数学计算，其实根本不需要使用变量）。不过，其实不使用变量而使用常量val也能完成很多的编程任务，而且似乎是更优雅。具体我们可以参考Scott的《程序设计语言实践之路》中对于名子、变量、作用域的介绍。 在Scala中，当然也可以强制变量类型声明。比如说，我们显然可以在变量后使用val a : Int的形式限定一个整型参数。另外，Scala中一行中存在多条语句的时候才需要使用分号隔开。 现在看来，学习Scala之前，确实是需要学习一些基础的知识。比如数据类型中的基本类型与引用类型。通过Scott的《程序设计语言实践之路》我们看到Java的数据类型的世界中，基本类型与其它类型的区别是明显的，因为基本类型返回的都是值方式，而用户自定义的类型，默认返回的都是一个引用。（这种规定不那么直观，但是在Java编程中却有着举足轻重的地位，决定了我们如何使用Java中的不同的数据类型）。此外，数组在Java中比较麻烦。但是Scala就不用考虑这一点。 总结：总而言之，学习一门编程语言的基础的时候，大概在学习一门语言的设计模式之外，第一步是了解编程风格。比如Scala，既然支持无参的方法不用括号，那么在Scala中，最好就不使用括号。这种风格更为简洁。在数据类型中，既然没有值类型与引用类型的复杂的区分，那么就不用考虑复制的问题，以一种更为函数式的风格思考问题。除此之外，还有一些复杂的问题，比如使用map-reduce风格。 总结：评价与了解一个编程语言，可能不再只是使用简单的类型的静态与动态、函数式编程或者其它的风格。其实，一般而言，评价一个东西，我们可以说一句话，可以说十句话，可以说一百句，可以说成一本书，也可以说成一套全集。关键是看我们描述的细的程度，仅一句话当然可以那么描写。但是要达到比较理想的层次，可能还需要一套详细的评价的方法。更进一步地，我们需要了解一门编程语言的特性可能包括以下的几个方面：最基础的方面，无论是函数式语言还是其它的语言，都要考虑抽象的问题，因为抽象是高级编程语言的共同的特性。这里面的主题就有名子，作用域，数据抽象，控制抽象等。第二步是所谓的编程语言的类型的系统。第三步是编程范式。然后是设计模式。经过这四个步骤，对于一个编程语言的理解或许就比较深了。至于前端的语法的知识，其实是比较形而下学的。 Scala文档风格[07-01-2015 08:40:18] 在没有考虑编程语言的任何特点的情况下写代码并不好，这个时候我们可以写注释。Scala的第一种的注释风格是这样的： /** This is a brief description of what&#39;s being documented. * * This is further documentation of what we&#39;re documenting. It should * provide more details as to how this works and what it does. */ def myMethod = {} 明显地，这种方法下，注释的整体就是一段文字，编程语言只知道注释是由几个段落构成的，而没有感知到其它的成份，所以生成的文档也很笨拙。虽然学术级别的写作要求非常高，以致于不可能单独在编程语言中讲到，但是其实注释是一种更深的艺术。只有明确地表达了自己的思维，所做的编程的工作才有意义。 如果是比较简单的类型，可以使用单行注释，示例如下 /** Does something very simple */ Scaladoc本身是一个完善的标记的语言。由于注释本身就是介绍文档的。所以，一方面，注释介绍了相应的数据结构的接口特性，另一方面是实现的特性。而且一般在文档当中，要把相应的编程结构的接口特性描述的更清楚一点。特别是把接口列出来。在Scala中，可以使用@return这样的标记来处理返回的值。doc文档的编写规范，可以参考http://docs.scala-lang.org/style/scaladoc.html。 使用package的注释 在绝大多数的编程语言中，模块或者包或者库都是比面向对象更为高级的抽象。所以对模块的注释也显得格外地重要。在Scala中，包往往需要比较长的注释。一种方式是放在package的后面。 package parent.package.name /** This is the ScalaDoc for the package. */ package object mypackage { } 另外一种方式是放在package当中。大块的注释，好像演化的趋势正是文学编程，以及使用markdown或者latex的风格。特别是在一些定理证明语言与Haskell这样的新的语言中，出现的在注释中插入代码的情况更加普遍。 package my.package /** Provides classes for dealing with complex numbers. Also provides * implicits for converting to and from `Int`. * * ==Overview== * The main class to use is [[my.package.complex.Complex]], as so * { { { * scala&gt; val complex = Complex(4,3) * complex: my.package.complex.Complex = 4 + 3i * } } } * * If you include [[my.package.complex.ComplexConversions]], you can * convert numbers more directly * { { { * scala&gt; import my.package.complex.ComplexConversions._ * scala&gt; val complex = 4 + 3.i * complex: my.package.complex.Complex = 4 + 3i * } } } */ package complex {} 类的注释可以参考 /** A person who uses our application. * * @constructor create a new person with a name and age. * @param name the person&#39;s name * @param age the person&#39;s age in years */ class Person(name: String, age: Int) { } 不过，类的注释的内容与类的构造器的内容的注释如何安排其实也不是那么容易的。对象可以参考 /** Factory for [[mypackage.Person]] instances. */ object Person { /** Creates a person with a given name and age. * * @param name their name * @param age the age of the person to create */ def apply(name: String, age: Int) = {} /** Creates a person with a given name and birthdate * * @param name their name * @param birthDate the person&#39;s birthdate * @return a new Person instance with the age determined by the * birthdate and current date. */ def apply(name: String, birthDate: java.util.Date) = {} } Scaladoc的注释规范，可以参考Scala lang的维基。 Scala的优势在哪里 首先，创建一个Person类，在Java中，代码是这样的： class Person { private String firstName; private String lastName; private int age; public Person(String firstName, String lastName, int age) { this.firstName = firstName; this.lastName = lastName; this.age = age; } public void setFirstName(String firstName) { this.firstName = firstName; } public void String getFirstName() { return this.firstName; } public void setLastName(String lastName) { this.lastName = lastName; } public void String getLastName() { return this.lastName; } public void setAge(int age) { this.age = age; } public void int getAge() { return this.age; } } 但是在Scala中对于简单的getter与setter的支持下，简单的形式就是： class Person(var firstName: String, var lastName: String, var age: Int) 当然，这种方法添加的构造函数可以通过直接访问Person.lastName得到，看起来是直接访问了成员，但是其实是访问的构造器。不过，要想在构造器中添加一些日志的功能，还是得另外的配置。 要注意的是，Scala的类的实现中，不使用静态方法，取而代之的是可以直接定义一个相关的对象，通过这个对象直接产生一个相当于静态成员的东西。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[用自举理解人工智能与学术研究]]></title>
      <url>%2Fai-and-bootstraping%2F</url>
      <content type="text"><![CDATA[最近人工智能在公众世界中变得很热。在各种技术应用铺天盖地的时候，肯定也有不少人在思考人工智能与人的思维的关系。在这里，我们首先关注的可能是这个很自然的问题：人工智能，或者干脆说智能机器，机器人，会不会取代人类。这里的取代，并不是说能够取代人的平常的工作，而是机器具有自主学习、自主决策的能力。完全不再需要人的干预。 本文的标题的前一半，就来尝试这个问题。至于后一半“理解学术研究”，比较具体。因为一直以来，科学研究活动都被视为是具有极高智力挑战的活动。同时，实际中的学术研究还是比较累的。单单做理论的工作，似乎很难合“学术共同体”的口味；而实践的工作，又上不了科学理论的台面。然而，科学活动的量级似乎越来越重。除了少数学科，如纯粹数学，研究方式变化没有那么大之外，几乎所有的科学都面临着数据处理的新的问题。“数据科学”，是否会成为所有的科学研究的基础？花费的代价越来越高的数值计算与模拟，是否越来越占据更大的份量？计算机在科学研究中的地位究竟是怎样的？ 虽然科学工作流系统、高级体系结构、科学数据可视化等对于提高相关活动的效率有极大的帮助，但是在自动化的层面似乎做的还不够好。我们肯定希望，如果有可能的话，编写数据处理的小脚本、可视化数据、甚至是选择计算环境等工作都能够分离出来，让我们有时间专心去思考某些问题，而不是花在没有什么含量的技术操作上。进一步地，许多活动该由计算机来做，比如计算机发现新的物质结构，由计算机来总结科学数据集中的结构，甚至是能够发现复杂的方程与约束的条件。最明显地，我们研究生是否能够花更多的时间在学术研究上，而不是花大量时间在做项目，做产品，或者是为理论找到一个合适的验证的平台上？ 本文这里尝试概要地理解问题的实质。受到计算机知识中的“自举”的启发，个人觉得，其实这两个问题在逻辑上的困境才是当前阻挡理解这个问题的关键。“自举”一个是指一个人在不借助于任何外力的情况下把自己提离地面。在机器是否超越人类，以及更具体的，让机器代替人进行科研活动创新的时候，类似的逻辑阴影似乎总是存在。“世界是满的”，个人相信肯定早就有人思考过这个问题。不过，其实花了一个下午来克服自己认识的局限效率还是要高一些。如果有类似的读物，可以发送邮件到这里。 问题抽象 直接面对两个问题中的任何一个，都会使人产生思维上的困惑。很多时候，我们不知道在这样的语境下该如何走。这种情况可能是由于问题与我们自身的生活体验、生活环境、生存利益等太过相关，以至于不可能单独出来看问题。没有足够的证据，但是我们也可以合乎逻辑地说，从神经质一直到经历了许多社会变迁的老人，都不可能对任何事情都有完全客观的看法，在这种看法中，不掺杂任何主观的成份。很明显，因为我们都相信，人无完人。 所以人类就有意或者无意地避开冲突领域。以一种抽象的、甚至与直接问题完全不相干的方式间接地解决问题的策略就被广泛使用了。大概哲学在解决问题的时候有一种抽象，甚至在任何创造性的活动中，都必须避开问题中某些特殊的语义，把问题中具有实际意义的概念变成只是一个符号。 所以，“机器能否取代人”之类的问题，我们可以改写成几种抽象的场景： 1.对象\(A\)创造了对象\(B\)（很有可能是让对象\(B\)从虚空之中产生出来），然后对象\(B\)能够取代对象\(A\)，在某些属性上超越了\(A\)，并且\(B\)同样具有“创造比对象\(B\)更强的对象”的能力。 2.整体\(A\)把\(B\)作为它的一个部分，然后\(B\)可以“整体作用”于\(A\)，从而引起\(A\)和\(B\)的共同的变化。结果，就相当于\(B\)间接地作用于自已。 把\(A\)看成是人类，把\(B\)看成是机器，那么其实很自然地，我们如果不怀疑\(A\)，那么自然“机器取代人类”是可能的一个命题；对于学术来说，学术研究是一个整体，数据处理是其中的一个部分，而数据处理的方式的变化，自然引起整个科学研究方式的变革。如果数据处理实现了自动化，那么科学研究自然也会引起一些变化。 自然地，自举的模式也是类似的，因为有如下的场景： 1.计算机系统刚开始只有一段BIOS程序来引导应用程序，这段BIOS把引导程序，如grub或者syslinux加载到内存当中。grub是可以执行lua脚本的，相当于一个微型的操作系统。不过，这个系统仅仅对文件系统访问提供有限的支持，唯一做的，经常是把操作系统内核如Linux加载到指定的位置，然后使它运行。而后Linux成为了一个“更强大的”操作系统。再加载一些桌面后，成为更完善的操作系统。在整个过程期间，BIOS、grub都相当于把自己从内存中“杀死”了。 2.编译器的构建。Ada编译器是用Ada写成的，C编译器是使用C写成的。那么这种循环的情况该如何理解呢？自然而然地，刚开始没有Ada或者C这种东西，只能是其它的某种语言产生的。便使用低级语言构造一个基础的编译器。之后的过程是，高版本的编译器只使用低版本的编译器所支持的语法特性来编写，用低版本编译器编译，生成高版本的编译器，然后高版本的编译器在保持特性相容的条件下，重新编译自己的源代码。更复杂一点的GCC，源代码编译需要三次构建。 在社会中也许我们可以看到更自然的形式，比如达尔文的《物种起源》被广泛接受之后，逐代进化的观念就保留了下来。与此同时，现代社会也认为社会是在不断向高级的形式进化的。从来没有人对这些提出疑问，那么为什么我们会对于机器取代人没法淡定了呢？ 问题精化 粗糙地看，提出的场景都是相似的。我们也就可以找到各自的特殊情况，以便相互借鉴解决问题的方法。比如说想象如下的问题： 1.在场景中，居于中心地位的，明显是一对对象而已，比如人与机器、数据处理与科学研究、整体与部分、对象\(A\)与对象\(B\)、编译器与新版本的编译器。但是真的就只有这两个对象的参与么？其实也许还有环境的作用。比如，执行代码的主机。那么，在人与智能的关系中，其实人的进化也是有原因的，机器的进化也是有原因的。这种原因是什么呢？ 2.在编译器的构造中，我们知道，每个语言虽然是不完全的，但是在计算能力上面，往往图灵等价。这似乎在告诉我们，不管每个时间\(t\)事物存在的情况如何，事物的轨迹构成成一个称为“全体”或者“空间”之类的东西。虽然我们在某一时刻或者短时间内只能看到其中的一部分，但是我们知道其中存在更多的可能。在智能上，是否人只是“智能的一种表现形式”，从而“人的智能”是“智能”的一个子空间呢？ 3.第三个问题，有些场景中，明显地涉及到“产生”这个概念。那么“从虚空中产生”究竟意味着什么呢？我们高中的物理知识告诉我们质量守恒与能量的守恒，后来是质能关系守恒，最近或许因为Higgs粒子的验证，或许又要修改另一种说法了。但是在能量之上，熵的增加却又成为了不争的事实。那么，世界是否任何对象都是“守恒”的，还是说，这些量仅仅是我们观测的量而已，它们并不无条件等同于世界？ 问题类比 一些共同的想法使我想到可能动力系统来比喻当前的问题。动力系统可以抽象人造的系统，也可以抽象现实世界中存在的一些运动机制；可以是小范围、少变量的，也可以是大范围的、复杂的系统；可以是离散的，连续的或者是混合的。既然“动力系统”只是一种数学的抽象，那么把人工智能与人的思维的关系建模成动力系统也是一种可能。 大概我们可以把这类双因素相互作用的系统看成是普遍的模式。那么，如果一个变量的变化，受到两个变量的影响，那么长期情况下会出现什么行为呢？是否总会是趋于无穷呢？数学方程告诉我们未必。那么，其实人工智能的问题就更不用担心了：在简单的二元变量的情况下，系统的行为尚且可以如此复杂，那么，对于人与机器的相互作用，这样复杂的东西，是否仅仅考虑到长时间以后，人类就被机器取代了呢？第一，这得附加上一些边界条件。第二，即使取代人类，那么也是方程指定的结果。 我想，在现实世界中，社会问题可能存在多种可能。每一种都有其存在的方式，存在的原因。要想了解具体的行为，还是得分析一些具体的量是怎样的。 初步结论 讨论机器是否取代人，或者科学研究过程中数据与理论哪个更为复杂，可能没有太多的实际的意义。不管怎样说，在目前如果我们不去推动人工智能的发展，那么人工智能成了什么样子还是不好预测的。至少我们得参与其中，才有一些发言权。 还有，目前机器能够的工作还是非常少。要相信人工智能可以取代人类，除非有人做出来机器代替目前研究生能够做的烦杂的劳动。否则我们怎样才能相信机器可以取代人？ 更根本的问题，或许是哪些事情应该由人来做，哪些事情应该由机器来做。人与机器的关系该是怎样的。目前，在机器取代人的工作的方面已经有一些进展了。在已有的经验的基础上，或许该发现“机器取代人工作的一些模式”，或者“人与机器共生的几个场景”一些例子。适当地总结下来，或许关键在于所谓的“能够把人与机器融合在一起的工作流”应该是怎样的。假如能够有这样一套系统的工作方法论，或许类似人与机器的可替代性的问题就太过基础和肤浅了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[个人主页项目的设计与管理]]></title>
      <url>%2Fblog-solutions%2F</url>
      <content type="text"><![CDATA[参考Eric Walkingshaw的主页、Ian Ross的主页以及yogsototh的支持多语言的主页的设计以决定该怎样布局个人的主页。 Hakyll下面的个人主页项目，似乎有把个人主页分成程序和资源两个部分的倾向。进一步地，site.hs，以及编译器属于程序，CSS、Markdown与HTML模板属于“资源”。那么我们会问，制作一个个人主页必须学会编程，特别是Haskell编程么？似乎前台的工作就已经足够让人烦了：个人主页中的CSS、HTML页面布局的设计就变得非常麻烦。鉴于所使用的后台对于个人主页没有任何直接的影响，我们不妨把构建网站的程序从网站代码当中分离出来。 理想中的工作流的情况应该是这样的：先由用户组织好自己的网站的目录（特别是Markdown目录、CSS、HTML模块这些主要的页面的文件。由于这些文件需要编译，所以应该由一个项目发布程序，功能类似于site.hs。但是项目发布程序原则上是一个DSL，而不应该是Haskell代码。即使是Haskell代码，因为发布之前的网站相当于“源代码”，所以也可以像Makefile那样使用本地的应用程序生成。 注：写到这里，已经不能把握最佳实践。恐怕自己的重点该放在理解Pandoc格式并写出几个过滤器来了。有足够的知识基础后再来整Hakyll网站。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Github主页修整记]]></title>
      <url>%2Fblog-github-modify%2F</url>
      <content type="text"><![CDATA[建主页有许多种选择。这些方案可以分成静态主页方案与动态主页方案两大类。动态主页的托管的方式可能复杂一些，需要维护的代价似乎比较高。此外，动态主页里面的内容在转成可打印的版本的时候质量也会缩水。最理想的情况自然是一边能够生成HTML文档，另一方面，不经重新修改，可以转成其它的格式，特别是LaTeX的格式。 但是实际中能像LaTeX那样有表现力，又有丰富宏包支持的格式还真不多。Markdown等都过于简单了。之前的实践中，LaTeX格式与HTML对比中，主要的不一致有： LaTeX中有wrapfigure、caption宏包可以调整图片，但是在HTML中的调整就得手工编码了。因为实在是没有学习HTML的排版细节问题；此外，LaTeX的表格转成HTML的表格也不太容易，特别是有对齐、指定宽度的表格，换到HTML页面上往往不好看。 数学公式中，使用MathJax中也只能使用预定义的公式集。但是在编程语言中所用的符号，与在逻辑中所用的符号不同，范畴论的符号，跟在线性代数中也非常不同。在MathJax中能够自定义数学公式命令是必须的，但是又是比较麻烦的。高级的框架，如交换图、amssymb、eulervm宏包提供的符号，似乎也得重新配置。单配置来说并不困难，可是有时候需要变更宏包，这个时候又得手工同步。 LaTeX中有一些宏包来支持其高级的特性，比如算法宏包algorithmicx、语法高亮的宏包listings或者minted、排版化学公式的chemfig、排版UML图形的umlcd、排版音乐的abc宏包（其它的还有lilypond、musixtex，后面两者的可用性没有abc好）。但是这些特性在markdown或者reStructuredText中不那么自然。 本人一直在用Sphinx来写编程语言教程，效果还不错。但是博客是一种新的格式，展示的内容可能也比较杂。 还有一点，LaTeX与XeLaTeX中可以自由使用各种字体，间距也会调整得很好。但是像审阅打印稿一样阅读网页中的文章是不可行的。用于网页中增强可读性的方法有自己的一套逻辑。 后来发现，Pandoc远胜于其它的方式，至少在原则上，Pandoc可以以一种既简洁又一致的方法扩展自己的功能，虽然Sphinx也支持各种插件。但是在Pandoc中写filter更容易。 期望中的个人主页的结构 遇到这么多问题，首先需要明确对于个人主页抱有的期望有哪些。现在自己推荐的是Hakyll工具，相应地，在http://jaspervdj.be/hakyll/examples.html上有一些建好的网站的样式。其中，Eric Walkingshaw的主页、Ian Ross的主页以及 yogsototh的支持多语言的主页里面的几个特性吸引了我。 根据这几个网站，总结出个人期望的个人主页应当具有如下几个特点： 1.首页应当加强作者的介绍。可以添加上作者的感兴趣的编程语言、感兴趣的研究方面，以及目前的研究的动向。不能只是每天都是列表的重复。如果有可能，可以添加上Disqus评论、标签云、文章检索、改变外观的功能。 2.对多语言的支持。我们现在在英文与中文方面都各自有一些要表达的东西。为了国际化，得使用英文，但同时也想用中文表达一些意思。在同一页面中各种语言混杂起来显得非常奇怪，可读性也非常差。所以，一个网站，准备有中文的、英文的、混合的版本，并且可以按照不同的语言切换。 3.对文章预览的支持。文章内容的可读性比较因人而异，但是整体页面的风格对于找到合适的文章亦非常关键。展示文章列表的时候，是否文字应该醒目？是否有关键词？是否放置一些摘要？是否将日期与网页右侧对齐？个人希望这些功能能够组合在一起。必要的时候，也可以附加一些搜索功能。 Pandoc与Hakyll没有直接支持的功能 Pandoc的设计确实令人印象深刻。但是目前要实现一个功能，还存在不足。Pandoc在机制方面可能足够好了，但是在“工作流”的处理上可能还不够好。比如说，出版的过程可能是首先确定题目，然后把封面设计与内容设计分开，在写各章的内容的时候，一般还要确定使用LaTeX的哪些Feature。如果Pandoc能够更好地支持“希望支持切角”，希望“把ACM SIG的论文格式改成IEEE Computer的论文格式”这样的语句，也许更好一些。或者，Pandoc最终能够做到“指定纸张大小”，“指定一个文类”，然后作者就可以只关心要写的内容了。 考虑到实际情况，个人希望在Pandoc与Hakyll里能够解决如下的问题： 1.处理LaTeX的更多的块。比如说，处理abc、theorem、definition等环境。 2.能够方便地定义LaTeX命令。 3.排版图片与表格的时候可以更简单一些。 4.能够更方便地绘制各种图表、示意图。 当然，这些问题有些并不是单独用Pandoc或者Hakyll来解决的。但是至少以后期望这些功能可以以一种更完整的方式集成在pandoc的markdown格式中。 已完成的事情、未完成的事件与展望 最近的作业特别多，时间也比较紧张。所以就先把个人主页弄到这里。有时间再添加内容、编写文档处理程序。 目前完成的事情是使用ssh就把主页上传过去，主页有master和source两个分支，分别用来保存网站和源代码。然后把文档和Travis相连接。 如果继续的话，可能需要加强以下几个方面的能力： 熟悉在Github上面的开发流程。了解在多个人员参与的情况下，代码该怎样提交；出现突之后怎样解决；以及更好地使用Travis CI或者Trello等工具实现软件测试、质量评审 了解一些HTML+CSS+JavaScript的知识，这是能够建立稍复杂一点的个人主页的基础知识 了解Pandoc的语法格式，能够熟练地写出Filter；能够熟练改变Pandoc的LaTeX模板、HTML模板 把Hakyll看成是Pandoc的构建工具。能够写出自己定制的文档编译器的cabal包。能够将其安装到系统当中，能够生成多页的HTML、生成一个LaTeX工程（多文件），比latexmk更方便地编译latex代码 在文档编译器自己定义的基础上，能够在Pandoc中把TikZ图形、abc音乐、minted代码，定理、参考文献等在HTML格式与LaTeX格式中同时排版出来。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Agda语言介绍]]></title>
      <url>%2Fagda-lang%2F</url>
      <content type="text"><![CDATA[Agda语言是使用了依存类型的函数式编程语言。最初发表于2007年，是在Ulf Norell的博士论文里面。目前实践当中，函数式语言中使用依存类型还不多。但是依存类型在可以预见的未来内会继续发展。目前发展依存类型的函数式语言的动力在于形式证明。目前的版本是Agda2，基本上是重写了。Agda2不像Coq的地方在于，Agda没有对于tactics与函数式proofs的支持。Agda 2语言有对于数据类型、模式匹配、记录、模块、Haskell语法的支持。Agda 2是基于Zhaohui Luo的UTT类型理论，与Martin-L&quot;of类型理论（也就是直觉类型论）有一点的不同。 Agda的值得提及的特性有归纳类型定义（这在Coq中也存在）、依存类型的模式匹配机制（允许在依存类型系统下使用模式匹配）、元变量（允许变量在运行的时候被细化和修改，因此支持程序在运行的时候增量构造，部分代替了tactics在Coq中的作用）、证明自动化（通过反射实现，以及允许程序在5s内枚举可能的证明），以及终止检查（因为Agda是一个完全的语言，能够保证每个程序都必然终止，以此保证语言的一致性，借助于Foetus termination checker实现终止检查）。 Agda和Coq等“后现代的编程语言”一样，对Unicode的变量支持很好。（相比之下，我们认为Haskell、Scala是属于所谓的现代编程语言）。Agda支持三种编译器后端：MAlonzo（输出Haskell）、JavaScript后端，以及Epic后端。关于Agda的论文与理论研究在这里自己就不总结了。 Agda语言的安装是比较简单的。可以直接在ubuntu下面使用apt-get安装。但是建议的安装方式是使用hackage的cabal install agda，因为它是用Haskell写成的。 自己学习Agda目前主要是根据《Dependently Typed Programming in Agda》http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf。里面强调的是其依存类型的风格。Hindley-Milner风格的编程语言如Haskell与ML中，类型与值之间存在明显的分割。两者是互不相关的。但是在依存类型当中，值与类型是相互关联的。函数可以根据值返回不同的类型，但是又不同于动态类型的语言。 在Agda的理解中，典型的依存类型是\(n\)-维向量。若把不同的\(n\)-维向量看成是不同的，那么向理的类型必然依赖于参数\(n\)。C++的模块编程支持这种\(n\)维向量的风格，但是在Hindley-Milner的类型系统中，区别似乎是有些困难。通过这个例子可以看出，依存类型系统会更精细，而且也有可能为C++的模块机制提供一个理论基础。 依存类型在定理证明中的可能的作用是：值的属性当成是一个元素为使得证明的属值为真的那些类型。这样，依存类型的编程语言可以当成是逻辑语言使用。 Agda语言的每个源文件都由一个顶层的模块名称声明开始。此外，agda使用的扩展名是lagda，表示的是agda源文件里面支持了文学编程（其实我们也可以把文学编程看成是后现代编程语言的一种特性，Haskell就具有这个特性）。Agda的文件名与模块名保持一致（像Java那样）。 Agda与Haskell与ML一样，支持对代数数据类型进行模式匹配（但是一般介绍Agda语言的书中，刚开始的时候还是介绍简单类型的函数式数据类型的匹配，而把依存类型的匹配规则放在最后）。数据类型使用data关键字来声明。比如声明一个布尔类型为： data Bool : Set where true : Bool false : Bool 声明中，Bool的类型是Set，Set是小类型的类型（因为Agda支持把Set这个类型当成是Set1的一个元素，也就是支持层次化类型）。此外，Agda的函数定义语法（不动点定义）与Haskell也是很像的，比如Bool的not函数： not : Bool -&gt; Bool not true = false not false = true 不过，not的类型声明其实不是必须的。 另外一种定义是采用归纳定义一个类型定义，比如自然数的定义： data Nat : Set where zero : Nat succ : Nat -&gt; Nat _+_ : Nat -&gt; Nat -&gt; Nat zero + m = m succ n + m = succ (n + m) _*_ : Nat -&gt; Nat -&gt; Nat zero * m = zero succ n * m = m + n * m 这种定义是允许的，但是为了保证合理性，应该加上一个n &lt; succ n的断言。 甚至函数的定义也是基于模式匹配的，比如定义if_then_else为： if_then_else_ : {A: Set} -&gt; Bool -&gt; A -&gt; A -&gt; A if true then x else y = x if false then x else y = y 这样我们就定义了一个if_then_else函数，而且可以把变量加在中间。如果需要声明中缀函数，以及指定中缀函数的优先级，可以使用infixr关键字。另外，像Haskell与ML一样，Agda允许含参数据类型，如： infixr 40 _::_ data List (A : Set) : Set where [] : List A _::_ : A -&gt; List A -&gt; List A 上面的List是一个含参类，除此之外，由于Unicode特性，变量可以包含任何的符号。 Agda的依存类型的函数 Agda的依存类型的函数的声明并不特别之处，也是使用(x:A)-&gt;B来声明这个变量。不过，由于指定了变元x，所以类型B是可以包含x作为变量的。此外，由于Agda的类型层次结构，所以一个类型的元素也可以是一个类型。 identity : (A : Set ) -&gt; A -&gt; A identity A x = x zero&#39; : Nat zero&#39; = identity Nat zero 上面的函数接受类型\(A\)以及类型\(A\)的一个元素为参数，然后返回相应的元素。再来一个非平凡的例子，这个例子创建了一个apply函数： apply : (A : Set)(B : A -&gt; Set) -&gt; ((x : A) -&gt; B x) -&gt; (a : A) -&gt; B a apply A B f a = f a 对于依存函数类型，有一些简便的记法可以使用，比如 (x : A)(y : B) -&gt; C for (x : A) -&gt; (y : B) -&gt; C (x y : A) -&gt; B for (x : A)(y : A) -&gt; B 具体的运算，可能要参考依存类型\(\lambda\)-演算来解决。函数式语言在处理可选参数的上面可能没有一些命令式语言直观。但是Agda提供了缺省参数的情况，这样一个函数可以应用在不同参数数目的场合。 Agda使用如下的方式声明\(n\)-维向量： data Vec (A : Set) : Nat -&gt; Set where [] : Vec A zero _::_ : {n : Nat} -&gt; A -&gt; Vec A n -&gt; Vec A (suc n) 上式表示Vec A是一个Nat-&gt;Set的映射，所以Vec A n得到一个具体的类型。 个人感觉，Agda的设计体现了对模式匹配与类型系统的大的发展。我们可以参考一下。这样我们遇到再奇怪的编程语言的时候也就不再感到奇怪了。Agda还可以导入Haskell的模块。agda的输入输出也是基于单体的。 Agda的文学化编程 Agda的文学化编程与Latex是类似的。不过agda程序可以使用–latex来输出一个tex文档，这样的话，可以实现许多的排版的功能。文学编程功能与Haskell是一样的。 lagda可以看成是一个.lhs文件，它可以由lhs2tex来处理。 agda的vim高亮可以参考https://github.com/derekelkins/agda-vim.git。 http://stevebob.net/agda-environment/上介绍了Agda的入门程序。包括在ubuntu下面安装一直到使用。 编译agda的时候，要想连接到相应的库，使用 agda -c -i /usr/share/agda-stdlib -i . hello.agda agda的编译器是通过调用Haskell来实现的。 http://blog.oxij.org/2011/12/22/howto-get-started-with-agda/上介绍了怎样开始Agda。不过是2011年的。关键的不是自己写出来一个Hello World，而是怎样让别人在网上写的复杂的教程，或者是一个实际的工程在自己的计算机上跑起来。写这篇博文的是教本科生Haskell的老师。但是作者也想利用Agda。看起来，研究生的阶段不是学习Agda，而是真正地理解其背后的依存类型、归纳数据类型等的原理与实现。（其实自己理想中，所有的形而上学的知识都应该是在大学完成的。但是很多时候，研究生的阶段我们尚未完成）。作者那个时候也认为，本科生理解Agda是几乎不可能的。 作者对于高级编程语言的看法： Advanced programming language requires advanced tools. 比如说，有企业级的开发环境（IDE、自动编译、调试、符号表查找、版本控制）。此外，也可以是最简单的一个文本编辑器。 不过，Agda的程序比较特殊，通常这些代码并不运行，甚至不进行编译，我们只是想对它们进行类型检查。对于Agda来说，调试也是没有用的。也根本没有调试器。 此外，为了使用Agda，还得有一种方便的方式输入Unicode字符。不过，大部分编辑器中，实现这个功能可能是非常复杂的。 写Agda代码也会不同于以往，因为一般有的时候，一天也写不到25行Agda代码。因为需要Unicode，而且目前Agda提供的也只有Emacs，所以不会Emacs就已经把大部分的程序员阻止在外了。 确保安装了如下的程序： cabal install agda ## 打开软件包，并安装agda-libs cabal install cabal install Agda-executable 然后配置~/.emacs文件： (load-file (let ((coding-system-for-read &#39;utf-8)) (shell-command-to-string &quot;agda-mode locate&quot;))) 打开emacs，使用C-x C-f打开一个编辑的文档。配置Emacs环境的方法有很多。但是必须在Emacs下面工作不可。否则，是没法写出合法的Agda代码的。 Agda程序写出来有什么样的作用：其实跟Haskell差不多，Agda程序也从Main开始。 Agda的用法[06-30-2015 16:46:01] Agda的一种用法是作为一个交互式的定理编辑器，或者说辅助定理证明器。不过，其实没有意义，是因为这些应用中，看不到使用它们证明了什么样的数学的定理。所以，感觉好像真的是没有什么用途。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Erlang编程语言中的并发小测试]]></title>
      <url>%2Ferlang-concurrency-test%2F</url>
      <content type="text"><![CDATA[已经接触了很多的编程语言。大概分成Lisp一系的、Haskell一系的，Erlang一系的、JVM一系的、C#一系的，以及OCaml一系的语言。但是自己感觉，分类上，可能还是按照类型的动态与静态，是否是纯函数式的，是否支持面向对象特性，是否支持自动类型推断（其实现代编程语言大概都支持了），求值的时候是否是惰性求值的，以及对于并发和并行的支持等。函数式语言的特性大概就这么看。其它的方面，说是语言的包管理系统、编译环境与版本控制。如果是在虚拟机上，那么对虚拟机上的原生语言的支持等。 看到这么多编程语言，自己感觉很多的设计模式都是内置在函数式语言中的，比如自己设想的在改变一个变量的时候，同时产生一种日志记录，已经在Clojure中完美实现。其它的语言特性也很多。 Erlang上面还建立有Eixir编程语言。语言更进一步。Erlang是运行在EVM虚拟机上的。有个时候，一些并发处理的机制与面向对象其实是不谋而合的。由于设计模式已经融入其中，自己感觉，设计模式是一种比较高级的抽象了。 Erlang是一种通用的面向并发的编程语言，它由瑞典电信设备制造商爱立信所辖的CS-Lab开发，目的是创造一种可以应对大规模并发活动的编程语言和运行环境。Erlang问世于1987年，经过十年的发展，于1998年发布开源版本。Erlang是运行于虚拟机的解释性语言，但是现在也包含有乌普萨拉大学高性能Erlang计划（HiPE）开发的本地代码编译器，自R11B-4版本开始，Erlang也开始支持脚本式解释器。在编程范型上，Erlang属于多重范型编程语言，涵盖函数式、并发式及分布式。顺序执行的Erlang是一个及早求值, 单次赋值和动态类型的函数式编程语言。 使用Erlang来编写分布式应用要简单的多，因为它的分布式机制是透明的：对于程序来说并不知道自己是在分布式运行。Erlang运行时环境是一个虚拟机，有点像Java虚拟机，这样代码一经编译，同样可以随处运行。它的运行时系统甚至允许代码在不被中断 的情况下更新。另外如果需要更高效的话，字节代码也可以编译成本地代码运行。 Erlang的设计中采纳了一些Prolog与Smalltalk中的东西。个人感觉，在处理并发问题的时候，还是不得不接触Erlang，就像在函数式语言中不能离开Haskell一样。 Erlang的并发测试环境设计 Erlang在安装好之后应该进行分布式集群的创建的工作。每个结点上可以开启一个。安装完Erlang之后，首先应该配置Cookie，因为同一个集群当中的Erlang，应当有相同的Cookie。以juju为例，在所有的结点中执行如下的操作： ## Install Erlang packages juju run --all &quot;sudo apt-get install -y erlang-base&quot; juju run --all &quot;echo just_for_test &gt; .erlang.cookie&quot; juju run --all &quot;chmod 400 ~/.erlang.cookie&quot; 上面的代码在每台机器上安装Erlang环境的同时，把各台机器上的Erlang Cookie都设置为just_for_test（以便它们都位于同一个群组中。然后正确设置cookie的权限。 接下来，我们要在每台机器上运行epmd进程，它负责映射符号名到机器地址。 juju run --all &quot;epmd -daemon&quot; http://gashero.yeax.com/?p=67中讲到了Erlang在单机环境中的应用和配置。 Elixir的连接与Erlang类似，但是还是有一些不同。 开启结点的话，可以使用 juju run --all &#39;erl -name $(hostname)@$(hostname).107.maas -detached&#39; 运行成功之后，可以在同一个网络中登录其中的一个结点并进行测试： erl -name test@node01.107.maas &lt;&lt;EOF net_adm:ping(&#39;node06@node06.107.maas&#39;). nodes(). EOF 经过ping之后，应该能够发现原来的结点。（实际上是这样的连接建立之后，整个Erlang上面的结点能够互相发现。不一会儿，结点就会加入Full Mesh的Erlang结点网络）这样一个Erlang分布式环境就搭建成功了。但是应该说，在这个平台上实现分布式的Erlang程序还是不够的。因为故障容错等都还需要额外的努力。需要一些特别的机制。 在配置过程中，注意有相同的Cookie才能加入同一个Erlang群组。通过 rpc:call(&#39;node01@node01.107.maas&#39;,erlang,now,[]). 可以测试在指定的结点上执行代码。其中，Erlang的结点之间自动连接是默认的选项，当然可以在启动Erlang的时候使用相关的选项禁止自动连接。手动连接使用net_kernel，示例如下： net_kernel:connect_node(&#39;node01@node01.107.maas&#39;). Erlang的编译工具Rebar[06-12-2015 22:09:11] Rebar是Erlang的编译工具，相当于sbt。见https://github.com/rebar/rebar。不过，rebar主要用于Erlang下面的OTP应用。中文也有一些参考的资料。 此外，sensor_cloud的示例也接触了一些。接下来要继续的是学习cavin的wiki。https://github.com/EricssonResearch/calvin-base/wiki。以及这篇论文http://www.sciencedirect.com/science/article/pii/S1877050915008595。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Elixir：建立在Erlang虚拟机上的函数式语言]]></title>
      <url>%2Felixir-lang%2F</url>
      <content type="text"><![CDATA[Elixir是建立头Elrang虚拟机上的函数式、并发的、通用的编程语言。Elixir是一个BEAM（Erlang虚拟机的名称）上面的一个比较新的编程语言。Elixir的思想是所有的事物都看成是表达式。现代编程语言通常都具有开些诸如泛型编程、函数式编程、面向对象编程，对并发、并行、异步、非阻塞都有很好的支持，支持多态特性。在函数式编程方面上也支持模式匹配。类型系统当然更为严谨。此外，模式匹配、惰性求值、unicode支持、多态、文档注释甚至文学编程特性、高阶函数也往往都具备。 Elixir的REPL环境是iex命令。Elixir的语言的扩展名是exs。 Erlang的虚拟机的配置是 erl -name node06@10.0.0.151 --cookie a 同样地，自己希望在Elixir中也可以采用集群的方式管理和安装。比如如下的代码： juju run --all &quot;wget http://packages.erlang-solutions.com/erlang-solutions_1.0_all.deb &amp;&amp; sudo dpkg -i erlang-solutions_1.0_all.deb&quot; juju run --all &quot;sudo apt-get update&quot; juju run --all &quot;sudo apt-get install elixir&quot; 这样就安装好了Elixir环境。然后就是配置程序语言了。不知道与Erlang同样基于BEAM虚拟机，是否可以同时启动Erlang环境与Elixir环境。结果是，确实是这样，如果一个Erlang虚拟机启动了，Elixir也能够连接到Erlang结点。 Erlang的各个结点加入之后，使用 iex --name elixir@node01.107.maas 来创建一个Elixir结点，然后使用 Node.connect :&#39;node06@node06. Node.list 如果要开启多个结点，可以使用这样的模式： juju run --all &#39;iex --name elixir@$(hostname).107.maas --detached&#39; 来查看Erlang/Elixir已经接受的虚拟机的结点。但是需要注意的是，虽然它们共用同一个结点，但是Elixir的程序的代码与Erlang的程序的代码却是不通用的。也就是说，iex能够发现Erlang的结点，但是在Erlang的结点上spawn程序会造成问题。因此，elixir只能在elixir的结点上分配程序。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ElasticSearch搜索软件]]></title>
      <url>%2Felastic-search%2F</url>
      <content type="text"><![CDATA[这里参考了Gitbook上面中文翻译的https://www.gitbook.com/book/fuxiaopang/learnelasticsearch/details。也就是ElasticSearch权威指南。自己觉得现在正面临的问题，也就是在文档中说的：已经被数据淹没，我们创造的系统产生的数据可以瞬间轻而易举地将我们压跨。现在的科技只是致力于如何存储数据，并能将拥有大量信息的数据仓库结构化。而一旦我们想从大量的数据中得出结做做决策的时候，美好的一天就要被毁灭了。不可否认的是，没有数据分析，数据确实要成为一种负担了。所以，我们必须建立能够分析数据的工具，帮助我们从数据中得到知识，得到决策的依据。 ElasticSearch适用于全文搜索、结构化数据的实时统计。Elastic并不只是全文搜索，还具有结构化搜索，统计、查询过滤、地理定位、自动完成等。ElasticSearch也可以应用于生产的环境。所以对我们而言是比较合理的。自己理想中的文献检索，特别是学术文献检索系统，也应该就是这样的。个人感觉，希望ElasticSearch成为自己一生的小伙伴。 ElasticSearch安装之后会开启一个服务器，监听9200端口。类似于安装之后直接开启一个网页的应用程序现在变得越来越普遍了。可以说，任何一个分布式的软件，都集成了网页前端与Web Service的功能了。ElasticSearch采用分布式的设计。每个运行的ES（ElasticSearch的简称，下同）实例称为一个结点。具有相同的cluster.name的结点构成一个集群。同一集群下的结点协同工作，互相分享数据，提供了故障转移与扩展的功能。一个节点单独也可以进行工作。 ES的客户端有两类。一种是节点客户端，它以一个无数据节点的身份加入集群。这个节点不存放数据，但是节点本身由于知道什么数据在哪一个节点上，所以它可以执行转发的功能。另一类客户端是传输客户端。本身不是集群的一部分，但是可以把请求转发到集群中的结点。这两个客户端所使用的端口是9300。现在要求Java的客户端的版本号必须与ES节点所使用的版本号一样（这是Java类库的问题）。如果是其它的语言，可以通过9200端口上的REST服务与ES通信。 ES是面向文档的数据库。它不仅存储整个对象或者文档，而且还为他们建立索引，以便我们通过ES搜索。ES还在索引与搜索的基础上实现了排序与过滤的功能。学习使用ES的很基础的工作就是学会JSON与JSON上面的查询DSL。只有这样才能了解数据处理的功能是如何的。 但是从企业架构的角度考虑，搜索只是实现一种功能。建议的架构是，使用mongodb存储数据，然后借助于元数据挖掘工具，从文档中得到文本，把文本送到ES搜索。然后用户在点击的时候，直接返回一个文档即可。Solr与ES都是索引文档的内容。Solr对文档的索引有内部的支持，然而ES还需要一个插件。SOlr与ES都使用Tika作为元数据挖掘的工具。虽然Solr与ES都具有存储文档的功能，然而目前非常不推荐将它们作为主要的存储单元。甚至把原始文档放在本地文件系统中都比放在Solr或者ES中要好。在实现中，ES与Solr通过一些扩展都可以实现元数据存放的功能。（从实用的角度看，个人的文档管理系统确实应该是把存储与搜索放在一起。但是目前个人软件并不能赚钱，需求也不好定位，所以，实践中，都是按照企业的要求设计软件，因此不建议把存储和全文搜索都放在一起。）。总而言之，现状上，它们都支持Mongodb一样的二进制文件存储，经过一些配置也都可以实现文档的全文检索。但是不建议使用。 http://stackoverflow.com/questions/10854858/best-practices-for-searchable-archive-of-thousands-of-documents-pdf-and-or-xml/10861308#10861308上面介绍了搜索上千PDF或者XML文档的最佳实践。我们可以参考一下。要使文档都能够通过Web UI界面搜索，现在还存在文档格式复杂繁多的问题。但是对于一般的文档来说，实现“搜索PDF的哪一页具有什么样的文字”可能还是具有一些挑战的。可能为大多数的文档建立一个统一的模型，能够描述文本在文档中的位置、页数是比较迫切的。 ES可以通过附件的形式返回一个完整的文档。但是作为附件的话，可能没有全文搜索引擎的功能。因此比较好的解决的方案是使用Tika做预处理的工作，把文本与元数据挖掘出来，然后使用它进行搜索。在文本搜索的领域，可能目前也就只能这样的。但是我们知道目前的发展的趋势是很多的。比如，多媒体数据的搜索。Sunspot与RSolr这样的工具，对Solr做了进一步的封装，能够处理大多数的文档格式。为了保持性能，在70K这样的级别的程序中，把文本从PDF中挖掘出来，然后把文本存到SQL或ES中。这样在性能上也是可以接受的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Apache的企业搜索工具]]></title>
      <url>%2Fsolr-and-lucene%2F</url>
      <content type="text"><![CDATA[企业级的应用相对于普通的软件相比，体现了更多的理性，体现了更多的需求的驱动。对普通的程序员来讲，学习企业级的软件提供了一个从底层的程序员上升到资深架构师的问题。不同层次的程序员，思考问题的方式也不一样。到了架构的层面，更多的时候讨论的是架构的缺点与优点。这个时候，根本不是一味地讨论程序有哪些功能。技术不等于产品，产品不等于市场，市场不等于盈利。但是一般程序员做的，只能是基本的技术。掌握架构师的技能，大概是可以做到高级的技术、产品以及市场。 不多说然它的事情。今天的主要的目的是帮助实现一个全文搜索引擎。全文搜索引擎在企业中的应用可以说是信息检索的一个重要的应用。整个的框架的部分为自然语言处理等奠定了基础。没有人工智能的时候，可以是传统的检索的方式。有人工智能与自然语言处理的时候，可以以插件的形式提供新的功能。但是这个架构是稳定的。 通过查找网络上的资料。比较有名的企业级应用的全文搜索引擎有Apache Solr、Sphinx、Elasticsearch等。其中，除了Sphinx，都是基于Lucene的。Java平台上还有所谓的Hibernate Search。一个技术到达企业级别的应用，一般而言是在编程与布署的层面上做一些更大的问题。比如，Lucene作为信息检索基础库，在编程层面上就可以做，许多软件的帮助文档就是使用Lucene作为索引的。但是到了企业级的应用上，Lucene就只是一个基本的IR（Information Retrival）库了。在Solr上面可能有更多的集成。所以，目前我们把Solr和Lucene的分界面看成是编程与架构的分界线。并以Lucene作为案例分析编程与架构是如何关联的。 本章的计划是，首先介绍Lucene在信息检索中的基础功能与用法，然后讲解Solr等全文搜索引擎在企业搜索中的应用。再然后是讨论一下为什么全文搜索是必要的。以此为机会，了解编程是如何走向商业实践的，掌握怎样的技术才能够把握技术发展趋势。 Lucene软件介绍 Apache Lucene是一个开源的IR软件库，原始版本是由Doug Cutting在Java语言之下写成的。目前以Apache Software License发布。目前Lucene程序已经移植到Delphi、Perl、C#、C++、Python、Ruby与PHP等多种语言。（这种移植可能是按照Lucene的架构在另外的语言中重新设计它，而不是简单提供一个接口那么简单）。 Lucene原始版本写于1999年。当时是一个SourceForge项目。后来加入Apache软件基金会，并于2005年成为Apache的一个顶级的项目。Lucene曾经包括许多的子项目，如Lucene.NET、Mahout、Solr、Nutch。现在Solr已经独立出来，而Mahout、Tika等项目也已经成为独立的顶级项目。4.0版本是2012年至2015年主要的开发版本。而2015年Lucene升级到了5.0版本。 Lucene所满足的应用主要有两个方面。第一个方面是应用程序对于全文检索数据的需求，第二个方面是对于单机或者互联网的个性化的数据集上的搜索的需求。比较典型的应用有，Eclipse的帮助子系统使用Lucene作为全文搜索引擎；Apache的网站使用Lucene作为全文检索的引擎。 Lucene的核心逻辑架色是把一个文档document看成是由fields文本构成的结构。这种结构使用Lucene的API独立于文件格式。因此，从PDF、HTML、Word、Open Document中抽取出来的文本都可以被Lucene所识别。对于许多的格式，只要它们的文本信息能够被抽取出来，Lucene就可以利用它构建全文引擎。 这里，我们对Lucene的功能深入思考一下。首先，音乐、图片、视频等信息基本上与Lucene没有什么关系，因为里面没什么文件信息。其次，Lucene是假设文件信息已经从PDF等文件格式中抽取出来，Lucene项目本身并不设计这样的抽取器。另外，Lucene本身并不包含HTML挖掘与解析的功能。但是有一些上层的库可以弥补。比如Apache Nutch提供了HTML抽取（挖掘）与解析的功能、Apache Solr与Elasticsearch这两个企业级的搜索服务器提供了完整的架构。还有Compass、DocFetcher、Swiftype、Kinosearch、Apache Lucy、Luke等工具也对Lucene做了不同程度的补充。 应当注意的是，信息检索程序虽然与搜索引擎有关，但是两者仍然是不同的概念，不应该混成同一个东西。 Lucene实现的特点 Lucene具有如下的特点： 索引格式独立于应用平台。Lucene的索引文件格式是内部定义的八字节为基础的格式，不受不同的系统与不同的平台的影响。因此应用程序能够共享建立的索引文件。 在传统全文检索引擎的倒排索引（不是由记录来确定属性的值，而是由属性值来确定记录的位置。这种索引的索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址，这种方式正好与数据库中的索引相反）的基础上，实现分块索引（针对新的文件建立小文件索引，提升索引速度，然后与原有索引合并）。 采用面向对象的思想与架构设计，方便扩充新的功能。 设计了独立于语言与文件格式的分析接口。用户可以通过实现文本分析接口来扩展新的语言和文件格式。 默认已经有一套强大的查询引擎，实现了布尔操作、模糊查询、分组查询等功能。 面对已经存在的商业的全文检索引擎，Lucene也具有相当的优势。比如开源发行、方便扩展、可以扩展支持中文、扩展支持HTML与PDF等格式。 Lucene的工作的时候采用的是索引检索。因此，可以把任务分割成建立索引与基于索引的查询两个阶段。在建立索引的阶段，做一些指定索引文件位置与索引特性的选项，然后添加字段。在查询索引的阶段，读取索引文件，设置查询格式，然后输出结果。Lucene的操作的对象是很明确的，就是文件系统当中的文件作为索引文件。运行的计算模型是传统的单机模式。 Lucene不是一个看爬虫。如果需要爬虫功能的话，应该参考Nutch；Lucene也不是一个完整的应用，若需要，应该参考PoweredBy；Lucene也不是实现了PageRank等算法的链接分析算法库，若需要后者，应该参考Nutch与Hadoop。它只是一个实现了基于文本的搜索的算法（在其上可以施行PageRank与Arc等链接分析算法）。 Lucene的一个Index是文档的集合Collection；一个文档是Fields的集合；一个Field则由描述文本内容的metadata构成。一个Field里面可以包含多个属性。 Lucene上面的编程任务可以分成两类。第一类是写代码以将Documents添加到index当中；第二类则是写代码将用户的查询转换成Lucene查询，并写Lucene提交查询，然后显示结果。整个的流程可以看成：围绕Index文件，一方面是提取文档元数据，把元数据通过IndexWriter添加到Index文件中。另一方面，通过IndexSearcher查询Index文件。 Lucene本身并不关心文件的格式。因为文件在添加之前，都要构造出一个索引字符串，不论被索引的文档是PDF还是纯文本。这样以来，Lucene必须结合一些好的开源的文档格式抽取器（如Tika）。在搜索的阶段，Lucene Query Parser把字符串转换成一系列的编程对象，由这些对象支持查询。 在从文档构造Index文件的过程中，需要经过“分析”。分析的任务是将原始的文本转化成可被索引的记号流。Lucene使用Analyser、Tokenizer与TokenFilter类负责这些任务。其中TokerFilters就是细节性地修正产生的Token了。 除此之外，Lucene还有一些高亮匹配文本、拼写检查、查找相似页面等功能。Luke是其上的一个前端。可以用它来查看索引文件，并执行相关的查询。 Solr介绍 Solr于2006年成为Apache的一个项目。目前常把Lucene与Solr放在一起讲述。目前的搜索模型有许多种，布尔模型、向量空间模型、语言模型、概率模型等。向量空间模型用得大概是最多的。经典的TF-IDF方法就是其中之一。Lucene的模型是修改过的向量空间模型，采用这样的原理检索文档。 Solr是一个开源的企业搜索服务器。基于Lucene。具有XML/HTTP API。在工作的时候支持cache、replication、web管理等功能。Solr实现中，借鉴了许多Lucene的最佳实践。方便扩展，并且安装与配置都很方便。在客户端方面，还设计了针对许多语言的接口。Solor的安装与启动都很简单。流程是：下载、运行。想要建立索引的话，cd到examples docs目录下，运行 java -jar post.jar *.xml 就可以了。 Solr的schema.xml描述了用户的数据与数据是怎样被处理的。它还允许用户添加除了字符串以外的一些类型（整型、浮点等）。solrconfig.xml文件描述了用户是怎样与数据交互的。配置了数据放置的位置、性能选项、以及允许的操作权限等。（企业级的应用中，许多的可选项一般是必然需要的）。 在Solr中添加索引一般需要客户端通过HTTP发送XML格式的文档表示添加索引的企图。通过HTTP与XML格式请求，客户端也可以完成删除文档、更新文档的操作。同样地，想要搜索文件，也通过客户端连接HTTP的方式请求指定的URL。Solr也有高亮、更多、拼写检查等功能。 Solr的高级功能有支持提高查询效率的副本功能、负载均衡、缓存等。Lucene采用的是嵌入到应用程序里面进行工作，而Solr采用的是作为单独的网络服务进行工作。 想具体测试Solr的性能，可以使用HTMLUNIT（Google）等工具。Solr的典型的使用场景是在Lucene索引文件的基础上，建立一个Solr Search Server。然后把它布署在HTTP Server应用服务器之上，用户通过访问应用服务器，间接使用Solr的服务。 至于传统CMS想使用Solr作为索引，则可以使用Curl与XSTL工具先进行转换，然后以XML的格式存到Solr当中。 在语言支持上面，Scala的Play框架可以异步调用Solr查询引擎。the play.api.libs.ws.WS library to call Solr and use Plays JSON support to extract the result (like in the example below) or is there any easier/faster way。网上有一些已经存在的好的实践方式，自己可以吸纳它们在Scala中是如何与Solr交互的。 Solr与自己的应用集成的时候，总是通过构造XML格式的添加文档、删除文档等命令实现。只要应用程序知道Solr服务器的URL就可以做到了。值得注意的是，Solr应当配置为utf-8编码，返回的结果也要使用utf-8转码。 注：Apache有一个叫OpenEJB的开源项目。似乎也值得一试。http://www.crawl-anywhere.com/上面给出了一个基于Solr的爬虫设计器。Mahout现在是用于机器学习，特别是用于协同过滤。在Mahout上面还有所谓的Giraph，用于图模型。 Apache的Solr官方网站上有Solr的快速入门及参考手册。但是在Solr快速入门中，介绍的最初的方式是纯文本的东西，比如XML、JSON、CSV格式的文档的查询。http://www.ibm.com/developerworks/cn/java/j-solr-lucene/#download上面的教程似乎更具有参考性。IBM上面提到了搜索引擎的新的用法。因为之间我们的理解都是搜索引擎用于搜索文本。但是Solr 4.x开始，发现了新的应用的需求。搜索引擎的核心被定义为关乎快速的、高效的过滤，然后依据某种相似度的概念对数据进行归类。搜索引擎还要能够处理稀疏数据和模糊数据，这此数据是现代数据应用程序的标志性特征。Lucene和Solr实现了各种灵活的相似性算法，还能够分析地理空间问题。这些功能使得搜索应用程序与传统的数据库应用程序（甚至是NoSQL应用）之间的界线。现在的Lucene与Solr可以说是不仅集成了数据后端（因而成为一种NoSQL），还可以自己定义复杂数据类型、数据存储、归类与分析功能。虽然搜索引擎不能解决所有的数据问题，然而我们仍然应该跳出众所周知的思维模式。 其实，很多的数据应用都是借助于搜索与简单的分析可以解决的，并不需要那么严谨的科学研究的模式。 欲使Solr支持PDF，还需要一些配置。参考https://wiki.apache.org/solr/UpdateRichDocuments 。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[在Debian/Ubuntu系统下面的Java与Scala包]]></title>
      <url>%2Fscala-sbt%2F</url>
      <content type="text"><![CDATA[Java包目前在Ubuntu下面的管理 目前的情况是，许多的Java包也安装在系统当中，在系统中的路径是/usr/share/doc、/usr/share/java以及/user/share/maven-repo。三个路径中，/usr/share/java里面用于放置所需要的库，我们可以通过apt-get source libjdom1-java，并在当前目录下解包这个文件，然后就知道jdom1这个jar包是怎样被安装到系统当中去的了。 这里有一个官方的“为Java库构建deb安装包” https://wiki.debian.org/Java/MavenBuilder 的指南。思想是利用Maven构建一个deb安装包。 I think a better way forward is to write a little program that takes the source jar (which most jars in the Maven central should already have) and the POM, then generate a build script that simply compiles the source jar into the binary jar. The said program should also inspect the jar file to figure out any resource files, and treat them as source files. That way, we can machine-generate Debian source packages. Granted, not all source packages produced that way would pass the requirements of the Debian Freesoftware Guideline, but I bet substantial number of Maven artifacts are simple enough that this will be actually completely satisfactory. And then humans can concentrate on harder ones. 对于Debian的世界来说，推荐的方式是在有二进制包的同时，提供源代码包（bin形式的包，与doc、src、dev都是不相同的）。所以目前的maven的只下载二进制包的方式与Debian的理念有一些冲突。 而且，目前的Java的做法的冲突的地方，就是指定了一个Java的版本之后，必须只用当前的那一个Java的版本。比如2.11.5与2.11.6就是不通用的。然而在一般的软件版本管理系统中，同一个major之下，只要比所需minor大的版本应该都是可用的。 The Debian folks have a standard response for this kind of attitude: “Patches are welcome.” If you don’t like it, you have the power to fix it. If you fix it, share the fixes. Debian的理念是欢迎使用者在不同的情况下对软件作出修改。特别是，用户能够知道错误在什么地方，同时能够得到及时的反馈。如果应用程序出现一些错误，用户能够自己重新编译与测试这些东西。参考Debian社群契约https://www.debian.org/social_contract Java与Scala的ABI规范可以参考http://blog.ometer.com/2012/01/24/the-java-ecosystem-and-scala-abi-versioning/。上面详细说明了Java与Scala的API版本管理的策略。其实主要的版本改变之后，整个工程就升级为一个“元工程”了。这个工程重要的是工程的思想，而不是工程制造出来的产品实践。 https://wiki.debian.org/Java/MavenDebianHelper上面介绍直接根据maven工程生成deb包是很容易的，只需要mh_make命令就可以了。但是现在Ubuntu上面好像没有这个工具了。（现在又有了） http://www.scala-sbt.org/0.13/tutorial/Installing-sbt-on-Linux.html上面介绍了怎样在Linux发行版下面安装sbt。这里采用的是rpm/deb软件包的方式安装sbt。这是值得推荐的做法。但是并不一定每一个都是按照这种做法来做的。 生成maven的软件包可以参考所谓的jdeb与apt-repo工具，在github上面：https://github.com/tcurdt/jdeb。 Scala下面构建适用于特定系统的包 但是Scala下面的做法有了大大的不同，得益于scala-naive-packager工具。https://github.com/sbt/sbt-native-packager。它还是受到官方支持的sbt构建的方法。生成tar、rpm、deb等都不在话下。关于deb包的，可以参考：http://www.scala-sbt.org/sbt-native-packager/formats/debian.html。 sbt-native-packager可能的缺点就是它把依赖的jar包都放在程序当中，因此，整个程序显得非常拥挤了。其实按照集群来配置的话，/usr目录是放置软件的，没有必要每个结点机器上都安装一遍，那样也太占空间了。 我们来看具体的做法。 生成deb包被看成是构建任务的一部分。所以简化到使用一个plugin的程度。首先，我们指定sbt的版本： sbt.version = 0.13.7 然后，在project/plugins.sbt文件中添加如下的插件： addSbtPlugin(&quot;com.typesafe.sbt&quot; % &quot;sbt-native-packager&quot; % &quot;1.0.0&quot;) 之后，在build.sbt中启用相应的插件，并指定生成debian包的时候所需要的一些关键字段，比如维护者名称，开发者名称等。 name :=&quot;example-app&quot; version := &quot;1.0&quot; //enablePlugins(DebianPlugin) enablePlugins(JavaAppPackaging) 如果只想启用生成Debian包的功能，添加DebianPlugin模块就可以了。注意，这种方便性只能在sbt-native-packager版本不小于1.0，以及sbt版本不低于0.13.5的时候才能使用。 接下来，我们就要创建自己的应用程序了。比如TestApp.scala。这个文件的路径是src/main/org/scala/TestApp.scala。 object TestApp extends App { println(&quot;IT LIVES!&quot;) } 要构建相应的工具，则使用sbt stage命令。这个时候，在target/universal/stage目录下可以看到bin、lib等目录。缺省情况下，会为JavaApp创建一个shell脚本，以及一个.bat批处理脚本。 接着，使用sbt universal:packageBin，sbt universal:packageZipTarball可以创建相应的tar包或者zip压缩包。这个包就可以直接发布出去了。 构建适合于Debian的包 要想构建.deb包，直接的操作很简单，sbt debian:packageBin就是在target目录下生成.deb文件的最终命令。 然而，在生成.deb包之前，要对一些字段进行配置，如维护者的名称，邮件，软件的描述等。 packageDescription in Debian := &quot;Example Cli&quot; maintainer in Debian := &quot;Josh Suereth&quot; name := &quot;Debian Example&quot; version := &quot;1.0&quot; maintainer := &quot;Max Smith &lt;max.smith@yourcompany.io&gt;&quot; packageSummary := &quot;Hello World Debian Package&quot; packageDescription := &quot;&quot;&quot;A fun package description of our software, with multiple lines.&quot;&quot;&quot; 整体而言，这些字段不需要怎么理解，只需要自己填上去就可以了。 sbt-native支持debian:package-bin作为构建deb包的命令，debian:lintian作为使用lintian命令检查deb包是否正确的命令，以及debian:gen-changes作为生成.changes文件的命令。 为了在某种程度上能够保证软件包能够正常工作，在bulid.sbt中添加如下的依赖： debianPackageDependencies in Debian ++= Seq(&quot;java2-runtime&quot;, &quot;bash (&gt;= 2.05a-11)&quot;) debianPackageRecommends in Debian += &quot;git&quot; 如果还想自己编写DEBIAN的preinst、postinst等命令，直接写到src/debian/DEBIAN目录里面就可以了。 If you use the packageArchetype.java_server there are predefined postinst and preinst files, which start/stop the application on install/remove calls. Existing maintainer scripts will be extended not overridden. 这说明，Sbt对于布署Java服务器也有很好的支持。 完整的Debian配置文档，参考http://www.scala-sbt.org/sbt-native-packager/formats/debian.html。此外，http://www.scala-sbt.org/sbt-native-packager/gettingstarted.html还告诉我们可以使用windows:packageBin生成MSI安装文档。 sbt-native-packager生成的Java应用有两种，一种是JavaApplication，另一种是Java Server。前者是具有一个bash/bat调用接口，后者则除了有调用脚本之外，还有一些配置文件可以使用，还能够开机自动启动（不过目前还只是支持Fedora的systemd管理工具）。 注：Linux的服务管理机制很多。在Ubuntu下面，默认使用的是upstart，当然，也有systemV服务管理工具。Windows下面的，则是Windows Services程序来管理开机启动的各个服务脚本。 今天就先到这里吧。关于Python的软件包的配置，先放在后面再说。 Sbt配置nexus软件包的方法 类似于在maven中的添加软件版本库，sbt的方法是添加repositories的字段。注意里面的repositories的配置是在用户的.sbt/conf配置的repo.properties文档，内容为： [repositories] local nexus: http://127.0.0.1:8081/nexus/content/groups/public sonatype-snapshots: 然后在conf目录中的sbtconfig.txt中添加三行 -Dsbt.global.base=E:/sbt/.sbt -Dsbt.ivy.home=E:/sbt/.ivy2 -Dsbt.repository.config=E:/sbt/conf/repo.properties ## 可选的选项 -Dsbt.override.build.repos=true ## 这些选项也可以通过sbt_opts的环境变量进行全局的配置这样sbt执行的时候就不需要访问外网了。 之后从nexus的私服下载jar包。在nexus里面需要添加typesafe的仓库。http://repo.typesafe.com/typesafe/ivy-releases。但是注意一般还是要修改nexus虚拟库中的配置，需要把中央仓库放在最后，而把sbt的仓库放在前面。 不过nexus的配置也不是一件容易的事情。这些事情可以写成一本书了。比如http://my.oschina.net/guanzhenxing/blog/209600中介绍的配置nexus的数据库的原理。 http://www.tuicool.com/articles/vMnyIb上面告诉了我们scala的三个主站，分别是 安装Nexus后默认会有一个Public Repositories组，可以将其作为Maven的镜像组，并添加一些常用的第三方镜像： cloudera: https://repository.cloudera.com/artifactory/cloudera-repos/ spring: http://repo.springsource.org/libs-release-remote/ scala-tools: https://oss.sonatype.org/content/groups/scala-tools/ 对于Ivy镜像，我们创建一个新的虚拟组：ivy-releases，并添加以下两个镜像： type-safe: http://repo.typesafe.com/typesafe/ivy-releases/ sbt-plugin: http://dl.bintray.com/sbt/sbt-plugin-releases/ 另外一种方法是直接去配置~/.m2/settings.xml文档。或者maven目录下面的conf/settings.xml文件。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Julia类型系统与并发]]></title>
      <url>%2Fjulia-lang-types%2F</url>
      <content type="text"><![CDATA[一般认为有类型系统的编程语言分成静态类型系统与动态类型系统两大类。静态系统指的是每个程序表达式在程序执行之前都有一个可以计算的类型。而动态类型的类型，只是在运行的期间才被感知。面向对象的编程实践中，经常是在静态类型系统中添加一些灵活的机制。如果代码能够操作不同的类型，便称为是多态。在经典动态类型系统中，多态是显而易见的。 在理解动态系统的时候，需要注意binding与dispatch的区别。具体地说，绑定是把一个名子与一个类型关联起来，而dispatch指的是给出了方法，然后确定由哪个实现来执行这个方法。Julia’s type system is dynamic, but gains some of the advantages of static type systems by making it possible to indicate that certain values are of specific types. This can be of great assistance in generating efficient code, but even more significantly, it allows method dispatch on the types of function arguments to be deeply integrated with the language. Method dispatch is explored in detail in Methods, but is rooted in the type system presented here. 按照类型系统的理论，Julia属于那种dynamic, nominative, parametric类型。在Julia中，又有具体类型与抽象类型的区别。在Julia当中，所有的值都是一个真正的对象，而每一个真正的对象都有一个类型。整个类型系统是全连同的type graph。在Julia的世界中，“编译期类型”是没有意义的，因为只有“运行期类型”。 另外，在Julia中，只有值是有类型的，变量只是一个名称，具体地说，变量是与某个类型范围相绑定的名称而已。 在Julia中，也可以添加一些显式的类型声明，使用 :: 来表示。有时候，可以当成是运算符来对待，就像是关系运算符一样，比如(1+2)::FloatingPoint会引发程序错误，但是(1+2)::Int则会正常返回结果。也就是运算符的结果有两种：一种结果是引发程序停止，抛出异常，另外一种，就好像是完全不起作用一样。::相当于一个类型断言。 在出现变量的任何的地方，包括形参当中，都可以使用类型断言。 类型也是我们可以抽象地定义的。比如abstract name &lt;: supertype定义了一个上界为supertype的类型（不过，它到底算是一个类型变量呢，还是一个类型常量呢？）。上界有时候可以省略。（不过，也许这不成为问题，因为没有说类型系统的结构是一个线必序集，它只需要是一个偏序集就可以了）。抽象类型的超类是所谓的Any类型。 Thus, abstract types allow programmers to write generic functions that can later be used as the default method by many combinations of concrete types. Thanks to multiple dispatch, the programmer has full control over whether the default or more specific method is used. 另外，具体类型可能是指的在程序运行期间会占据值的那些类型。比如具体的无符号短整型数据。比如bitstype 16 Float16 &lt;: FloatingPoint就定义了一个具体的“比特类型”。 具体类型与抽象类型的区别可能在于，具体类型是负责实际的操作的，而抽象类型则提供的仅仅是检查操作合法性的功能。也就是抽象类型可以看成是纯粹的逻辑检查，但是具体类型则同时是与内存分配相绑定的。 Julia的类型可以进行组合，就像是结构体那样（其实语法与C的结构体类似）。 type Foo bar baz::Int qux::Float64 end 可以使用构造函数来产生新类，以及给某个类型的变量新的值。（不使用new方法）。 另外，如果定义的一个类型完全没有任何的成员，比如 type NoField end 那么，这个类型就对应着一个单件（singleton）。使用is(NoFields(), NoFields())得到的结果就是true(is用于判断两个对象是否是同一个对象）。 如果需要不可变类型，那么就在类型声明中，用immutable关键字代替type。看起来，不可变类型的每一次求值的时候都需要新的内存空间。但是其实问题没有这么简单。实现不可变类型的开销，可能并不比可变类型高多少。在Julia当中，可变类型是按照引用传递的，而不可变类型中通过copy来赋值的。这意味着把变量赋给一个可变类型的时候，并不会创建一个新的对象。 抽象类型、比特类型、组合类型是Julia的三种基本类型。此外，Julia还支持元组类型，也就是用(Int, String)来当成新的类型。这种类型之间也是可以比较的。另外，类型还可以合并起来，比如IntOrString = Union(Int, String)，表示这个东西为一个整数或者字符型。 为了支持泛型编程，Julia还有含参类型。含参类型有一个类型参数。比如 type Point{T} x::T y::T end 使用 Point{Float64} 可以构造出一个类。它就好像是Point这个类具有一个类型参数，当类型参数给出来的时候，Point类就调用它的构造函数，然后生成一个新的类型一样。注意Point是抽象类型，但是构造出来的是具体类型。 In other words, in the parlance of type theory, Julia’s type parameters are invariant, rather than being covariant (or even contravariant). This is for practical reasons: while any instance of Point{Float64} may conceptually be like an instance of Point{Real} as well, the two types have different representations in memory: 这真的应该参考类型理论了。 在Julia当中，函数是一个把一个参数元组映射一个返回值的类型。所以，在实践中，函数是非常抽象的类型概念。而在Julia中，把函数的实现，也就是把具体的执行看成是一个方法。显然可能会有多种对应。这种对应的过程称为分派(dispatch)。 The choice of which method to execute when a function is applied is called dispatch. Julia allows the dispatch process to choose which of a function’s methods to call based on the number of arguments given, and on the types of all of the function’s arguments. This is different than traditional object-oriented languages, where dispatch occurs based only on the first argument, which often has a special argument syntax, and is sometimes implied rather than explicitly written as an argument. [1] Using all of a function’s arguments to choose which method should be invoked, rather than just the first, is known as multiple dispatch. Multiple dispatch is particularly useful for mathematical code, where it makes little sense to artificially deem the operations to “belong” to one argument more than any of the others: does the addition operation in x + y belong to x any more than it does to y? The implementation of a mathematical operator generally depends on the types of all of its arguments. Even beyond mathematical operations, however, multiple dispatch ends up being a powerful and convenient paradigm for structuring and organizing programs. 里面提出一个不依赖于算术优先级文法的概念，比如x+y为什么调用的是x的方法而不是调用的y的方法？这个问题的提出的情景是这样的，对于一般的函数而言，可能应用的方法是很简单的，很确定，因为f(x,y)很容易确定是哪个函数。但是如果函数采用的是中缀的形式，那么问题就出现了。在出现中缀的地方，可能dispatch的意义更大。对于a f b这样形式的函数，我们知道f是一个纯粹的标签而已，但是这个方法是独立的方法，还是a的一个方法，或者b的方法。在多种可能的情况下，dispatch就显得必要了。 还有，如果参数允许多种类型的话，那么实际上函数代码中的行为也是不确定的。 function f(a,b) a +b end 对于这种情况，如果a是整数，那么+调用的是整型的+方法；但是a也可以是浮点类型，这样的话，就要调用不同的方法了。如果把+看成是一个方法的话，那么，确实+绑定的是哪一个方法是不确定的。但是在C++当中就没有这样的问题。 利用methods(f)可以查看当前的名子有多少种定义。比如+号，有92种定义。 table = methods(+) length(table) multiple Dispatch（多重分派）机制可以产生神奇的效果，比如 same_type{T}(x::T, y::T) = true same_type(x,y) = false 上面的代码实际上是两个函数的定义，但是前一个定义的优先级更高，所以使用这种方法，可以实现一个判断两个变量的类型是否相等的函数。但是实际的执行是这样的：如果两个类型相同，调用的是第一个定义的方法；如果是其它情况，就匹配到后一个方法。结果，这样就可以调用same_type了。但是定义的方式确实是很特殊的。从中我们可以很明显地看到，同一个函数，可以绑定到不同的方法，而且是在运行期间决定的。 判断是否是同一个函数有一些不同的标准。如果仅仅看名称，就是Julia这里的。但是数学上，也许更习惯把函数的参数类型也当成函数的一部分，那时候就有不同的处理的方式。不过在动态类型的语言中，区分“函数”与“方法”确实是有必要的。 具有可选参数的函数，实际上在定义的时候同时产生了几种不同的方法。 f(a=1,b=2) = a + b methods(f) 将会查看到f有三个方法绑定。（这种情况下，似乎只要定义函数的时候使用了模式匹配，并且分成了多个句子，似乎都可以看成是多分派的语言了）。 构造函数 在Julia当中，构造子被理解成创建新的对象的函数。这与面向对象语言有一些不同（面向对象倾向于把构造函数理解成类的初始化的过程）。不过，在函数式与面向对象的结合中，把构造子理解成创建新对象的函数确实是更好一些。 在函数式与面向对象的结合的过程中，区分外部构造方法与内部构造方法有一些必要。外部构造方法就是像函数式那样，由一个与类同名的，但是不属于这个类的函数构成。而内部构造方法，则在声明类型的过程中，在类型里面的那些与类同名的函数。 如何在类里面使用这个类的一个对象？这个看起来是很困难的。但是Julia允许这么做而不出现问题。 参数类型提升 这基本是和类型转换一个含义。关键在于是否允许自动类型提升。在分类上，Julia是属于那类不允许自动类型转换的语言。使用convert(Type, var)来进行显式的转换。 Julia的模块 模块使用module来声明，使用export来导出可被利用的函数，使用using或者import来应用。 元编程语言：The strongest legacy of Lisp in the Julia language is its metaprogramming support. Like Lisp, Julia represents its own code as a data structure of the language itself. Since code is represented by objects that can be created and manipulated from within the language, it is possible for a program to transform and generate its own code. This allows sophisticated code generation without extra build steps, and also allows true Lisp-style macros operating at the level of abstract syntax trees. In contrast, preprocessor “macro” systems, like that of C and C++, perform textual manipulation and substitution before any actual parsing or interpretation occurs. Because all data types and code in Julia are represented by Julia data structures, powerful reflection capabilities are available to explore the internals of a program and its types just like any other data. 元编程是把程序与数据混在一起，可以把数据当成程序看待。比如parse(“1+1”)，把字符串1+1当成Julia代码。这种机制下，显然是运行期的特性，而且还要暴露编译器的结构。 利用dump()，还可以把程序变成数据（序列化的一种）。 介于字符串数据与程序之间的是所谓的symbol。一个symbol使用:symbolname来声明。symbol是不可变类型，因此:foo = symbol(“foo”)。symbol里面可以是任何的表达式，所以ex = :(a+b*c+1)也是合法的表达式。使用ex = :(\(a+b*\)c+1)的时候，带美元符号的变量会被立即被其值替换。 表达式可以使用eval()函数，根据当前的程序的上下文求出值。这对于符号计算来说可能是必须的。 元编程与宏又比较接近了。 Julia的异步与并行支持 按理说这应该是重点所在，但是现在还不容易理解它们。Julia使用Task的概念来描述一个异步过程。 运行julia -p n可以开启一个n个工作进程的程序。使用remotecall()可以调用另外线程的程序，借此可以实现并行编程的功能。 //julia -p 4 r = remotecall(2, rand, 2,2) fetch(r) The first argument to remotecall() is the index of the process that will do the work. Most parallel programming in Julia does not reference specific processes or the number of processes available, but remotecall() is considered a low-level interface providing finer control. The second argument to remotecall() is the function to call, and the remaining arguments will be passed to this function. As you can see, in the first line we asked process 2 to construct a 2-by-2 random matrix, and in the second line we asked it to add 1 to it. The result of both calculations is available in the two remote references, r and s. The @spawnat macro evaluates the expression in the second argument on the process specified by the first argument. 通过并行编程的方法也是使用装饰器。它可以把Julia的模块分散到多个工作进程中。 个人认为，在并行计算的情况下，如何保证机器不会运行在内存不够而经常使用交换空间，以及让机器随时能够保持响应是关键的。因为在并行计算的时候，总是要消耗很多的资源。但是确定资源是否够用也很重要。如果不够用，那就只能进入死机状态了。 Julia对于SSH方式工作也有支持。可以用来管理不同的机器。 运行Shell命令，使用 run(`echo hello`) 。其中左单引号表示一个外部程序。括号里面的美元符号里面的变量，同样地会被替换。 Julia对外部程序的支持是非常全面的，可以参考 http://docs.julialang.org/en/release-0.3/manual/running-external-programs/ 。管道等方式的运用，就好像是在Shell自身当中一样。通过julia.h，也可以在C中嵌入Julia的代码。 Julia的包管理功能 包管理功能是通过github来实现的。通过Pkg来管理。 @time装饰器可以在执行代码的时候显示时间和内存使用报告。 其实Julia实现这么多的特性，靠的大多也还是装饰器。在Base.Test中提供了大量的装饰器。 Jeff: Julia基于多分派（multiple dispatch）。这是一种强大的面向对象编程机制，以前其他语言也用过，但出于某些原因从未真正流行起来。我们设计的多分派旨在定义具有多种形式和行为的数学函数，事实证明它也能用于其他情形。它在“你能表达什么”和“编译器能用它做什么”之间达到了很好的平衡。 Julia的更多的特性 感觉之前在看Julia的维基百科的时候自己都没有看仔细，漏掉了很多的重要的东西。比如在Julia中，有几个非常有用的软件包，PyPlot与SIUnits。 以及比较重要的一类调用其它语言的代码的宏包JavaCall、Mathematica。两者分别可以实现在Julia中调用Java与Mathematica的代码。在维基百科上还介绍了使用Julia调用Torch的代码的程序。使用Spark可以调用Spark，以及调用Hadoop的大数据。虽然Julia使用积极求值的策略，但是通过Lazy.jl包，也可以实现惰性求值。 通过Rcall可以在Julia中调用R，反过来，通过RJulia可以在R里调用Julia。 虽然支持Lisp-like宏，但是大多数时候，宏是不向应用程序的开发者提供的。就像Java中的Lambda与反射一样。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Julia编程语言基础知识]]></title>
      <url>%2Fjulia-basics%2F</url>
      <content type="text"><![CDATA[也许这个编程语言才真正贴近科学计算的真实需求。见http://en.wikipedia.org/wiki/Julia_%28programming_language%29。在Ubuntu下面可以直接安装它。 基本的定位是，发明于2012年，多范式（面向对象、过程、函数式加元编程语言），具有动态类型，以及类型注解功能。受到很多高级动态语言的启发。同样地，它也是一个高级动态编程语言，但是对于高性能数值计算与科学计算非常重视。对于通用编程也有一定的效率。注：其实是2009年开发，2012年释出开源版本。 Julia具有一个参数类型的类型系统。使用并行与分布式计算，并且可以直接调用C与Fortran的接口库。而且具有自动内存回收的功能。它的浮点数库、线性代数库、随机数生成、快速傅里叶变换以及正则表达式匹配都非常有效率。目前的版本是0.4。 自己试用了Ubuntu上面的Julia，即使是在命令行界面之下，也有非常好的视觉效果。Julia有一个同名的交互式Shell(正式称呼是Julia REPL)，便于学习和测试程序代码。 Julia直接管理在线的包。因为它的包可以直接从Github上面获取。Julia有JavaCall，Mathematica等，面向R的是Rcall。，可以直接从这些语言里面调用程序。 Julia的其中的一个目标是像R一样好用。Julia的加号等运算符同样地是一种语法糖。 Julia的核心是用C和C++写成的，解析器使用Schema，而Just-in-time编译器使用了LLVM的机制。Julia的JIT是通过LLVM实现的。 其实我们看重的还是Julia的语法功能，其表现力更重要。至于实现，则不用那么重要。就像对于Scala，我们看重的仍是其语法、语义模型等。 关于REPL: A read–eval–print loop (REPL), also known as an interactive toplevel or language shell, is a simple, interactive computer programming environment that takes single user inputs (i.e. single expressions), evaluates them, and returns the result to the user; a program written in a REPL environment is executed piecewise. The term is most usually used to refer to programming interfaces similar to the classic Lisp machine interactive environment. Common examples include command line shells and similar environments for programming languages. 实际上，可以使很多的语言都变成REPL方式工作。参考http://repl.it/languages上面的一个在线的REPL程序，包含了各种程序实现。 虽然julia命令直接打开一个REPL，但是官方还是推荐使用IJulia（以后会改名为Jupyter）。安装它是非常简单的，打开julia,输入Pkg.add(“IJulia”)即可。然后使用Pkg.update()或者Pkg.build(“IJulia”)可以执行更多的包管理的功能。启动IJulia的时候，可以通过打开julia控制台，然后输入： using IJulia notebook() 或者使用 ipython notebook --profile julia 下面还是浏览一下Julia的基本的功能 通过说明书http://docs.julialang.org/en/latest/manual/来看，内容还是比较简单的。但是里面其实不简单。包括了元编程，并行编程等概念。 下面我们一点点解决相关的问题。 在导言的部分，作者指出科学计算有追求高性能的传统。但是目前的情况下，这些科学计算的专家们经常使用较慢的动态语言当成日常的工作。现在随着编译技术的进步等，这些人现在可以使用动态语言的同时写出高效率的工作。同时，JIT、REPL等的进步，也使得交互式工作变得越来越容易了。Julia就在这种情况下应运而生。 Julia的设计其实是沿着经典的数学编程语言（mathematical programming languages）的设计路线，并不同于通用编程语言的路线（虽然从编程语言原理上看没有什么区别，但是在现实中，我们完全可以把通用编程语言，数学编程语言，以及领域专用语言看成是编程语言原理的不同的领域的应用，以致于在讲通用编程语言的机制的时候，几乎完全不适用于领域专用语言。现在，这些语言又有进一步融合的趋势。 作者提到，动态语言并不是没有类型的：虽然大多数情况下类型不用声明，而且会自动进行转换，结果开发人员好像不用考虑类型的问题一样。其实对于静态语言，我们也可以说，类型完全是编译期的一个概念，运行期完全没有那样的一回事。 变量与赋值 Julia当中的变量支持使用unicode的字符，但是变量名不能是保留字。赋值使用一般的等号，字符串字面量当中，Unicode是自然而然的。另外，也可以使用latex风格的变量名称，这其实就是把变量以数学模式开始和结束而已，没有什么好奇怪的。 Julia的建议的风格是：变量名以小写的字母开始，同时不使用下划线，而使用大写字母使变量显得紧凑。另外，如果是函数，建议最后加一个叹号，表示这个函数是一个改变状态的函数（也称为过程）。这样可以与函数式风格明显地区别开。 Julia对于常见的类型（整型、无符号整型、长整型、布尔型、字符型、浮点型）都有支持。Julia是动态类型语言，由此它有typeof函数，该函数接受一个变量为参数，然后返回一个类型。我们还可以把类型当成一个值赋给一个变量，这个变量就是一个类型变量了。下面是在Julia当中合法的操作： my_type = typeof(123) my_type &lt;: Int 其中，&lt;:是类的操作符，表示一个子类型。第二条语句运行的结果就是True，因为Int64确实是Int的子类型。另外，整数可以用0x之类的前缀表示，以支持不同进制的字面量输入。另外，使用isa(var, Type)可以判断某个变量是否属于某个类型。 Julia的类型系统直接暴露于程序员可见的范围。比如，通过typemin(T)、typemax(T)可以得到相关类型的表示范围中的极小值与极大值。这比C实践中的方法方便多了。注意，在Julia当中，实行的是所谓的模态算术。因此typemax(Int64)+1 == typemin(Int64)为真。也就是说，整数的加减是循环的。这种数学的处理，大大方便了对于数值操作的溢出的概念。使用bits函数，可以得到数据的内部字节表示。另外，Julia的浮点数的处理的机制按照IEEE 754规范，因此具有Inf、NaN之类的量。使用eps()函数，可以得到浮点类型的机器的最小精度。 浮点数与整数的处理，可以参考http://docs.julialang.org/en/release-0.3/manual/integers-and-floating-point-numbers/。个人觉得，这可以作为高级编程语言的进一步的知识，让学习者可以掌握编程语言处理科学数据的规范。 Julia实现了GMP与MPFR库基础上的变长精度浮点运算。任意长的整数的运算，使用的类型是BigInt。通过BigInt(“2342342342342”)可以制造出这样的大整数来，也可以由其它的整数转换而来。 Julia的乘法运算，有时候可以省略掉中间的乘号。这种方法在符号计算语言中已经实行了很久了。现在只是告诉我们，Julia也具有这种方便性而已。Julia也支持使用 ^ 来做取指的运算。但是要注意取指的优先级。如果乘法在前面，那么省略号与否，取指的优先级都是高的。但是如果是先做取指再做乘法，就不一样了。2^5x将被翻译成2^(5x)，而2^5*x被翻译成(2^5)*x 。而5x^2==5(x^2)、5*x^2=5*(x^2)。这说明，怎样求值不只是算术优先级的问题，与算术运算符的前后顺序也有关系。 但是需要注意的是，Julia的省略乘号的做法可能会与其编程范式产生冲突。比如(x-1)(x+2)。因为任何表达式都是返回类型的，而对一个表达式应用()，相当于把这个表达式看成一个函数（在Julia中，BigInt也是一个对象，因此有()方法；函数在Juila中使用f()来应用，但是调用的实际上是f.apply()方法），因此便会出错。这一点是我们需要注意的。一般来说，因为函数式加上面向对象的方法中，类也是一个类型，而函数正是一个具有apply方法的类型，所以就有可能与构造函数冲突。但是面向对象加上函数式比较容易解决这个问题，而如果加上省略乘号运算符，可能语法分析就出现困难了。）。在编程实践中， 面对多范式语言，必须小心语法冲突 。 Julia把类型也当成是值，具有一种优点，那就是我们想得到某个类型的特殊的元素的时候，可以直接通过类的方法产生，比如one(Int32)、zero(Int32)分别产生这个类型的单位元与零元，前面的typemin与typemax函数也是这样。 但是，如果我们能够通过Int32.zero这样的属性或者方法产生类型的单位元与零元的时候，相信会更方便 。 Julia作为科学计算语言，支持的运算符的种类是非常多的。加减乘除取指取模都是不例外的。对于除法，还有除与反除两种(视斜杠方向不同)。除此之外，还有按位运算，如~、&amp;, &gt;&gt;, &lt;&lt;,等。具体参考http://docs.julialang.org/en/release-0.3/manual/mathematical-operations/。注意&lt;!&gt;是逻辑非，不是按位的反转。Julia也提供了+=这样的重新赋值操作，实际上，任何二元运算符都可以这么做。 运算符一般来说是按照类别分的，不同类别的含义不同。一般来说，分成算术运算，比较运算、逻辑运算和按位运算等几类。具有C++赋值特性的，只能是算术运算符，因为此时我们认为算术运算符返回的类型与第一个变量的类型是相同的。 Julia还支持比较运算符的累积，这是与Python相一致的，比如1&lt;2&lt;=3这样的表达式是有意义的。 http://docs.julialang.org/en/release-0.3/manual/mathematical-operations/里面提供了大量的运算符与类型的特殊函数(数学函数)，有需要可以参考一下。 另外，Julia支持以a+b*im的形式表达复数，以及使用a//b的形式表达有理数，这些也是科学计算语言的必备的特性。(准确地说，科学计算语言的基本数据类型) 科学计算语言通常也有字符与字符串类型的支持。字符串是被当成数组对待的，因此具有中括号方法。 在Julia中，字符串可以直接引用一个变量，这时候使用美元符号引导。因此用双引号括起来的字符串，里面的字符可以被转义，也可以被求值。甚至可以在字符串中使用$name, abc, (1+2)这样的复杂的形式。这里，name被变量值替换，而1+2被求值。 Julia中的字符串不想被转义的话，可以在前面添加一个r，与Python类似。Julia的正则表达式与PCRE是兼容的。r代表的实际上是后面的字符是一个正则表达式字符串。比特数组使用b“DATA”这样的字面形式表示。另外，v“0.2”表示一个版本号类型，具有版本号的一些比较运算符，这是为了方便某些操作吧。版本号的比较机制，可以参考http://docs.julialang.org/en/release-0.3/manual/strings/。 Julia的函数 Julia的函数体可以使用 function f(x,y) x + y end 最后一个表达式的值，默认作为返回的值。另外，也可以使用f(x,y) = x+y来定义一个函数。此时表达式不会被求值。(注意，表达式与表达式被求值是完全不同的概念）。 此外，函数名也可以作为一个变量被赋值，比如g=f，这时候便可以用g(x,y)来调用f(x,y)。另外，函数求值实际上是调用方法，所以可以使用apply(f,2,3)。(不过，直接使用f.apply(2,3)可能是不被允许的（也许像Python那样处理的吧）。 因为Julia支持使用Unicode字符，所以有些时候语法会很奇妙，比如可以直接把Unicode字符的求和\sigma当成函数名称。 函数也可以显式添加return语句。在Julia中，运算符也是函数，所以使用+(1,2,3)以及f = + 也是被允许的。Scala也有这样的特性，但是不知道形式语言理论是怎么说的。 在Julia中，组成数组与Python中一样方便，a, b就组成了一个数组。所以表达式a,b返回的是两个表达式的和按照顺序组成一个数组。x, y = 1, 2这样的赋值语句，也是被容许的。Julia的函数也支持可选参数，做法与Python类似，此外，如果有可选参数名称，显式指定可选参数的时候，位置可以替换。 定义函数的时候发生了什么： function f (x, y ) x + y end 实际上，函数的参数是在比x+y高一个作用域的位置，但是低于可见作用域。而且，参数得到值的过程是从左到右按照顺序来的。所以f(x, y = x)不会发生错误，但是f(y, x = y)却会报“变量未定义”的错误。其实我们可以看成是函数的参数是在执行之前被构造出来的过程，在动态语言中，调用f(1)相当于实际执行的是： eval (x = 1) // 判断出参数有一个，所以 eval (y = x) x = y 执行中，左边的形参先得到其值，右边的形参稍后。所以，虽然直觉上可能认为函数的形参取得参数是并行的，但是其实并不是这样。 MapReduce特性 为了方便书写把一个函数作为参数传递到其它的函数，julia使用do语法，比如 map([A, B, C]) do x if x &lt; 0 &amp;&amp; iseven(x) return 0 elseif x == 0 return 1 else return x end end 该语句的含义是创建一个以x为参数的匿名函数，后面是该匿名函数的体。最后，do会把这个函数当成是第一个参数传递给map()函数。这与Python语言中的with语句有一些相像。 Julia的控制流可以使用(sentence; sentence; sentence)表示，小括号可以换成begin .. end。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala的一些设计特点]]></title>
      <url>%2Fscala-features%2F</url>
      <content type="text"><![CDATA[首先，Scala中的几乎所有的语言元素都是表达式。也就是返回一个值。另外，Scala中的val实际上是“常量”，或者说，“字面变量”的意思。相当于给常量一个名子。对于编程实践与软件工程具有重要性。 函数可以用def语句定义也可以使用val语句来定义。主要是看有没有小括号方法。这一点就很容易混少淆了：def与val定义的函数在实质上有什么区别呢？ def square(a: Int) = a * a def squareWithBlock(a: Int) = { a * a} val squareVal = (a: Int) =&gt; a * a Scala的变量的使用的时候不需要指明类型，而且Scala支持按值传递与按名传递，所以就有了不同的模式。试着把函数定义为 def log(msg: String) 与把函数定义为 def log(msg: =&gt; String) 都不会使 log(MSG + 1 / 0 ) 出现编译期错误。然而后者是按名传递，所以1/0不会被求值，也就不会在运行期出现错误。按名传递的优点是可以避免不必要的计算。 标准的调用类的方式是使用new方法。 柯里化currying的意思是允许一个函数的多次调用，并且只有最后一次调用的时候返回的是正常的值，中间的所有的调用只是产生一个特定函数（参数被确定了）。 Traits就像是一个Interface。但是可以有函数体。 模式匹配特性 自己中间的时候接触到了模式匹配。模式匹配与switch case语句最大的匹别就是它可以直接匹配一个类型而不单单是匹配在一个值。在支持高阶函数等特性的语言中，模式匹配是很强大的，尤其是用来构造一个分析器。 def fib(int: Any) : Int = in match { case 0 =&gt; 0 case 1 =&gt; 1 case n: Int =&gt; fib(n-1) + fib(n-2) case _ =&gt; 0 case n: String =&gt; fib(n.toInt) } 注意上面的后两个匹配条件。它显然容许了final类型的匹配，以及在泛型的情况下，如果匹配到一个字符串的类型，就把它处理成整数后再计算。这对于应用程序传参是非常有利的。应该是比具有变长参数的函数传递，以及Key=Value方法的传递更自由。 实例类 一个函数与一个类有什么样的区别呢？在函数的调用的时候，以及类的构造的时候，都是使用所谓的小括号的表达式。但是不同之处在于，给类传递参数的时候，类的参数会持久化起来。因为类有存储空间。这样的话，类的参数的信息实际上是保留下来了。于是我们可以认为类是一个惰性的函数。即使被调用的时候，里面的参数也保存了下来。请看下面的写法： abstract class Expr case class FibExpr(n : Int) extends Expr { require(n &gt;= 0) } case class SumExpr(a: Expr, b: Expr) extends Expr def value(in: Expr): Int = in match { case FibExpr(0) =&gt; 0 case FibExpr(1) =&gt; 1 case FibExpr(n) =&gt; value(SumExpr(Fib(n-1), Fib(n-2))) case SumExpr(a,b) =&gt; value(a) + value(b) case _ =&gt; 0 } println(value(FibExpr(3))) 工作的时候，FibExpr(0)作为一个参数被匹配。因为FibExpr是一个实例类，所以实例类中的成员都保存了下来。在语义上，FibExpr出现在Case中，表示该类的名称是FibExpr，同时它的传值是0。正好匹配。这样的话，一个类的对象更像是一个实体。因为我们可以拿两个类的构造函数直接比较。 因为函数式语言可以直接将函数作为传递的参数。同时函数式语言中函数的声明与操纵往往很方便，所以判断也是很容易的。比如Scala中|list.exists(_ % 2 ==1)|就表示判断列表当中有没有奇数。 函数式语言中的Map-Reduce 在Scala中实现Map和Reduce是非常直接的。因为List对象直接有map方法，而且map的参数就是一个函数。另外，map后可以直接使用reduceLeft这样的函数。用于把列表折叠起来。假设StrList是一个包含字符串的列表，那么下面的方法就用MapReduce实现了一个统计列表中的单词总数的方法： def wordCount(str: String): Int = str.split(&quot; &quot;).count(&quot;msg&quot;==_) file.map(wordCount).reduceLeft(_+_) Map的参数是一个正常的，操纵单个元素的函数是很常见的。许多向量式的语言就有这个特性。但是我们对于reduce函数却生疏一些。因为reduce要把许多元素结合起来。所以reduce函数的执行有两个要素，第一个是怎么结合子元素，第二是怎样执行合并的次序。reduceLeft函数的参数告诉我们，从左到右，两个元素依次相加，返回的元素再和右边的元素相加，直到最后一个元素被处理。 Scala还具有优化尾递归的能力。因为在函数式语言中，尾递归的效率比C++之类的要高很多。在编译器就会全部优化这些东西。 Scala的for也是函数式的for。意思是依次读取列表中的元素，生成一个新的列表。在for当中使用yield可以返回值。比如： val counts = for (line &lt;- file) yield wordCount(line) val num = counts.reduceLeft(_+_) 总而言之，Scala对于多种编程方式都有支持，它们完成的任务都类似。关键还是看风格的问题了。现在我们缺的不是先进的编程方法，而是如何更好地运用这样的编程方法。 模式匹配的应用范围很广。比如在得到一个值的时候，返回的是错误该怎么办？通常情况下就要进行错误处理了。但是这样其实很麻烦。更好的做法，而且不打断业务逻辑的做法就是使用内容匹配。 处理错误通常发生在同样具有意义的函数的高层。通常而言是由某个操作所引起的。因此都是放在try块当中。使用错误处理的时候，利用match方法更为简洁，这是因为，处理错误的代码与算法的代码被分割了。比如 val osName = getProperty(&quot;os.name&quot;) osName match { case Some(value) =&gt; println(value) case _ =&gt; println(&quot;none&quot;) } println(osName.getOrElse(&quot;none&quot;)) osName.foreach(print _) Scala的lazy初始化也是一个具有重要意义的特性。其重点在于把耗时的操作推后，放在尽可能需要做的时候才开始做。特别是访问网络。比如一个类需要访问网址的时候，最好的方法可能不是在构造类的时候就开始做，而是首次访问网络的时候。这个时候用lazy操作就可以了。另外，lazy操作中调用lazy函数的时候，操作也不会立即完成。只有lazy变量被首次使用的时候，才逐步执行lazy变量的初始化。 Scala的并发 Scala的并发主要是Actor库。Actor是Scala的并发模型。而2.10之后，推荐Akka作为Scala的Actor的实现。Actor类似于一个线程，有一个邮箱。Actor可以通过system.actorOf来创建，通过receive来获取消息，用叹号发送消息。实现了语言级别对于并行的支持。Actor还有一个DSL可以使用。Actor是比线程还较量的并发的实现。因为Scala可以实现线程的复用。 Scala通过future实现异步的返回。另外，对于列表，Scala还能够形成并行集合。像普通并行计算那样进入并行区。通过par.map方法就可以实现并行的map操作了。不过，这里的并行，主要是利用多核的能力。 Akka也支持远程的并发的模型，在Akka中通过akka:&lt;//RemoteSystem@127.0.0.1&gt;:2552/user/echoServer这样的地址就可以做到分布式的消息通信与并发。 自己可能在C42的第一阶段中了解编译的概念与并发的概念，并将它们与操作系统相结合起来了。这样好像是一切的基础。而且自己觉得，只有软件工程与安全工程、系统工程学习得多了，才知道编译器为什么这样设计、并行系统为什么那样处理。 个人始终认为，学习计算机和学习数学是一样的道理，自己学习过很多的基础的知识，未必就理解它的意义和用途了。反而是自己把更高级的东西学会之后，有了新的视角的时候，对于有些东西才能看得非常透。比如，编译原理与操作系统和网络显然是非常深的知识，但是我们肯定不知道为什么这样。 实战中的Scala（与Java的互操作） 首先是Java与Scala的互操作。在scala中有beans这样的库，以至于可以允许Scala中也使用beans的对象，Scala也支持beans中的@BeanProperty注解。 在Java中判断类是否相等是一件不容易的事，因为它的equals方法与 == 方法的含义是不一样的。而且有时候这样的判断非常难写正确。在Scala中 == 与equals的含义完全相同。另外，在Scala中，建议在需要判断类的相等的时候使用实例类case class，而不用对通常的类判断相等。 抽取器也是Scala的一大特色。具体来说，抽取器允许直接变量的匹配。注意到Scala的case可以匹配一个带有形参的函数，那么，从Email中抽取用户可以这样做： import scala.util.matchingRegex object Email { def unapply(str: String) = new Regex(&quot;&quot;&quot;(.*)@(.*)&quot;&quot;&quot;) .unapplySeq(str).get match { case user :: domain :: Nil =&gt; Some(user, domain) case _ =&gt; None } } &quot;user@domain.com&quot; match { case Email(user, domain) =&gt; println(user + &#39;@&#39;+ domain) } 这种方法，依赖于对象有unapply方法，以及正则表达式的match功能。 另外，Scala执行中可以启用Cache的功能。具体来说，就是对于函数的指定调用启用Cache。因为每次结果相同，下一次的时候就不再调用了。这种方法需要显式使用。尤其是自己建立一个维护cache的字典。不过，使用的方法也是相当简单的。使用cache的最大的优势可能在于非尾递归的情形下，也不用我们手工改成迭代的方法。在scala中，是通过memo函数（scala.collection.mutable.WeakHashMap）实现的。中文译为“记忆模式”。 记忆模式在计算Fibnacci数之类的问题上是非常显著的。这使得Scala在科学计算中具有表达十分简洁、效率又十分高的特点。 定义了implicit的函数可以成为一个隐式类型转换函数。比如 implicit def strToData(str: String) = ...} 这样就可以实现隐式类型转换了。关键还是在于implicit关键字。 另外，Scala的强大的地方就在于DSL。Scala有许多特性看起来是语言级的，但是其实是DSL的结果。比如Scala操作JSON的方法。 此外，Scala还有一些测试的套件。可以使用Spec2、ScalaTest等测试。通过使用shound, mustEqual等语句，就好像是在写自然语言一样(好像是声明式的效果）。 另外，Scala还有自己的sbt工具。构建的时候会方便很多。使用sbt，甚至只需要安装JRE，scala就能够把东西构造出来。 SBT教程 sbt的入门是非常简单的。创建一个新目录，新目录下有一个scala文件，直接运行sbt run，或者先输入sbt，在交互式窗口中输入run，就可以编译并运行结果了。 但是通常情况下，sbt会像java那样工作。也就是，先查找当前目录下的文件，然后查找src/main/scala或者src/main/java目录下的文件，再找src/test/scala与src/test/java目录下面的文件，再找src/main/resources或者src/test/resources目录下的文件。最后找在lib目录下的jar文件。其实是继承了java的优点。因为java就是让哪些不懂软件工程的人也能够按照软件工程的实践来配置，从而避免了随意性。 sbt是和scala同时发布的。默认的情况下，sbt编译的时候也会使用和scala相同的版本的编译器。其实，scala本身就是用java写的编译器。 sbt的配置文件是当前目录中的build.sbt文件。配置根元素的方法是： lazy val root = (project in file(&quot;.&quot;)). settings( name := &quot;hello&quot;, version := &quot;1.0&quot;, scalaVersion := &quot;2.11.4&quot; ) sbt文件的书写规范可以参考http://www.scala-sbt.org/0.13/tutorial/Basic-Def.html。在project/build.properties文件里面可以加上sbt.version=0.13.8来配置所使用的编译器。scala的工程的目录结构，一般和maven保持相同。但是java目录的优先级要低于scala目录。以点号开头的所有的文件都会被忽略。 在sbt中，主要的配置文件放在build.sbt文件中，而其余的配置文件放在project/目录的下面。它们各自有自己的作用。在project/目录下还可以有.scala文件。它们也用于指导构建的过程。 在目录下完全可以使用.gitigonre文件。尤其是，在根目录下应当有.gitignore文件，把target/目录给忽略掉。 在所有的配置中，添加依赖可以说是最基本的了。一般而言，采取这样的风格： val derby = &quot;org.apache.derby&quot; % &quot;derby&quot; % &quot;10.4.1.3&quot; lazy val commonSettings = Seq( organization := &quot;com.example&quot;, version := &quot;0.1.0&quot;, scalaVersion := &quot;2.11.4&quot; ) lazy val root = (project in file(&quot;.&quot;)). settings(commonSettings: _*). settings( name := &quot;hello&quot;, libraryDependencies += derby ) 特别是，使用derby常量定义一个串，然后在settings的libraryDependencies中添加这个库。 Play等网页框架 这里介绍了Play框架用来开发Scala网页应用的技术https://playframework.com/ 。这里是中文的一个介绍play框架的博客http://www.cnblogs.com/nixil/articles/play_with_scala.html 。 http://stevenshe.ca/ 是一个博士生的主页。做的也是SPLC与feature model方向。而且使用的编程语言是scala。 Scala的语言的完整的规范，包括语法解析规则可以参考http://www.scala-lang.org/files/archive/spec/2.11/ 。 Scala对于XML的支持 Scala的语言的完整的规范，包括语法解析规则可以参考http://www.scala-lang.org/files/archive/spec/2.11/。以下就是从这本书里面提取出的Scala的语言级别的特性。 XML可以直接作为一种数据类型而出现，而不必添加其它的标注。比如: val b = &lt;book&gt; &lt;title&gt;The Scala Language Specification&lt;/title&gt; &lt;version&gt;{scalaBook.version}&lt;/version&gt; &lt;authors&gt;{scalaBook.authors.mkList(&quot;&quot;, &quot;, &quot;, &quot;&quot;)}&lt;/authors&gt; &lt;/book&gt; 其中的scalaBook.version可以用于对于scala变量的求值。这样一来，XML完全可以作为一种原生的数据类型出现。至少表现得与原生数据类型是一样的。在词法的级别，Scala也引入了其它的一些特性，比如支持unicode作为变量名。这是Scala的词法文法的介绍http://www.scala-lang.org/files/archive/spec/2.11/01-lexical-syntax.html。 在Scala当中，类型、值、方法、类都统称为一个实体(Names in Scala identify types, values, methods and classes which are collectively called entities)。引入一个名称称为绑定（bind）这个名称。在scala当中，引入一个名称的方式有局部声明与定义、继承、import子句、package子句。将一个名称引入之后，scala就知道这个东西该怎样被解析了。 如果不同的绑定定义了同样一个方法，那么它们会有不同的优先级。在编译的时候，编译器会按照优先级来查找这些名称的含义。 在scala中，有两种name spaces。也就是有两个命名的空间。第一个空间是为类型准备的，第二个是为项准备的。因此即使name相同，如果它们属于不同的语法单元，scala也不会把它们弄混了。根据上下文，一个名称，可以被指派给一个类型或者一个项。 每一个绑定都有一个作用域。(A binding has a scope)。在scala中，作用域是可以嵌套的。如果在上下文菜单中出现了一个普通的标识符，scala会尝试从当前生效的作用域中找出这个绑定对应的名子。如果没有这个名子，将会出错。标识符有定域和非定域之分（identifier: unqualified identifier and qualified identifier）。定域的标识符，指的是使用a.x这样中间有点号限定的标识符。 如果是定域标识符，也就是 \(e.x\) 的形式，那么scala会把x绑定到具有成员 \(x\) 的一个对象 \(e\) 当中，但是这个时候， \(e\) 的类型 \(T\) 不是任意选择的。如果 \(T\) 不是value type，那么就会出错。 Scala的类型系统 Scala的类型有value type, non-value type之分。因为对于高阶的支持，所以在scala中有first-order types与type constructors之分。顾名思义，两种类型中，一种是语言内置的，另外一种是接受类型参数以生成另外一种类型。其实可以算是元类型，因为它接受类型参数之后才变成一个具体的类型。 value types is a subset of first-order types. value types又有具体类型concerte与抽象类型abstract之分。它是一个具体的value types的属性。一个具体的value type，要么是具体的，要么是抽象的。value types在scala中又称为first-class values。译为一等值？ Every concrete value type can be represented as a class type, i.e. a type designator that refers to a class or a trait 1, or as a compound type representing an intersection of types, possibly with a refinement that further constrains the types of its members. Abstract value types are introduced by type parameters and abstract type bindings. Parentheses in types can be used for grouping. Non-value types capture properties of identifiers that are not values. For example, a type constructor does not directly specify a type of values. However, when a type constructor is applied to the correct type arguments, it yields a first-order type, which may be a value type. Non-value types are expressed indirectly in Scala. E.g., a method type is described by writing down a method signature, which in itself is not a real type, although it gives rise to a corresponding method type. Type constructors are another example, as one can write type Swap[m[_, _], a,b] = m[b, a] , but there is no syntax to write the corresponding anonymous type function directly. 在scala中，non-value types包含了其它的一些东西。特别是，在scala中，一个方法的类型与它的字面意思并不相同。方法的签名自然是与它的类型有关，但是方法的名称却不能唯一决定它的类型。也就是说，non-value types的含义实际上就是和编程的时候出现在代码中的名称不一样的类型。它的类型是由编译器推导出来的，有一个内部的，隐式的表达。另外，一个类型构造子也不算一个具体的类型，是因为，一个类型构造子的名称还不足以成为一个类型。只有它接受了特定的参数之后，才成为一个类型。 Scala的名称还可能有点号作为限定符。这个时候，完整的路径并不是类型的一部分。但是它们对于确定出现的一个名称是什么类型非常重要。Paths are not types themselves, but they can be a part of named types and in that function form a central role in Scala’s type system. 在scala中的c.x中，x必须是p的一个稳定的成员： \(p.x\) where \(p\) is a path and \(x\) is a stable member of p. Stable members are packages or members introduced by object definitions or by value definitions of non-volatile types.其中，稳定成员就是在路径中，它是一个叶结点: A stable identifier is a path which ends in an identifier.也就是出现c.x之后，x不能再有子成员？ 注意，引用一个类的超类中的成员也是可能的。比如C.super.x或者super[M].x。 A stable type is either a singleton type or a type which is declared to be a subtype of trait scala.Singleton. 编程语言的类型问题 在这一领域有许多正式的名称。它们甚至是可以形式地定义出来的。比如\(T[T_1,\cdots]\) 。这个完整的整体叫做一个含参类型，称为parameterized types，而 \(T\) 本身则称为一个类型构造子。也就是说， \(T[T_1]\) 是对类型构造子已经使用了 \(T_1\) 构造之后的结果。类型参数是可以定义上界与下界的。尤其是在声明一个类型构造子的时候。 比如声明 class S[K&lt;: String] {...}; class G[M[Z&lt;:I],I]{...} 的话，可以使用 \(G[S,String]\) 来构造一个带参类。 Scala还允许元组类型。这种类型是由 \((T_1,\cdots,T_n)\) 构成的。在使用的时候，相应的数据的各个维数属于不同的类型，类似于结构体。 另外一种是所谓的注解类(Annotated types)，用法如String @suspendable。其它的，还有合成类型（compound types）、中缀类型（Infix Types）、函数类型(function types)等。 函数的类型是由 \(T_1,\cdots, T_n \Rightarrow U\) 来决定的。也可以使用复合的类型，如 \(S\Rightarrow T \Rightarrow U\)，但是这个类型是右结合的，表示的是等价于 \(S\Rightarrow (T\Rightarrow U)\)的元素。 中缀类型具有 \(T_1 op T_2\) 的类型。从实现上看，中缀类型是对于\(op[T_1, T_2]\) 的一个语法糖。 在Scala当中，函数是具有apply方法的类，因此函数类型实际上是一种类类型（class types)。函数类型的结果是共变的，但是参数是反变的。 在编程语言中，把一个名子与一个类型关联起来的过程称为绑定。然而，具体实现绑定的方法就是通过声明或者定义。 Scala的Object实际上是由设计模式中的“单件”改变而来。参考 http://zh.wikipedia.org/wiki/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F 。 模式匹配的技术与模式识别正好相反。在模式匹配中，模型是精确指定的。但是在模式识别中，模式却南大要挖掘。Tree patterns are used in some programming languages as a general tool to process data based on its structure, e.g., Haskell, ML, Scala and the symbolic mathematics language Mathematica have special syntax for expressing tree patterns and a language construct for conditional execution and value retrieval based on it. For simplicity and efficiency reasons, these tree patterns lack some features that are available in regular expressions. 使用Scala实现一个符号微分的程序 类型的匹配其实就是使用带参类与泛型的结果。尤其是对于一个表达式，通常的情况下，都是设置优先级来匹配一个类。比如 def Diff(Expr, Var) = Expr match { case Sum (l, r) =&gt; Diff (l, Var) + Diff (r, Var) case Prod (l, r) =&gt; Diff (l, Var) * r + l * Diff(r, Var) ... } 实现中缀形式的匹配也是有可能的，特别是在scala中中缀也可以惰性匹配的情况下。个人认为，大学的时候学习编程语言不能非常方便地写出一个符号微分的程序就是一个失败。 写符号微分的另外一种方式是使用语法解析器。如果能把语法解析器自动嵌入到一个语言中，会是很有趣的一件事情。特别是如果一个语言的子解析模式是可以由用户方便地定制的话。 Scala下的Actor[06-09-2015 22:21:56] 使用AKKA并发库来解决问题。Actor系统的原理我们已经知道了。对于Erlang而言，程序本身就是一个Actor（进程）。而在scala当中，进程通过创建actor中的一个对象实现与actor通信系统的关联。示例的代码如下： case class Greet(name: String) case class Praise(name: String) case class Celebrate(name: String, age: Int) class Talker extends Actor { def receive = { case Greet(name) =&gt; println(s&quot;Hello $name&quot;) case Praise(name)=&gt; println(s&quot;$name, you&#39;re amazing&quot;) case Celebrate(name, age) =&gt; println(s&quot;Here&#39;s to another $age years, $name&quot;) } } object HeloActors extneds App { val system = ActorSystem(&quot;HelloActors&quot;) val talker = system.actorOf(Props[Talker], &quot;talker&quot;) talker ! Greet(&quot;Huey&quot;) talker ! Praise(&quot;Dewey&quot;) talker ! Celebrate(&quot;Louie&quot;, 16) Thread.sleep(1000) system.shutdown } 在上面的代码中，使用ActorSystem进入Actor系统当中（可能需要一些认证），而使用actorOf来创建一个actor。发送消息使用叹号，而使用shutdown来实现断开actor.基本原理就是这样。如果需要多个消费者协调，或者错误处理功能，就需要再参考相关的书籍了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eclipse体系结构与Ecore技术]]></title>
      <url>%2Feclipse-architecture%2F</url>
      <content type="text"><![CDATA[这对于理解Eclipse的建模的技术至关重要。Eclipse Modeling Framework(EMF)是Eclipse提供的一套建模的框架，可以使用EMF建立自己的UML模型，设计模型的XML格式或编写模型的Java代码。EMF提供了一套机制实现功能的相互转换，大大提高了效率。 统一Java、UML与XML的Ecore文件 故事不妨从程序员开始。一般的程序员都是上来写Java代码，但是按照软件工程的要求，往往要先开始建模。两种思路各有千秋吧。但是如果我们能写一份代码，然后自动转成另一种格式，明显会使程序员舒服许多，同时又减少了程序员对软件工程的抵触情绪。这种思路能够转变成为现实，这是因为，Java代码描述，UML描述是等价的，理论上也就存在一种转换的可能。（特别是类图的转换）。 Java的接口是统一UML类图与代码的关键。因为Java的接口只有声明而不需要实现，与UML的类图的描述正好相同。如果Java类中包含了代码实现，反而比UML描述的东西更多了。（也许UML不适合在算法的级别上描述软件）。UML图形的保存的格式是XML的，准确地说，是基于XML Schema。 如果我们想设计一种模型，然后在三种模型之间转换，那么就要借助于EMF Model了.EMF给我们的回答是，在软件开发中，设计既可以从UML图形开始，也可以从Java代码开始，也可以从XML Schema开始。这样，大概结束了设计与编程的地位的高低的问题。解决了这个“To model or to program, that is not the question”。(这个思想大概同Knuth的观点相同，关键是EMF似乎也允许了既不是自顶自下也不是自低向下的设计。） 但是我们先看为了统一三种模型，我们应该考虑哪些现实的问题： 在UML与Java中是类的东西，在XML Schema中被定义成复杂类型 在UML中使用属性，在Java中使用get/set方法，而在XML Schema中是内嵌元素类型 在UML中是类的关联或者引用，在Java中可能是方法，在XML Schema中是另一种复杂类型的内嵌元素类型 于是要实现EMF和三种模型的转换，需要一种能够描述EMF模型的模型，这个模型我们称为元模型，也就是Ecore(Meta)模型。 Ecore模型位于MOF的M2层，它本身也是EMF模型。Ecore模型本身是可以用于描述自身的模型。Ecore是OMG的MOF建议在Eclipse下的一种实现，同时MOF的M2模型还有其它的实现形式。Ecore模型的实例，使用XMI序列来表示。在Eclipse中，导出EMF模型，实际上是导出一个EMF模型，也就是导出EMF模型的XMI格式。 EMF能够将Java接口自动生成UML的属性和方法，但是并非所有的Java接口都自动会生成UML的属性和方法。其实要生成相应接口与方法，编写Java代码的时候必须符合一定的规范。 EMF的核心就是Ecore和它的XMI序列化格式。通过UML、XML Schema与Java接口，Eclipse提供了一种转换成Ecore模型的方法。而且转换Ecore之后，可以生成这三种模式以及其它形式的模型。 使用XML Schema不仅定义了模型，而且还指定了模型实例的持久格式（？）。还有其它的持久模型格式，如Relational Database Schema (RDB)。 注：持久模型好像指的是，Java代码中也有不是自动生成的部分，这部分需要我们手动编写。如果自动工具能够识别哪些是手写的，哪些是自动生成的，然后在更新模型的时候保留我们手写的那部分，则就称为是一个持久化的模型。 EMF是一个强类型的语言。我们也许可以从形式语言的一般理论中理解它。 Ecore模型可以使用GMF可视化工具编辑(就是那个树形的编辑框)。注意，使用Eclipse新建Ecore文件的时候，最好还是不要使用纯文件建立一个空白文件类型，那样要做很多多余的工作，直接新建Ecore Diagram即可，因为它生成的是Ecore文件。 Papyrus插件中再安装上Extras软件包之后就可以有生成Java或者C++的代码的功能了。 Papyrushttp://download.eclipse.org/modeling/mdt/papyrus/updates/releases/luna/extra。 Eclipse的体系结构 了解Eclipse的体系结构对于后面要进行的开发会有一些好处吧。Eclipse的骨架是OSGi体系结构，它是Open Services Gateway Initiative的简称。OSGi技术原是为嵌入式硬件而开发的，使网络上的服务提供者和使用者互相交互。 在OSGi中，所有被配置的组件都是以插件的方式提供的。SWT和JFace是Eclipse的最基本的用户接口API。在其上提供了基本的UI Workbench。在然后上面就有了更新管理器与帮助系统，它们构成了Eclipse的框架。 插件为了自身能够对其它插件进行扩展而提供“扩展点”。当要为插件提供增加功能的时候就可以利用这个扩展点。在扩展点的基础上，插件之间可以互相连接。扩展和扩展点之间的连接是在程序执行的时候被建立的，提供扩展点的插件事先并不知道该扩展点在实际运行的时候被展了什么样的行为。使用扩展点的插件需要在其源代码的plugin.xml配置中使用&lt;extension&gt;元素声明该扩展点。基本格式为: &lt;extension point=&quot;被使用扩展点的ID&quot;&gt; ...... &lt;/extension&gt; 像这样的扩展点和扩展不断地积累，使得Eclipse平台能够实现各种各样的功能。Eclipse平台提供的扩展点许多类，其中有三类比较基础： 增加菜单项 增加视图 增加编辑器 在Eclipse的帮助中有Eclipse提供的所有扩展点的说明，可供编写扩展时参考。我们也可以为自己的插件定义一个扩展点。 在开发Java的时候，我们已经熟悉了Eclipse窗口由工作台、菜单栏、工具栏、工作台页（也就是包含一个个子窗口的容器）、状态栏构成。其中工作台页又有视图、编辑器等类型的子窗口，通称为透视图(Perspective)。Eclipse工作台即Workbench，它是整个用户接口的总称。 我们的插件使用org.eclipse.ui.PlatformUI类访问工作台，示例如下： //取得工作台 IWorkbench workbench = PlatformUI.getWorkbench(); //取得工作台窗口 IWorkbenchWindow window = workbench.getActiveWorkbenchWindow(); //取得工作台页面 IWorkbenchPage page = window.getActivePage(); //取得当前处于活动状态的编辑器窗口 IEditorPart part = page.getActiveEditor(); 在Eclipse启动时，会要求用户配置一个工作空间(workspace)作为开发人员作业的一个区域。它在物理上是一个文件夹。在逻辑上，生成工程、创建文件等操作，一般都会在工作空间中的指定文件夹里面生成实际的文件。Eclipse使用org.eclipse.core.resource在Eclipse启动时，会要求用户配置一个工作空间(workspace)作为开发人员作业的一个区域。它在物理上是一个文件夹。在逻辑上，生成工程、创建文件等操作，一般都会在工作空间中的指定文件夹里面生成实际的文件。Eclipse使用org.eclipse.core.resources包定义的虚拟对象操作工作空间里的资源。如工程是IProject、文件夹是IFolder、文件是IFile。对工作空间的访问就使用org.eclipse.core.resources.ResourcesPlugin。下面的代码给出了访问工作空间的代码示例： //取得工作区的root IWorkspaceRoot wsroot = ResourcesPlugin.getWorkspace().getRoot(); //取得项目 IProject[] projects = wsroot.getProjects(); 工作台和资源访问的API是Eclipse提供的API中最基本的，在插件开发时使用频率较高的API。使用PlatformUI作为工作台访问的入口点和使用ResourcesPlugin作为工作区访问的入口点，是无论如何也要记住的。 插件如何与Eclipse交互全在plugin.xml配置文件当中。&lt;extension&gt;元素有point属性以指定扩展点的位置，里面通常包括将插件的图标放在哪里，以及点击插件的时候要调用的动作。另外，注意Activator类，该类为插件提供了生命周期管理。 Eclipse中的Compare功能已经可以在Ecore与UML模型之间相互比较了，在Package Explorer中选择多个文件，然后右键找Compare中的Compare as Model，即可以在语法的级别上进行模型的不同的检查。 Papyrus中包含一些Components，比如Diagram generation, 用于从一个语义UML模型中生成Papyrus图表。Papyrus Compare则用于以语义的形式或图表的形式比较Papyrus模型。C++ Code Generation用于生成C++的Profile与代码。 模型驱动开发 为了支持软件工程以建立大规模的软件系统，传统的编程思想必须发生改变。比如，如果直接访问数据，那么数据读写之后就只是数据的读写，而不会对其它的类产生影响，也不会向软件系统中的其它部分发出通知。这表明，编程方法的好坏是有条件的。在小程序上工作很好的方法，在处理软件系统的问题的时候，就变成非常差的方法了。如果我们坚持不用get/set方法，那么读写数据之后触发其它的动作简直就是不能想象的。 工厂方法 Eclipse中为我们展示了一个基本的例子。一般创建对象的时候，我们总是使用new的方法。但是这种方法，并没有形成创建对象的统一的模式。于是就了有工厂类。该类的功能就是提供创建各种对象的接口，把它们封装起来。比如： PurchaseOrder aPurchaseOrder = POFactory.eINSTANCE.createPurchaseOrder(); 用于创建一个购物单。调用该类的其它方法，可以创建其它的对象。使用这种模式，使得创建一个对象，看起来就像是访问不同的数据库一样。像是所有的数据访问的操作都被这一个对象代理了，于是就实现了所谓的“数据抽象”。相当于在人类社会中，有专门的仓库保管员来给我们做这样的事情，我们只需要发号施令即可（看起来人类总是希望指挥别人）。 我想EMF框架的最吸引人的地方不是自动地创建代码中的接口和类，而是配置生成器使得可以根据需要生成Factory类、Package类、Adapter类、Switch类等。EMF框架对面向对象的支持程度还有一些局限。比如动态绑定技术，在EMF中好像就没有得到充分的利用。但是我们知道UML是充分利用了这些技术的。 注：写到这里，我想到了Scala提供强大的面向对象的机制，使编程语言本身再结合面向对象的编程方法，可以写出非常漂亮、功能非常完善的程序的。 官方的软件提供了一些源，但是我们最好能够使用Eclipse Marketplace。该插件可以从Ecipse官方软件源中的General Purpose Tool中选择Marketplace Client选项。 Eclipse下Feature Model插件 Eclipse下Feature Model是这样做的，首先在EMFT下面有Feature Model的Project，我们可以下载这个Project.然后我们要添加pure_systems提供的更强大的Feature Model与UML相结合的工具，因为Feature Model是变化性建模的标准工具。为此，先从http://www.emftext.org/index.php/EMFText_Download找到EMFtext的下载地址http://emftext.org/update_trunk下载EMFtext。 EMFText is an Eclipse plug-in that allows you to define text syntax for languages described by an Ecore metamodel. EMFText enables developers to define textual Domain Specific Languages quickly and without the need to learn new technologies and concepts. 下载后的EMFtext要被FeatureMapper工具使用。该工具可以从http://featuremapper.org找到，Eclipse源地址是http://featuremapper.org/update下载之后安装，然后可以使用这样的工具了。还有几篇论文可以使用。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala介绍（第二版资料）]]></title>
      <url>%2Fscala-history%2F</url>
      <content type="text"><![CDATA[使用了这么久的Scala，对于Scala就又有了新的认识。觉得Scala还是一种普通的语言。它有它支持的编程范式。其实编程范式是属于思维方式问题，可以跟编程语言亳无关系。面对对象的程序设计，其实与面向对象的软件工程没有什么关系。因为软件工程的重点在软件系统上。 Scala的IDE需要在Eclipse中实现，这让人实在很头疼。一方面计算机没有足够的性能运行大型的程序，另一方面，自己也不想使用大型的软件了。很多大型软件的设计，其实根本就没有必要。软件设计的最高境界，就是软件本身作为一种语言被人使用着。 Simula 67是第一种面向对象的语言应该是可以接受的（而非Smalltalk），现在回过头来发现，其实面向对象的设计其实就是模拟现实世界，不然，也不会在与软件工程结合得那么紧密。很多软件是我们不曾接触到的。像军工等东西，应用的技术我们听都没听过，更不用说研究了。但是它们确确实实存在着，我们也得正视其存在。虽然我们现在没有那样的实验条件，但是我们也得认可Simula 67与Ada等是一种实际存在的语言。 Scala编程语言 Scala是一门多范式（函数式，面向对象）的编程语言，设计初衷是要集成面向对象编程与函数式编程的各种特性。 平台和许可证 Scala运行于Java平台（Java虚拟机），并兼容现有的Java程序。它也能运行于CLDC配置的Java ME中。目前还有另一.NET平台的实现，不过该版本更新有些滞后。 Scala的编译模型（独立编译，动态类加载）与Java和C#一样，所以Scala代码可以调用Java类库（对于.NET实现则可调用.NET类库）。 Scala包包括编译器和类库，以BSD许可证发布。 Scala的历史 洛桑联邦理工学院的Martin Odersky于2001年基于Funnel的工作开始设计Scala。Funnel是把函数式编程思想和佩特里网相结合的一种编程语言。Odersky先前的工作是Generic Java和javac。Java平台的Scala于2003年底/2004年初发布。.NET平台的Scala发布于2004年6月。该语言第二个版本，v2.0，发布于2006年3月。 Scala 2.8的特性包括重写的Scala容器库、命名参数和默认参数、包对象，以及Continuation。 2012年1月，发布版本2.9.1。 2012年4月，发布版本2.9.2。 特性 面向对象特性 Scala是一种纯面向对象的语言，每个值都是对象。对象的数据类型以及行为由类和特质描述。类抽象机制的扩展有两种途径。一种途径是子类继承，另一种途径是灵活的混入机制。这两种途径能避免多重继承的种种问题。 函数式编程 Scala也是一种函数式语言，其函数也能当成值来使用。Scala提供了轻量级的语法用以定义匿名函数，支持高阶函数，允许嵌套多层函数，并支持柯里化。Scala的case class及其内置的模式匹配相当于函数式编程语言中常用的代数类型。 更进一步，程序员可以利用Scala的模式匹配，编写类似正则表达式的代码处理XML数据。在这些情形中，列表推导式功能对编写公式化查询非常有用。 由于JVM不支持尾调用，Scala也不能完全支持尾调用优化。不过，Scala编译器可以把某些简单的尾递归优化成循环。 以下代码以函数式风格实现了快速排序算法，可以与Erlang快速排序的例子做个比较： def qsort(list: List[Int]): List[Int] = { case Nil =&gt; Nil case pivot :: tail =&gt; val(smaller, rest) = tail.partition(_ &lt; pivot) qsort(smaller) ::: pivot :: qsort(rest) } 静态类型 Scala具备类型系统，通过编译时检查，保证代码的安全性和一致性。类型系统具体支持以下特性： 泛型类， 协变和逆变， 标注， 类型参数的上下限约束， 把类别和抽象类型作为对象成员， 复合类型， 引用自己时显式指定类型， 视图， 多态方法。 扩展性 Scala的设计秉承一项事实，即在实践中，某个领域特定的应用程序开发往往需要特定于该领域的语言扩展。Scala提供了许多独特的语言机制，可以以库的形式轻易无缝添加新的语言结构：任何方法可用作前缀或后缀操作符，可以根据预期类型自动构造闭包。 联合使用以上两个特性，使你可以定义新的语句而无须扩展语法也无须使用宏之类的元编程特性。 并发性 Scala使用Actor作为其并发模型，Actor是类似线程的实体，通过邮箱发收消息。Actor可以复用线程，因此可以在程序中可以使用数百万个Actor,而线程只能创建数千个。在2.10之后的版本中，使用Akka作为其默认Actor实现。 以下代码是使用Actor模式的EchoServer实现: val echoServer = actor(new Act { become { case msg =&gt; println(&quot;echo &quot; + msg) } }) echoServer ! &quot;hi&quot; Actor模式可以简化并发编程，好利用多核CPU的能力。 程序与编译 Scala的编译和执行模型与Java是等效的，因而它也兼容于Java的构建工具，比如Ant. 直接使用Scala解释器也可以运行该程序，使用选项-i（从文件加载代码）和选项-e（若要运行额外的代码，就得实际执行HelloWorld对象的方法）即可。 Scala的测试工具有ScalaTest与ScalaCheck，后者类似于Haskell的QuickCheck库。 Scala的标准书籍是Odersky的《Programming in Scala》,见(Odersky, Spoon, and Venners 2008)。 Odersky, Martin, Lex Spoon, and Bill Venners. 2008. Programming in Scala. Artima Inc.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PXE方法远程启动Ubuntu 14.04桌面版]]></title>
      <url>%2Fpxeliunux%2F</url>
      <content type="text"><![CDATA[之前使用过各种启动方法。最近要往实验室计算机里装系统，而手头又没有光盘或者优盘，就只能再使用PXELINUX的启动方法了。再想一想，实验室里那么多台计算机，要一个一个地整系统实在太麻烦了，还不如远程启动，让一切自动化。 原理 许多计算机都有自己的远程启动机制，Intel系列使用的技术叫做PXE(Portable eXcution Enviroment)。 远程启动的过程可以与本地启动相类比。无论SYSLINUX还是Grub，抑或其它的启动模块，都完成的是Bootloader的功能。它们仅限于在开机后，帮助我们找到操作系统内核，向操作系统传递启动参数。完成这些功能后，它们就不再被使用了。引导程序(Bootloader)一般比较轻量，在几兆的数量级。操作系统（的内核）相对较大，在几十兆的数量级。 假设当前系统已经装好了SYSLINUX引导程序，启动的过程大致是： 机器加电，BIOS开机自检。完成自检后到启动设备（光盘或硬盘）的约定的位置查找引导程序Bootloader，将Bootloader的代码加载到内存指定位置 BIOS将机器的控制权交给SYSLINUX，原则上SYSLINUX可以做很多的工作。不过，我们现在关心的是，它从指定的位置读取配置文件，找到操作系统，并按设置加载操作系统。 操作系统启动，设置根文件系统，加载开机自启的程序，等等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[命令行下面的关机，PXE远程启动]]></title>
      <url>%2FPXEboot%2F</url>
      <content type="text"><![CDATA[下午针对这个问题google了一下，原因大概就是 halt 是强制关机，而poweroff 会先给 ACPI （Advanced Configuration and Power Management Interface）一个命令，之后再关机（不知道这么理解是不是准确，逃）。感觉是我直接用 halt 才出的问题。继而观察了下这三个命令， shutdown实际上是调用init 0, init 0会cleanup一些工作然后调用halt或者poweroff。其实主要区别是halt和poweroff，做没有acpi的系统上，halt只是关闭了os，电源还在工作，你得手动取按一下那个按钮，而poweroff会发送一个关闭电源的信号给acpi。但在现在的系统上，他们实际上都一样了 可以参考juju-charm上面的关于maas的区域控制器的介绍。上面用图表的形式列出了区域控制器所依赖的psql、sstream等组件。 远程启动 不同计算机支持的远程启动协议是各种各样的，在Intel的机器上，使用的是所谓的PXE(Preboot Execution Enviroment)技术。PXE协议是根据服务器端收到的工作站的MAC地址，使用DHCP服务给这个MAC地址指定一个IP。在PXE中，待启动的机器常称为工作站。PXE工作的大致过程是，工作站开机后，PXE BootROM(网卡上的自启芯片)获得控制权之前先做自我测试，然后以广播形式发出一个请求FIND帧。服务器若收到工作站的要求，就会发出DHCP回应。内容包括用户端的IP地址、预设通讯通道、开机映象文件等。工作站收到后回应相应的帧请求传送所需文件。之后将会有多次协商过程，以决定启动参数。之后BootROM由TFTP通讯协议从服务器下载开机映象文件。这个映象档就是软盘映象文件（系统映象文件）。工作站使用TFTP接收启动文件后，将控制权转交启动块，引导操作系统映象，完成自启动过程。 配置过程中，针对DHCP、TFTP、NFS进行相应的配置。DHCP用于将引导模块交给工作站，TFTP用于传送操作系统映象，而NFS用于加载开机启动时所需的各个文件。 TFTP的配置可由xinetd决定。而DHCP中的一些选项是与TFTP启动配合的。所以在正常配置好DHCP服务器之后，由next-server选项指定TFTP服务器的地址，由filename选项指定TFTP服务器文件的路径。这是因为，根据DHCP协议的规范，next-server就是TFTP服务器的地址。 ## 目标机器的DHCP配置项 host target { ## 目标机器所匹配的MAC地址 hardware ethernet 00:13:21:1F:F1:82; ## 目标机器分配到的IP地址 fixed-address 192.168.0.10; ## 目标机器所使用的网关地址 option routers 192.168.0.254; ## 目标机器所用的DNS option domain-name-servers 208.67.222.222,208.67.220.220; ## 指定TFTP服务器的地址。如果TFTP与DHCP服务器是一个IP，则可以忽略 next-server 192.168.0.2; ## 指定开机文档在TFTP服务器上的路径 filename &quot;/ubuntu-installer/i386/pxelinux.0&quot;; } 然后可以开启TFTP服务，并且操作系统映象也可以放在TFTP服务器上。对于Ubuntu来说，可以将光盘中的/install/netboot/ubuntu-installer/目录复制到TFTP目录下面。之后，打开客户机的电源，BIOS中选择从网络启动即可。 上面的DHCP配置中仅有被启动的工作站的配置节，而正常的DHCP应当有针对子网的配置。dhcpd.conf文件的其他部分可参考示例文件： ddns-update-style none; ignore client-updates; allow booting; allow bootp; subnet 192.168.5.0 netmask 255.255.255.0 { option routers 192.168.5.1; option subnet-mask 255.255.255.0; option domain-name-servers 202.112.128.50; range dynamic-bootp 192.168.5.33 192.168.5.38; default-lease-time 21600; max-lease-time 43200; } 我们知道，本地启动的时候，有GRUB和LINUX系统映象两个文件。前面的pxelinux.0就相当于GRUB、整个光盘就相当于开机系统。linux发行版光盘的install/netboot目录中有pxelinux.0文件及相应的配置选项，使用的时候，该文件夹的内容全部拷贝到TFTP根目录下面。 Ubuntu一系的软件，光盘映象基本上都放在HTTP服务器上。也就是操作系统映象自TFTP传到工作站并运行的时候，Ubuntu自动从本网络的一台HTTP服务器上查找安装所需文档。此时，我们可以选择将整个光盘映象挂载至HTTP服务器的 /ubuntu目录下面。工作站的PXELINUX启动的时候，会向我们询问操作系统映象的地址。 如果合适，我们也可以将安装好的系统分发给其它的工作站，而不用远程安装系统。 实战 首先安装Ubuntu上所需要的各种软件，然后将Ubuntu14.04的映象下载过来。 apt-get install nfs-common nfs-kernel-server apt-get install tftpd-hpa tftp-hpa apt-get install isc-dhcp-server DHCP服务的端口号是TCP67，而TFTP服务的端口号是UDP59，可以通过netstat命令查看相关的设置。 tftp-hpa使用的配置文件是 /etc/default/tftpd-hpa ，可以根据需要，将TFTP的服务器目录改变到其它的位置。不过，配置的时候，注意权限问题。 isc-dhcp-server使用的配置文件是 /etc/dhcp/dhcpd.conf 。配置的时候按照格式。 配置DHCP的时候，应将这里的DHCP与服务器上的DHCP区分开。一般而言，笔记本在连接无线的时候，有线网络并不受到影响。这个时候我们可以指定本机的地址，然后在dhcpd.conf文件中，将网关的位置填写成自己的。其实，如果是局域网里面访问，则根本不需要网关地址。因为局域网中的主机访问，不需要通过网关。 NFS服务是可选的。如果需要使用这个服务的话，使用NFS的时候，别忘了安装nfs-kernel-server。然后编辑 /etc/exports 文件，选择需要导出的数据。 然而在共享的时候，NFS需要用户的密码。这一点需要我们注意。没有/etc/exports里面的文件的时候，导出的目录是空的，NFSD守护进程也不会运行。简单的导出可 以是 /srv/www *(ro) 这样的行。 PXELINUX介绍 其实使用TFTP服务全部依赖于所谓的PXELINUX启动程序。该程序与SYSLINUX、EXTLINUX同属于一个发行版。PXELINUX的pxelinux.0文件所在的TFTP的根目录，其实就相当于本地启动的时候的boot分区而已。 下载PXELINUX程序之后，将 /usr/lib/syslinux/pxelinux.0 文件复制在TFTP根目录下面。然后在TFTP根目录下建立pxelinux.cfg目录。在目录中建立default文件。其实，PXELINUX的解释是， pxelinux.cfg目录代表了对不同的客户机的启动选项的配置，以便支持不同的系统。而只有一个default文件的时候，相当于局域网中只有一个主机。 下面是PXELINUX的配置文件的一个示例写法： DEFAULT ubuntu LABEL ubuntu kernel linux append initrd=initrd.nfs root=/dev/nfs nfsroot=192.168.1.88:/home/cache/netboot/root ip=dhcp rw kernel与append命令所需的linux与initrd文件，都是以TFTP根目录为根所得到的文件路径。因此内核linux与initrd文件要与pxelinux.0一起放在TFTP根目录下。 任何linux内核均支持root=这样的参数，大部分也支持nfsroot选项。如果把nfsroot都指定了，那么工作站将以nfsroot所指的位置作为根系统。然后，找到根系统后，我们就可以从根文件系统的 /etc/fstab中加载其它的NFS挂载选项。通过不同的组合，可以实现无盘工作站或者有盘工作站。 如果理解了内核的root=选项，以及联想到OpenSUSE安装光盘具有指定光盘位置的选项，那么远程安装系统就不是什么困难的事情了。 对于Ubuntu来说，不同之处在于，Ubuntu的安装映象支持ks=选项，而ks=又可以调用http服务，因此Ubuntu具有从HTTP服务器上下载文件的能力。显然，如果工作站能够下载服务器上的安装映象，那么自然就能够完成接下来的安装。 网络唤醒功能 网络唤醒功能一个是网卡支持，第二个是BIOS启用，另外一个是有应用工具。网卡的支持是生产商的问题。BIOS中启用与否，可以在机器BIOS中启用，应用工具则是运行在具体操作系统下面的。 linux的ethtool工具可以用于修改网卡上WOL的状态，决定从网络唤醒是否启用。使用 ethtool -s eth0 wol g 就可以启用网卡的网络唤醒功能。 wol d表示禁用。 linux的 wakeonlan工具是唤醒网卡的终端。它接受MAC地址作为参数，唤醒局域网中具有此MAC的机器。 完成PXE启动的时候，导出NFSROOT目录，配置为 /etc/exports: the access control list for filesystems which may be exported to NFS clients. See exports(5). Example for NFSv2 and NFSv3: /srv/homes hostname1(rw,sync,no_subtree_check) hostname2(ro,sync,no_subtree_check) Example for NFSv4: /srv/nfs4 gss/krb5i(rw,sync,fsid=0,crossmnt,no_subtree_check) /srv/nfs4/homes gss/krb5i(rw,sync,no_subtree_check) /srv/www *(ro) /srv/tftpboot/ *(no_subtree_check,rw,no_root_squash,async) 然后在启动文件 pxelinux.cfg/default 中配置启动选项为: # D-I config version 2.0 prompt 0 timeout 100 DEFAULT ubuntu LABEL ubuntu KERNEL ../ubuntu/casper/vmlinuz.efi APPEND initrd=../ubuntu/casper/initrd.lz boot=casper netboot=nfs root=/dev/nfs nfsroot=10.10.10.1:/srv/tftpboot/ubuntu ip=dhcp 其中 /srv/tftpboot/ubuntu 相当于光盘的根目录，里面有linux安装光盘里面的所有的文件。这种方式只需要NFS就可以，不用HTTP服务，因此是一种比较好的解决的办法。 剩下的就是 wakonlan 的测试了。这也应该是不成为问题的。只需要将网卡配置好就可以了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Scala语言编程]]></title>
      <url>%2Fscala-tutorial%2F</url>
      <content type="text"><![CDATA[接触过许多编程语言后，对Scala也就不那么热心了。一句话，Scala有的，有什么是在其它编程语言中没有的么？像函数式编程语言、面向对象编程，找了一打，也找不到以Scala为代表。在具体特性上，Python的字典，比Scala的映射表其实更为好用。在叠代上，Python至少更方便，而且C#的LINQ查询似乎比Scala走得更远。Scala是静态类型的，而现在，有很多脚本语言已经成为了“高级动态语言”，这也是Scala望尘莫及的。 个人觉得，对Scala语言的正确定位是，它是一种新的开发应用的方式，按照Scala的这种方式，并不需要激进的革命，传统的程序员就可以完成转型。因此，软件工程与编程语言的结合得到了保留，一个语言同时也就是为一个软件工程而生。 甚至C#，因为所使用的CLR技术，比Scala更强调机器的技术。Java和Scala一系的基础结构其实很简单，就是脱离机器的JVM虚拟机。得益于对这个虚拟机的优化，它们得以演变成独立的生态环境。而像Python与Ruby这样的，对于怎样编译其实并不关心，因为有CLR帮助它们，所以Python与Ruby可以更强调编程的灵活。 Scala的安装、配置和基本使用 Scala与Java有许多相通之处，因此用Java的观点看Scala往往可以减少学习曲线的坡度。有人说，一周学一打语言都不算是值得称道的计算机科学家，此话对于Scala也是适应用的。 可参见Donald E. Knuth的大作《The Art of Computer Programming》。 在Ubuntu下面，安装scala程序之简单，就不必说了。安装好之后，将会得到scala、scalac、scalap、scaladoc、fsc几个命令。由于Scala的语法糖中有一个是既可作为命令式语言中的脚本，也可作为所有方法都在对象中的类(Java)，所以scala既可以作为Scala语言的解释器，也可以作为运行所谓Scala字节码的运行时环境。该技术的实现另有细节，现在只需记住这两种方式即可。 直接运行scala命令，可以进入脚本式执行环境。里面可以逐个写Scala语句，而不用担心非得使用面向对象的编程，像Java那样，把程序写在类里面。scala命令也可以直接运行一个标准的Scala程序，不过由于每次都要加载大量的类库，即使运行一个HelloWorld这样的程序，需要的时间也相当长。因此把Scala当成一个脚本语言，显得非常别扭。 scalac命令是把scala代码编译成字节码格式，以便以后脱离开发环境也能执行。编译生成的 .class 文件，可以交由scala命令直接处理，运行的速度还可以。不过，Scala的scalac编译器编译HelloWorld这样的程序的时候，也是相当慢，为此有了一个人性化的方案，即使用fsc编译，fsc的作用就是开启一个守护进程，将本次编译之前加载的库文件都缓存下来，下次调用fsc的时候，直接从里面取，因此就加快了编译的速度。 说到底，Scala的scala、scalac、scaladoc工具，与Java的java、javac、javadoc可以分别对应，在Java里怎样使用后者，就可以在Scala里怎样使用前者。scalap可以看成是一个逆向工程工具，用于解码Scala类文件。 平常学习的话，使用scala程序直接写脚本，并使用scala运行即可。此外，Martin Odersky等蓍的《Scala Programming》一书的“附录A：Unix和Windows下的Scala脚本”介绍了把scala脚本当成系统的可执行文件的方法。看起来有用，但是那样用的时候，Scala在各种脚本语言与高级动态语言中显得特别笨重、缓慢，使用它太破坏体验了。这种方法，便就不再介绍了。 Scala概述 定位Scala的正确思路，或许是把Scala看成是Java的自然延伸。这里的自然延伸是从编程语言大家族的发展来看的。Java本身与C和C++相比，其进步并不是很大，但是其业务确实很成功。近些年来，函数式编程、动态类型等开始变得流行，使得传统指令式语言受到一定的冲击。应用型编程语言尤其应当得到改进。因为人们看到了它们存在很多能力上的限制。对于单片机程序的开发语言来说，C语言的短处是它们不必看到的，相反，因为基础，还有更多的长处；对于函数式语言编程者来说，LISP等语言现在已发展得很成熟。不仅有严密的理论，也实现了许多的库，甚至以LISP语言实现了操作系统。所以，Java与Scala好像是正夹在中间，其缺点正好为广大的应用开发者所在意。那么，Java的改进就十分现实了。 在设计软件产品上，很多时候，一开始的思想固定下来后，再对它修修补补，还不如来一场更彻底的革命。Java虽然做了很多的改进，然而这些改进似乎不仅不能转化成优势，而且使语言本身变得更为复杂，不得不全部推倒，重新实现。其结果，大概就是现在的Scala了。 Scala本身仍是面向对象的、静态类型的语言。这可能是出于符合现在应用程序员的习惯，也可能是不得不这么做。这使得函数式编程还不能成为该语言的核心卖点。这么说吧。把Scala看成是改进的Java。 即使在Java当中，语法特性也并不值得单独去讲。因此在Scala中，对于经典的数据类型、函数、运算符、控制语句，都略写；对于Scala在业务应用上的特点给以重点的介绍。如线程与消息处理机制。另外，不变类型、 \(\lambda\)-演算，笔者在其它语言中也接触过许多，也作简略处理。 一句话，Scala不适合作算法级（结构级）的编程语言，它主要是一个工程级（应用级）的编程语言。 单独运行的Scala程序 要使Scala程序能单独运行（在Scala中，指的是可以编译成字节码在Scala虚拟机中执行，并非操作系统直接可认知），程序就要有一个main方法。该方法仅有一个 Array[String] 作为参数，并以 Unit作为返回类型。任何拥有这样签名的main方法的单例对象都可以作为程序的入口。 单独运行的Scala程序示例 object Hello { def main(args: Array[String]) { for (arg &lt;- args) println(&quot;Hello, World!&quot;) } } Scala应用程序源文件一般以 .scala 作为后缀。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[千呼万唤始出来(整好github)]]></title>
      <url>%2Fblog-github%2F</url>
      <content type="text"><![CDATA[整理github博客 测试了很多。现在的代码应该是正常的吧。 代码使用Python块，使用Markdown内嵌的支持。 A block of text. import os print &quot;hello,world&quot; 代码虽然不是很好看，但是也可以接受。 数学公式使用MathJax插件，下面的是勾股定理： \[a^2+b^2=c^2.\]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MathGL绘图工具]]></title>
      <url>%2FMathGL%2F</url>
      <content type="text"><![CDATA[该绘图工具的应用也很广，但是之前一直都没有能够接触到。现在才将相关的内容补充到笔记当中，希望这是一个非常有效的绘图的工具。 MathGL在Ubuntu下的安装是一件简单的事，安装mathgl关键字开头的程序、文档、头文件与库文件、面向Python语言的python-mathgl库，以及udav可视化工具即可。MathGL支持几种不同的编程方式，面向C、C++、Fortran、Octave或者Python。根据需要，应当安装上不同的接口。也许有一天，支持R也是可行的。此外，MathGL工具还可以分析一种称为MGL的脚本文件，该脚本文件可以方便地完成MathGL中的一些绘图操作，是值得学习的一种操作方式。 在绘图过程中，MathGL有自己的字体系统，但是尽量可以做到与TeX的兼容。不仅可以方便地选择字体，而且提供了大量的数学符号。这些对于初学者及一般的应用都是非常充足的。 MathGL有很多优点。如脚本化的绘图语言、C++的执行效率、多语言接口、支持输出多种图形格式、内建多种绘图方法、支持MPI等编程接口、与C++等宿主语言的数据结构融合。这些使它成为很有吸引力的一个绘图库。 MathGL基础操作 首先我们介绍在MathGL在C++下的使用。像C++这类接口，一般要安装lib*这样的软件包，而不只mathgl软件包一个，这样g++在编译的时候，才可能与正确的库文件链接。这是一个需要注意的地方。如果下面的MathGL C++程序出错，根据编译器反馈的错误信息，我们应当能够发现错误、纠正错误。 #include &lt;mgl2/mgl.h&gt; int main(int argc, char* argv[]) { mglGraph graph; graph.FPlot(&quot;sin(pi*x)&quot;); graph.WriteFrame(&quot;test.png&quot;); return 0; } 编译、运行mathgl1.cpp，查看图片所使用的Bash命令建议为: g++ -lmgl mathgl1.cpp -o mathgl1 ./mathgl1 eog sample.png 注：如果使用了其它的绘图接口，可能需要使用 -lmgl-wnd 等库。 MathGL的绘图画布中使用帧、子图等概念，因此一个 mglGraph对象可以创造出多个子图的组合，以及多个帧的组合。后者使MathGL有制作动画的能力。 使用MGL脚本的时候，MathGL中有 mglconv 工具和 mglview工具可以使用。它们 是运行MGL脚本的宿主环境。 MathGL库支持的输出方式，包括向图形终端输出，此方式下可以完成一些交互式的动作；直接写入到点阵或者矢量图形格式，此方式下直接运行MathGL的C++程序以得到结果。 窗口绘图、GLUT绘图与输出到文件 绘图到一个单独的窗口，或者使用GLUT库输出，道理是一样的。 #include &lt;mgl2/mgl.h&gt; #include &lt;mgl2/window.h&gt; int do_draw(mglGraph *graph) { graph-&gt;Rotate(60,40); graph-&gt;Box(); return 0; } int main(int argc, char* argv[]) { mglWindow window(do_draw, &quot;MathGL Window example&#39;); int status = window.Run(); return status; } 原理就是如此了，不过在Ubuntu上有些错误，可能是安装MathGL的问题。 使用GLUT作为后端的时候，更为简单，因为不用WX组件了。 #include &lt;mgl2/mgl.h&gt; #include &lt;mgl2/glut.h&gt; int do_draw(mglGraph *graph) { graph-&gt;Rotate(60,40); graph-&gt;Box(); return 0; } int main(int argc, char* argv[]) { mglGLUT window(do_draw, &quot;MathGL Window example&quot;); return 0; } 在编译的时候，调用 g++ mglut.cpp -o mglut -lmgl -lmgl-glut 如果将 -lmgl 选项放在 mglut.cpp的前面，似乎总会出现连接错误。这个问题 目前还不知道是怎么样的一回事。 在GLUT界面中，使用aswd按键旋转图形，使用r与f切换透明(transparency)与光照(lighting)状态。按键x可以退出窗口。 说明：以后我们的绘图的时候，就使用上面的代码所提供的方法，把绘图的代码都放在 do\_draw() 函数里面，然后由 mglGLUT对象调用。这样可以使我们更 专心于图形的绘制。 如果是输出到文件，那么调用 mglGraph 对象的 WritePNG()、 WriteEPS() 等 函数即可。在使用g++编译的时候，除了-lmgl 选项，其它都不用。 动画的制作使用 mglGraph对象的多帧功能。如果是保存GIF格式，在绘出每帧 之前，就应当使用mglGraph 的 StartGIF() 函数保存文件，并在完成所有的帧的绘制之后使用 CloseGIF() 函数关闭GIF文件的描述符。 保存动画还有另一种方法，就是绘制完当前帧后，以frameXX.jpg的格式保存当前帧，然后切换到下一帧。所有的帧都各自输出成JPEG格式后，使用ImageMagick提供的convert命令将JPEG制作成MPG。 MathGL也支持在Qt绘图画布中绘图，图形作为Qt窗口的一部分。但是那并非MathGL绘图语言的核心。现在不讲，或许以后结合PyQt库使用MathGL的时候这个功能我们会用到。 MathGL对子图绘制的支持 MathGL采用“选中-绘制”的方法支持子图的绘制，也就是一个mglGraph 对象使用 SubPlot()方法选中一块子图区域，之后还是使用 mglGraph 对象的Title()等函数来操作绘图，此时图形会自动绘制在当前的子图上。在绘制子图的时候，另一种编程实现是“切换-绘制”的方法。该方法是调用当前绘图对象的方法产生一个子图对象，通过操作子图对象的方法在子图上绘图。Asymptote与Mathplotlib等都是采用这种方法。MathGL是前一种方法，因此要与后一种实现方式区分开。 int do_draw(mglGraph *g) { g-&gt;SubPlot(2,2,0); g-&gt;Box(); g-&gt;Puts(mglPoint(-1,1,1),:&quot;Just box&quot;, &quot;:L&quot;); g-&gt;InPlot(0.2,0.5,0.7,1,false); g-&gt;Box(); g-&gt;Puts(mglPoint(0,1.2), &quot;InPlot Example&quot;); g-&gt;SubPlot(2,2,1); g-&gt;Title(&quot;Rotate only&quot;); g-&gt;Rotate(50,60); g-&gt;Box(); g-&gt;SubPlot(2,2,2); g-&gt;Title(&quot;Rotate and Aspect&quot;); g-&gt;Rotate(50,60); g-&gt;Aspect(1,1,2); g-&gt;Box(); g-&gt;SubPlot(2,2,3); g-&gt;Title(&quot;Aspect in other direction&quot;); g-&gt;Rotate(50,60); g-&gt;Aspect(1,2,2); g-&gt;Box(); return 0; } 更复杂的子图绘制方式，可以参考 MultiPlot() 、StickPlot() 等函数。 剩下的就是具体各种图形的绘制了。 使用MathGL绘制动画示例 int do_draw(mglGraph *gr) { gr-&gt;NewFrame(); gr-&gt;Rotate(60,40); gr-&gt;Box(); gr-&gt;EndFrame(); gr-&gt;NewFrame(); gr-&gt;Box(); gr-&gt;Axis(&quot;xy&quot;); gr-&gt;EndFrame(); return gr-&gt;GetNumFrame(); } 使用MGL脚本语言 MGL脚本语言其实是很方便的一个东西。该语言每一行都代表一个命令，类似于tcl脚本，而且连注释的格式都是与tcl语言相同的：从#开始直到行尾。另一方面，MGL脚本按行分析语句，语句的第一个单词代表一个命令，像Bash中那样。而MGL脚本中的字符串用成对的单引号括起来，如果需要跨行，则使用反斜杠加换行表示将本行与下一行联系在一起。 MGL脚本中的命令都来自 mglGraph的成员函数，因此只要我们了解了MathGL面向C++的库的用法，自然就知道如何写MGL脚本文件。 除此之外，MGL还有一些定义函数、声明变量的语句。它们都转成相应的C++的语法。在C++中使用MGL语言也是可行的，因为MGL脚本会通过 Parse()函数 被解析，由 Execute()函数执行。(两个函数都在mgl2/mgl.h头文件中)。 A. A. Balakin所蓍的《MathGL官方文档》中的《MathGL core》一章，既介绍了MathGL语言(C++库的函数)，同时又介绍了MGL的命令，是MGL语言与MathGL库的最标准的参考手册。 MathGL所提供的mglconv工具可以将MGL脚本转换成PGF/TikZ、EPS、PRC、SVG等格式，因此也可以作为一个实用的面向TeX文档的接口。这样一来，可能在MathGL中文字处理变得更简单了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Gnuplot绘图]]></title>
      <url>%2Fdrawing-gnuplot%2F</url>
      <content type="text"><![CDATA[使用过很多的绘图的软件了，但是用起来总是不那么方便。而且我的绘图是在文档当中的，要求与文档有相同的风格。但是通常情况下，这些都难以达到。因此，不管是Asymptote还是其它的软件，配置起来都比较麻烦。 MetaPost的问题是，Metapost与XeTeX不太兼容。使用中文的时候又不方便了。所以我们还是使用其它的方法。 gnuplot有一个优点，就是它可输出成TeX的源代码的格式。第一种是LaTeX自带的picture环境，在里面直接绘图。第二种是tikz环境。无论哪一种环境，排版的工作都是连同文字一起的。所以正文是什么格式，其它文章也可以是这样的格式。 如果将gnuplot的输出改成picture环境，那么在每个gnuplot文件前面添加如下的行： set terminal latex ## 也可以是emtex环境。 set output &quot;pic.tex&quot; ## 生成的.tex文件。 然后使用\input{pic.tex}将生成的文件嵌入到文本中，注意段落的安排，以及将图表排版有适当的空格。 如果将gnuplot的输出改成tikzpicture环境，那么在每个gnuplot文件前添加 set terminal tikz ## 也可以是 set terminal lua tikz。 ## 还可以在 tikz 后添加额外选项，如 fontscale 0.9 , latex, tex, context。 set output &quot;pic.tex&quot; 同样使用\input{pic.tex}将生成的文件嵌入到文本中。不过tikz图像 也可以在 plain TeX 环境下使用，因此使用这种方法，支持在tex或者xetex环境中插入图片，并不局限于latex或者xelatex。如果是在LaTeX环境中使用，则需要使用如下的宏包： \usepackage{tikz} \usepackage{gnuplot-lua-tikz} 如果是plain TeX，则使用\input gnuplot-lua-tikz.tex命令。这样一来，gnuplot就非常能够满足我们的需要了。所以我们学习绘图也就从 它开始讲起。 Gnuplot绘图基础 Gnuplot是一个交互式的绘图语言。绘出的图形展示在一个设备上。所以我们在绘图脚本中需要指定绘图的终端类型，以及输出的文件。默认情况下，Gnuplot是将图形输出到显示器。我们也可以更改成其它类型。前面我们就已经介绍了如何将图形导出成 .tex 格式。实际上，Gnuplot支持几乎所有的图片格式与文档格式，完整的支持可以参考Gnuplot官方文档的 Terminal Types一节。 从4.6版本开始，Gnuplot支持了控制语句 if/else/while/do。这使得一些 表达式变得非常简单。 建议对Gnuplot文件使用 .gpl 扩展名。 出于排版文档的需要，在绘图之前，我们需要明确地指定绘图画布的大小，使图片不超过这个区域。在Gnuplot中，是通过 set termial 命令的size XX,YY实现的。任何终端均支持这个选项，前面的文档也不例外。如果terminal 类型 是 tikz ，那么默认的单位是 cm，后面跟数字。实际上， XX 、 YY 的 单位也可以是mm 、 in 、 pt等。建议在绘图之前给图像确定一个大小。 set size XX,YY 命令也起到设置图片大小的命令。但是它只是改变绘图区的大小，而非改变画布的大小。绘图区的大小可以通过 ratio 等指定，分别表示在 (X) 或 (Y) 方向的比例缩放的情况。 在Gnuplot当中，绘图都是通过绘图语句实现的，因此讲的并不多。重点的是Gnuplot的数据类型与运算规则。 而Gnuplot的表达式运算规则主要来自于C语言。与C语言相同，Gnuplot的表达式中间的空格会被忽略。 在Gnuplot当中，复数值有特定的表示方法，一个二维数组，用大括号括起来，就是一个复数，第一分量代表实部，第二分量代表虚部。如 {3,2} 代表着复数 (3+2i)。如果对字符串使用用于数值类型的运算符，则Gnuplot尝试把字符串转成数值再进行运算。比如在Gnuplot当中， &quot;3&quot;+&quot;4&quot;=7 ，并且 6.78=&quot;6.78&quot; 。 对字符串允许使用下标运算符 [BEGIN:END] ，表示提取数组中区间\([BEGIN,END]\)中的元素。使用 * 号，可以代表对其中一个区间不加限制。 在Gnuplot当中内置了许多数学函数，而反函数在原函数前加 a ，如 sin(x) 的 反函数是 asin(y) 。三角函数的单位是弧度。** 表示取幂运算， * 表示乘法。 .表示字符串的连接。 ne 、 eq 表示字符串的相等的判断（而 == 表示 的是两个数值类型的相等。 绘图语句 在Gnuplot中实际绘图的语句只有 plot 、 splot 、replot 三个。 plot 语句产生2D图形， splot 产生3D图形，而 replot 则是把它的参数 加到前一 plot 或 splot 语句绘图当中，并修改它们的绘图结果。 plot 绘图可以使用直角坐标或者极坐标，具体行为受到 set polar 命令的 影响。 splot 绘图仅能使用直角坐标，但是也能通过 set mapping 选项使用其它的一些坐标系。最后， using 命令可以让我们对付大多数的坐标系。 在直角坐标系下面， plot 命令可以使用四个坐标轴 (X) 、 (X2)、 (Y) 和 (Y2) 。它们分别代表底、顶、左、右方向的坐标轴。 axes 选项可以指定我们所使用的数对分别与哪一个坐标轴相对应。坐标轴的刻度也可以修改。比如 set logscale xy 允许我们对两个坐标轴都使用对度刻度。 splot 命令可以绘制表面图(surfaces)或者等高图(contours)。使用 set contour 或者 set cntrparam 命令可以改变绘图等高图时候的行为。在3D绘图中，对坐标轴同样可以使用不同的刻度，如对数刻数。 绘图的参数来源 Gnuplot的绘图语句中都可以直接书写绘图的表达式，它们含有若干个变量。但是表达式可以有不同的产生方法。在赋值语句中，以单引号括起来的内容表示一个Shell命令。在解释时，Gnuplot会将出现的地方替换成相应的结果。比如\(f(x)=`whoami`\) ，实际上是\(f(x)\)等于命令\(whoami\)执行的结果。 在shell命令中，也可以通过 @var 引用Gnuplot里面的变量。即使 \\\``出现在字符串双引号当中，也并不影响命令的执行。“`uname -a`”返回的仍然是命令的结果。不过“uname -a”`并不会引起Gnuplot执行一个系统命令。 绘图语句与绘图风格是相关联的。绘图风格指的是图形的类型，比如直方图，散点图等。绘图风格不同，绘图语句的行为也不相同。 绘图风格由 set style 指定。常包括 set style data 与 set style function 。它们影响其后的 plot 与 splot 语句的行为。 GNUplot绘图工具 使用之后，除了命令行不太方便外，其它地方还很方便。至少可以直接整合到LaTeX里面，这样就使排版的效果大大增强了。 GNUplot的用法其实很简单，其设置是样式、选项与绘图的综合。绘图语法中需要指定数据源以及绘图的样式即可。坐标轴也各自有自己设置的办法。 对GNUPLOT有疑问的话，可以直接使用help语句，此时在对话界面中会显示出来相应的帮助。另外，gnuplot的一个简单的例子如下： set terminal png size 1000,400 set output &quot;./sin.png&quot; plot sin(x) gnuplot的命令有两类，一类是修改状态，一种是绘图指令。set方法都是修改状态。使用plot, replot, multiplot来绘图。 gnuplot对于数据中的时间项有很好的支持，可以直接将文本中某些数据项设置成时间的格式。这一功能对于日志分析与统计报表极为有用。 上面列举了许多极有有趣的例子。 上面给出了调整直方图的一个教程。 命令式编程语言的绘图包括Python绘图工具，gnuplot, 以及C语言的编译工具等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Awk工具与编程语言]]></title>
      <url>%2Fawk-lang%2F</url>
      <content type="text"><![CDATA[说明 刚接触unix相关的书籍的时候，里面有一章是专门介绍awk的使用的。但当时觉得它过于复杂，很难记住它是什么，能干什么。想来是因为我知识的储备还不够。Awk主要的思想就是，它的确是一种设计得非常精巧的编程语言，很好地满足了实际应用的同时，也能够让我们以软件工程，编译原理等理论性的东西欣赏它。因此，我就知道awk的使用不再是一件困难的事情。 awk基础 有些东西，理解它的过程，就好像是要进入一个豪华的庭院，要进入门内，非得绕过门前的屏风墙。不这样，就看不到里面的风景。 awk本身的语法是比较怪异的。然而外面的人看到的，往往是用awk写出来的程序，而非程序的规范。所以就不得要领。人们又常常抱着学习awk就直接是为了处理文本的功利目的，一旦不能一眼看出来它在处理文本上的直观，就放弃了。但是，绝大部分事情，是不能凭感官的。我们必须要有一种理论的指导。 让我们忽略掉awk的语法形式，单纯地考虑，如果是我们，将会怎样处理文本，特别是在C语言的框架下编写这样的程序。将能设想到，基本的方法，还是通过传递变量。也就是至多每读取一行，就自动将参数匹配到指定的位置。因此整个awk程序，首先看成是一个函数。宿主环境代理地读取目标文本，并在每次调用函数的时候得到参数。文本处理的思想，也就只能如此了。 另外，我们看到，awk在文本处理上做得更深一步。它本身是一个编译型的语言。也就是说，在文本没有读取之前，宿主环境先进行语法等方面的检查，通过之后才开始处理程序。这一点与 make 程序相似。因此，首先应当考虑到awk是如何检查脚本的，再考虑脚本如何执行文件。命令 awk -f AWK脚本.awk 数据文件 可以与 python py脚本.py 参数 相类比。 通常调用awk的时候，AWK脚本可以是即时编辑的，也就是脚本的内容直接出现在命令行的第一个参数中。把这个功能看成是一个语法糖，也许就顺畅多了。 awk程序的执行流程是： 读取指定的脚本命令并进行语法的检查； 从指定的数据文件中读取一个数据行； 自动更新相关的内建变量的值，如 $0 , $1 , NR ； 依次执行程序中每个 Pattern { Actions } 指令； 处理完当前行之后，读取下一个数据行，自动返回步骤三继续执行； 文件处理完毕，结束运行。 Awk主要概念 Awk程序的主要语法是 Pattern { Actions } 。一个Awk程序常常由许多这样结构的语句构成。在执行的时候， Pattern 主要是确定一个逻辑表达式，若数据行符合这样的条件，就执行相应的 Actions ；不符合条件则执行下一个 Pattern { Actions } 语句。如果 Pattern 为空，则表示无条件执行该语句的 Actions 。 在 Pattern 部分中，可能最需要介绍的部分是Awk的关系运算符。Awk本身是用C语言编写的，而且继承了其中常见的关系运算符，如 &gt; 、 &lt; 、 &gt;= 、 &lt;= 、 == 、 != 。此外，Awk还用运算符与!表示字符串与正则表达式的匹配。 BEGIN 与 END 是特殊定义的模式匹配语句，分别表示在第一个记录之前，与最后一个记录之后。 在 Actions 部分，主要是许多Awk指令。Awk的指令与C语言也十分相似，大多数时候，只是改用Shell那样的传参方式，而非C语言的函数。Awk的指令大致可分为普通指令与控制指令两类。前者如 print , getline ；后者如 if(...){...} else{...} , while(...){...}... 。除此之外，C语言赋值表达式往往也继续有效。 遇到 Pattern { Actions } 语句，Awk会先计算 Pattern 的值，若计算出的值为 true 、非零的数字或者非空字符串，则awk将执行后面的 Actions 。在其它条件下，将跳过相应的 Actions 。这一过程，可以与路由器上的ACL处理流程相类比。 为了方便对数据行的处理，Awk提供了许多内建的变量。常见的变量如下： 变量符号 含义 $0 awk当前所读入数据行的所有内容 $1 当前所读入数据行的第一个字段的内容，下个字段的变量依次类推 $NF Number of Fields。表示当前读入数据行 $0 含有的字段数 $NR Number of Records。表示已读入的数据行的数目 $FILENAME 当前文件的名称 注：awk的变量并不需要用$符号括住，用以字母打头的英文字符即可。$实际上是awk的一元运算符，它以一个数字为参数，表示操作“取字段”。 awk处理数据的时候，自动从数据文件中每次读取一行记录，然后将记录切分成若干个字段，程序可使用$1、$2等直接取得字段中的内容。若要简单打印出相应字段，使用print $1, $2这样的语句即可。 此外，awk还提供 printf() 指令，它的使用方式与C语言更相近，用于格式化字符串。 比如: awk &#39; { printf(&quot;%d times %d is %d.\n&quot;, $1, $2 ,$1 * $2) } &#39; 234234234 234234234 将显示出两个字段的乘积。从上面的例子我们也看出，awk的整型运算功能是非常强大的，可以进行非常大的整数之间的运算。可以认为具有无限的精度。 作为一个领域专用的语言，在变量的使用上，要尽可能足够简单。所以awk的变量，不需要宣告就能够使用，类型是自动确定。并且，awk提供的“字典”(有人称为数组)类型，也可以自动使用。引用字典不存在的键值的时候，该键值会自动被创建。 awk与shell指令 在awk中使用shell指令是比较方便的。其思想是让字符串通过管道运算符|与awk内置的函数运算。字符串被当成指令执行，执行后的输出的结果，被当成内置函数的运算符。比如 &quot;who&quot; \| getline getline 是awk的输入指令。当 Pattern 为 BEGIN 或 END 的时候， getline 默认从 stdin 读取数据，否则从awk正处理的数据文件上读取数据。 若是后者，将会使数据文件中的两行当成一个记录来处理。 使用getline之后，变量 $0 , $1 等的内容会被刷新。 在awk中，输出文件则使用重定向运算符 &gt; 或 &gt;&gt; 。它可以用在任意 Action 之后。重定向运算符可以理解成一个普通的 Action 与一个字符串运算，而字符串被解释成文件的路径。 awk也提供了一个 system() 函数以调用shell命令。 注意，在执行shell指令的时候，相同的字符串代表同一个pipe名称，因此尽管出现在不同的 Actions 当中，shell命令可能只启动一次。具体意思是，比如 print $1, $2 &gt; &quot;sort -k 1&quot; 这一语句，并非每执行一个 print ，就启动一个 sort -k 1 进程。而是所有 print 出来的内容，都送到 sort -k 1 这个程序的输入管道中，因而所有 print 出来的内容都输入同一文件流中，被 sort -k 1 处理。要想关闭此管道，必须显式地使用 close() 函数。 awk程序的结构 一般而言，awk当中都是 Pattern { Actions } 指令。但是还有其它类型的语句，包括注释与函数定义。注释以#号开头的行，而函数字义与C语言类似，比如 function double(x) {return 2*x} 。 其它 在写awk程序的时候，可能会用到许多字符串函数，如 substr() , length() 。一般而言，是不可缺少的。 awk读取文件的时候，使用FS作为字段分割符。它可以取一个正则表达式， 但默认情况下都是空白字符。若不想在启动awk时指定 FS ，可以在 BEGIN 对应的 Actions 中更改 FS 的值。 awk读取文件的时候，使用 RS 作为记录分割符。默认 RS 是字符 \n 。但是我们也可以改成其它的符号。特别地，当定义 RS=&quot;&quot; 时，分割符是空白的行。此时，中间无论多少空白行，都被当成是记录分割符。 awk程序也可以有参数。这些参数在程序中通过 ARGV[] 与 ARGC 标识。 awk中所有的变量都默认是全局变量，除了函数参数之外。因此在写递归程序的时候，有一些编程上的技巧。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[非标准分析简介]]></title>
      <url>%2Fnon-standard-analysis%2F</url>
      <content type="text"><![CDATA[人们对非标准分析的通常说法是非标准分析建立在实数域\(\mathbb{R}\)的扩张之上。扩张之后的\(\mathbb{R}^*\)包含了无限小的非零数，以及无限大的数。无限小的非零数具有的特点是绝对值比任何正实数都小，无限大的数的特点是绝对值比任何正实数都大。 显然，非标准分析得提供许多有益的结论，并且不会导致与直观相悖的结果才能为人接受。事实上它正符合这一点。因此非标准分析很有发展的前途。 然而为此建立新的公理基础的方法却比较艰难。在微积分的创立时期，Newton,Leibniz都是在一阶与高阶无穷小的基础上发展起了微积分的理论。但是因为不严格而备受责难。现在看来，当时主要是没有严格的逻辑公理基础，因而对实数的理解不够深刻。那么这样的思想，也就是把无穷小与无穷大作为实数中正常的元素的思想，就不能继续发展下去。 个人的观点是，实无穷与潜无穷的争论很难解决。甚至准确地描述它们都显得很困难。所以两种哲学观点，都可能具有一些价值。但是我们还是得从理性的角度出发，哪一个上面建立的理论比较完善，就接受哪一个。如果都比较完善，那么就不舍弃另一个，让两种观点同时向前发展。现在，大概“标准分析”与“非标准分析”两者应该是同时发展的。 按照惯例应当介绍非标准分析的发展历史。不过这个新兴领域中的发展，哪些具有更重要的意义可能不太容易说清。结果，这里就不介绍相关背景了。 超实数的构造背景 超实数域\(\mathbb{R}^*\)是非标准分析的空间模型，有时候也称为实数的非标准模型。非标准分析正是在空间\(\mathbb{R}^*\)上展开，因此叙述非标准分析必然从超实数域的构造开始。 任何领域在初创的时期，往往比较极端。非标准分析的极端体现在创立者刚开始的时候尝试通过修正数理逻辑与集合论构造能够容纳非标准分析的模型。这样的工作或许在将来的某个时间，被发现了非标准分析更深刻思想的人继承。不过，一开始就修改逻辑，未免让这个理论变得不必要的复杂。在这时候，有一个相对成熟的模型来解释新的模型，也许是更明智的做法。 所以我们先把从ZFC公理系统添加新的东西而构成的内集合论公理放在一边。 当前，对它的理解仅限于： 知道新公理系统与ZFC公理系统是相容的， 内集合论加上了一个新的一元谓词“标准的”，以及三条新的公理， 新添加的三条公理，转换原理，理想化原理，标准化原理与原来ZFC中的公理一起，构成了所谓“非标准分析的饱和模型”中内集的基本性质， 要研究内集合论公理，可能需要更多的数理逻辑基础。 非标准分析提出之后，有若干个相应的模型。第一个是Robinson给出的，基于数理逻辑的紧致性定理的证明而保证存在的模型。第二个仍是Robinson提出的，但经过许多人的改进后形成的模型。这个模型需要较少的数理逻辑的知识，并且建立在标准分析的概念之上，相当于扩充\(\mathbb{R}\)形成的新域。它是目前大多数人习惯使用的模型。第三个，则是1977年美国数学家Nelson.E提出的内集合论公理所表述的非标准分析。当前，第三个主要由法国的非标准分析学派使用。 当前，我们仅使用第二个模型，因为这种模型数学较为简单。而且，它能使我们更关注于用非标准方法解决标准的数学问题，而不是一开始就陷入非标准模型本身逻辑性质的抽象之中。 当前，非标准分析的理论已经在微积分，拓扑学、实分析、广义函数、函数论、泛函分析、李群、弹性力学以及流体力学中得到了应用。或许这个领域真的如哥德尔为Robinson的《非标准分析》所写的序言中所写的那样，“以这种或者那种形式表示的非标准分析，将成为未来的分析学”。 超实数域的超幂构造 完整叙述这个构造，需要熟悉“滤子”，“自由超滤子”等概念。但目前甚至难于找到一本书介绍这些东西。因此我们也不一般地介绍它们是什么。仅仅从有限余滤子开始。 自然数集\(\mathbb{N}\)上的有限余滤子指的是由自然数集的补集为有限集的子集构成的集族\(\mathscr{F}\)。有限余滤子又称Frechet滤子。这样的滤子我们以前见过，比如说，若自从某项开始，数列\(\{a_n\}\)与数\(A\)的距离小于\(\varepsilon\)，那么显然使\(\vert a_n - A \vert &lt; \varepsilon\)的\(n\)构成的集合，就具有有限余集。若一实数列在某个具有有限余集的子列上收敛于某个数，显然实数列本身也收敛于这个数。 \(\mathscr{U}\)需要扩张才能进一步满足非标准分析的要求。扩张后的集族，为一个自由超滤子。扩张的过程是简单的，并且其存在性可由选择公理或Zorn引理证明。自由超滤子\(\mathscr{U}\)在\(\mathscr{F}\)的基础上，对于任一集合\(A \in \mathbb{N}\)，若\(A\neq \mathscr{F}\)并且\(A^c\neq\mathscr{F}\)，那么取\(A\)或\(A^c\)中的一个加入\(\mathscr{U}\)。直到不能扩张时，就构成了自由超滤子\(\mathscr{U}\)。 设\(\mathbb{R}^{\mathbb{N}}\)是所有实数列构成的集合，即 \[\mathbb{R}^{\mathbb{N}}=\{ \{a_n\} \,:\, \{a_n\}:\mathbb{N}\to\mathbb{R}\}。\] 定义两个实数列上关系\(R\)为\(\{a_n\}\,R\,\{b_n\}\)，当且仅当集族\(\mathscr{U}\)的某个集合上数列\(\{a_n\}\)与\(\{b_n\}\)相等。可以证明关系\(R\)是一个等价关系。由这个等价关系构成的等价数的集合，我们就用\(\mathbb{R}^*\)来表示。\(\mathbb{R}^*\)就是我们要的超实数模型，它里面的元素称为超实数。 在\(\mathbb{R}^*\)里，加法与乘法都按照实数列的加法与乘法进行。两个元素 \(\langle\{a_n\}\rangle\)与\(\langle\{b_n\}\rangle\)的序关系，按照 \[\langle\{a_n\}\rangle &lt; \langle\{b_n\}\rangle, \ \mathrm{iff} \ \exists\,S\subseteq\mathscr{U}\,\forall n \in S,\,a_n=b_n\] 来定义。 而原来的实数\(r\)，在\(\mathbb{R}^*\)中与常值数列\(\{r,r,\cdots,r,\cdots\}\)等价。因此使\(\mathbb{R}\)自然嵌入到\(\mathbb{R}^*\)当中。 这样我们可以将\(\mathbb{R}^*\)看成是\(\mathbb{R}\)的有序域扩张。 思考收敛于零的实数列\(\varepsilon\)，由序的定义，我们知道，对于每个正实数\(a\)都有\(a&lt;\varepsilon\)。而发散到无穷的序列可以看成无限大。可以证明在超实数域上有这样的表示定理： 每个有限的超实数\(x\)，可以唯一分解成 \[x=x^\circ+\varepsilon.\] 其中\(x^\circ\)是\(\mathbb{R}\)中的数，而\(\varepsilon\)是无限小。 对于任意\(x,y\in\mathbb{R}^*\)，我们可证明\(x-y\)是无限小，是\(x\)与\(y\)的等价关系。对于每个\(a\in\mathbb{R}\)，我们用\(M(a)\)记与\(a\)等价的元素的集合，称为\(a\)的单子。当\(x-y\)是无限小的时候，我们记\(x\thickapprox y\)。 现在，在超实数域中，无穷小与无穷大都已经引入了。但是我们知道，有许多的实序列头没有收敛的性质，因此它们的行为就比较复杂。这启示我们进一步限制哪些序列是我们将要在其上进一步讨论的对象。 设\(A\)是\(\mathbb{R}^*\)的一个子集。如果存在\(\mathbb{R}\)上的集列\(A_n\)，使得在自由超滤子\(\mathscr{U}\)的某个集合\(U\)上\(x=\{x_n\}\in A\subseteq\mathbb{R}^*\)，当且仅当\(x_n\in A_n\)，那么称\(A\)是\(\mathbb{R}^*\)的一个内子集。否则称\(A\)为\(\mathbb{R}^*\)的一个外子集。可以证明\(\mathbb{R}^*\)中的任意开区间，闭区间，半开半闭区间都是内子集。 超实数域的外集与实数集及其子集的性质差别较大，而内子集的性质则较为相近。以后我们的研究主要是超实数域的内子集。\(\mathbb{N}^*\)、\(\mathbb{Q}^*\), \(\mathbb{Z}^*\)，以及区间\([x,y]^*\)、\((x,y)^*\)都是\(\mathbb{R}^*\)的标准内子集。 当\(A\)是\(\mathbb{R}\)的有限子集时，\(A\)的扩充\(A^*\)与\(A\)有相同的势。但是当\(A\)不是\(\mathbb{R}\)的有限子集时，\(A\)的扩充\(A^*\)将比\(A\)中的元素多很多。 在此基础上，自然原延伸是建立超实数域\(\mathbb{R}^*\)类似于\(\mathbb{R}\)的加法公理，乘法公理，序公理，完备性公理等理论。所以就不再用多余的叙述。 超实数域总结 构造完\(\mathbb{R}^*\)及其上的内集，非标准分析的基础就算完成了。因此说来，学习非标准分析的难度也不算很高。 不过上面的构造过程应当引起我们更深的思考，比如为什么这样的扩充是容许的，尤其是，为什么实数集的子集，可以进一步扩充成内集。我们知道，实数的某些性质是不完美的，但是实数的构造确实很完美，域结构，序结构，拓扑结构以及微分结构它都有。这启示我们，是否在构造实数时是否遗忘了一些基本的公理。对比超实数的构造，也许我们会发现，如果在集论上添加一些新的东西，实数的理论就会变得更简单。非标准分析的逻辑理论，或者说，尝试在集合论的层次上建立内子集与外子集的想法，或许就是尝试发现这些被忽视的构造吧。 这样一来，好像我们必然要建立更完备的集合论一样，好像内集合论公理是集合论必然的选择一样。 前面我们表达的意思是，超实数域的理论是很容易模仿经典实数理论建立起来的，而现在我们想更详细地谈一些东西。 极限，在超实数域中有特别简单的解释。函数\(f\)是连续的，用直观的语言说，就是自变量\(x\)与常数\(a\)无限接近的时候，函数值\(f(x)\)与\(f(a)\)也无限接近。这一直观的语言在\(\varepsilon\)-\(\delta\)语言中并无直接对应。但是用超实数域的语言很容易说明。在\(\mathbb{R}^*\)中，函数\(f\)是连续的，意思是，当自变量\(x\thickapprox y\)的时候，\(f(x)\thickapprox f(a)\)。 我们知道，导数与积分都是定义在求极限的过程上的，于是两个概念不难定义。函数的可导，就是自变量无限接近的时候，差商有限具无限接近。差商的标准部分，就是函数\(f\)在\(a\)点在标准意义下的导数。函数的积分，就是分割、求和、取极限。自然地，不构成太大的困难。 非标准的微分可能需要做一些较多的工作，尤其可能是需要定义扩充后的线性函数。但应该也不会太困难吧。总而言之，非标准分析以一种优雅的方式实现了分析学的扩充。 非标准微积分的思想及其基本内容均由非标准分析的创始人Robinson于20世纪60年代提出。1966年出版的第一本非标准分析专著《非标准分析》中专门有一章叙述非标准微积分。1976年Keisler,H.J.还出版了可供大学生使用的非标准微积分教材《初等微积分》。该书在大学的试用获得了好评。此后出版的非标准分析中关于微积分，便只有少量论述了—因为这个领域已经表明它是足够成熟的。 实数域与超实数域的公理化定义 可以仿照实数的公理化定义那样定义超实数域的公理。而且后者的定义就建立在前者的基础上。超实数域的具体公理用四条即可概括： 实数公理 实数域\(\mathbb{R}\)是一个完备的有序域，与之前所有的实数公理化定义相同； 扩张公理 超实数域\(\mathbb{R}^*\)是\(\mathbb{R}\)的真有序域扩张。第一节叙述的方法是一种可行方案； 函数公理 对于每个\(n\)元实函\(f\)，存在\(n\)元超实函数\(f^*\)是\(f\)的自然 扩张，并且\(\mathbb{R}^*\)的域运算是\(\mathbb{R}\)的域运算的自然扩张； 可解公理 如果两组公式有相同的实数解，则它们有相同的超实数解。 这一公理使平方根等概念可以推广到超实数域上。 在四条公理之外，还常常添加一条称为饱和公理的命题，以便超实数域有唯一的基数。 说明：有了这几条公理，感觉可以立即开始非标准分析观点下的一元分析。这种感觉真奇怪：在几十分钟之前还觉得非标准分析是天书一样难的理论，但是几十分钟之后，便觉得它在分析学当中是自然而然的东西了。甚至几十分钟之前，还觉得内集合论公理是不可接受的，几十分钟之后便觉得它是十分必要的。可能是因为迅速接受了非标准分析，所以觉得非标准分析的逻辑理论并不是人为刻意构造的逻辑系统。 用公理除了可以证明超实数的存在，还可以证明超实数域\(\mathbb{R}^*\)的唯一性。这样超实数域的性质就非常良好了。 非标准分析展望 如果内集合论公理添加到集合论当中，那么集合中相关的扩张自然在所有的数学门类中应用，包括拓扑空间的理论。事实如此。相关扩张的确可以用在拓扑空间上，使一个一般的拓扑空间\(X\)扩张成\(X^*\)。也许测度空间等同样可以使用。 这样，非标准分析很容易在其它数学门类获得应用。也许它尤其能改变拓扑学叙述问题的方式。 比如说，超实向量可以写成\((a_1,\cdots,a_n)\)，\(a_i\in \mathbb{R}^*\)的形式。这说明非标准分析可以向线性空间中扩展。 非标准分析的思想应用在测度论中，对于集函数会是一个好的修正。因为集函数往往需要取值到\(+\infty\)。 非标准拓扑学是一个研究得比较多的领域。找到相关的书籍应该是不难的。另外，在分析学中常使用度量空间。在度量空间中改写成非标准分析的形式，要比在一般拓扑空间中容易许多。因为可以用度量趋于零刻画度量空间中无限接近的点列。 在广义函数领域。像\(\delta\)-函数这类函数，在应用数学中十分有用，但在标准分析中却不能把它表示为一个具体的函数。于是Schwarz.H.A等人建立了广义函数论，把每一个\(\delta\)-函数定义为满足一定条件的一个线性泛函，从而严格定义了这类函数。然而在非标准分析中，\(\delta\)-函数可以定义成一个通常的函数，从而避免了标准分析中甚至不能定义广义函数乘法的困难。这也许是广义函数研究的一条更好的路径。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[.NET平台上的一些程序语言]]></title>
      <url>%2Fdotnet-lang%2F</url>
      <content type="text"><![CDATA[asp.net使用说明 使用一个技术架构, 需要了解其原理, 并知道其实现的思路. 为了更清楚地知道这一点, 必需从.NET架构开始. 现在的互联网技术, 甚至是一般的连网平台的技术, 跨平台性都是一个重要的特性. 在跨平台的背景下我们讨论各种技术. .NET的开发虽然比较早, 但是后来被ECMA规范化了, 标准是ECMA335. 关于.NET技术, 我们以Mono的实现为例进行介绍. Visual Studio 开发环境是相同的原理可以理解的. mono计划从核心虚拟机引擎开始. 这个引擎用于编译C#等代码, 也就是高层的代码. 在一些平台, 比如x86, x86-64当中, 这个引擎具有实时性, 也就是现在可以编译成平台相关代码的形式. 在其它平台上, Mono用解释的方式运行.NET的相关代码. mono的目标就是创建符合.NET标准的工具. 而.NET架构的核心, 就是C#编译器, 以及通用语言架构(Common Language Instructure, CLI). 因此C#才成为.NET开发的首选的语言. Mono计划中, C#编译器由GPL规范, 运行库由LGPL规范, 类库则由MIT许可证规范. 因此mono是开源的一个计划. 微软也提供了一个共享编码公共语言基础库, 但并不是开源的, 虽然可以跨平台使用. 公共语言基础CLI是ECMA335标准, CLR,即公共语言运行环境, 则是CLI的标准实现, Mono即是其实现者之一. 它可以执行已经编译出来的.NET应用程序. linux下面的mono命令大概就是用于执行编译出来的.NET应用程序的. 虽然.NET应用程序往往使用.exe与.dll等格式, 但是与传统的.exe格式还是有所区别的. 在能够编译本地运行的C#代码, 大概是所有的.NET平台的基础. 了解了C#的编译的原理, 就不难知道其它的语言也可以利用C#语言的这一套基础设施, 比如C#运行时的库, 就可以为C#, IronPython, VB.Net, C++/CLI等.NET平台上的语言使用. .NET平台用命名空间组织各个类库, 使得所有的程序库有相同的调用方法. 命名空间, 比如System.Web, Microsoft.abc等. .NET framework是微软开发的一套.NET的框架, 主要的内容是大量的类库. 它是继Microsoft DNA之后微软的新开发平台. 实际上, .NET framework与mono, Sliverlight, 以及XNA都是差不多的道理. .NET framework提供了类库之后, ASP.NET, ADO.NET Windows Forms都是基于这个平台的创建出来的技术. 其中ASP.NET其实是在.NET framework中提供的支持开发Web应用程序的类库, 封装在System.Web.dll文件中, 以System.Web作为命名空间, 它具有负责网页处理的功能. 它是ASP技术的后继, 但是各方面的发展潜力比ASP要大很多. 原来的ASP的特点是其代码封装在HTML标签当中, 在ASP.NET中, 添加了面向对象的支持而变得集成在相应类的Render机制中, 形成一个包装. .NET技术在2.0之后变得成熟, 在3.5之后又添加了许许多多的功能. ASP.NET MVC是又开发出来的一个类库, 在System.Web.Mvc.dll当中, 它添加了ASP.NET Routing 以支持动作流与URL重写等功能. 开发网页应用程序 开发网页应用程序的时间, 服务器端的架设仍与原来的机制类似. xsp4是在unix下面支持.NET动态网页技术的一个服务器, 但是配置Apache与nginx以支持.NET格式的动态网页也并不是困难的事情, 因为只需要过滤出相应的文件, 让mod-mono-server2接收并处理就可以了. 后端的数据库当然是由.NET程序来连接. 实际上流行的关系数据库软件面向.NET都是有接口的, 我们可以很容易地在其中写出接口文件. 比如MySQL数据库的, 只需拷贝Mysql.Data.dll文件到系统库目录中即可. 实际上, 这只是编译C#应用程序的时候添加的一个编译选项而已. 使用gacutil工具, 可以将系统库安装到标准目录当中. 学习使用.NET开发应用的步骤 鉴于.NET的技术架构, 首先了解一个C#程序的编译过程即可. 虽然编译出来的文件以.exe作为结尾, 但是与传统的.exe格式我们可以认为是没有关联的. 然后我们学会使用C#面向对象的方法, 调用它的各种类库, 特别是面向数据库的接口. 编译好本地运行的程序之后, 我们再一步一步地走向网页应用程序. Csharp基本介绍 C#与java有更多的相近, 然而与com是直接集成的, 并且是Windows网络框架的主角. 现在的大部分的微软的技术, 以C#为基础了. C#与C/C++相比, 是对后者的继承, 并且去掉了宏, 以及多重继承的规则. C#综合了C++的效率与VB的简单可视化操作, 是.NET的首选的语言. C#可以调用C/C++编写的本机上的原生的函数. C#由Anders Hejlsberg主持编写, 于2000年6月发布. 新增了许多的功能与语法糖. Anders也是Dephi语言的开发者. C#很可能是一个全能型的语言, 从复杂的操作系统到嵌入式可能均适用. 类的声明与Java相似而不像C语言. 而且C#的结构体与类不支持继承. 但与Java相同的是一个结构体可以实现接口. 类可以定义成抽象的或者不可继承的. 被声明为abstract的类不能被实例化, 只能被用作一个基类. 而C#的关键字final就象Java的final一样, 具有此声明的类不能被用作另外一个类的基类. 与Java一样, 一个界面是一组方法集合的抽象定义, 当类或者结构体实现这个界面的时候, 它必须实现所有的方法, 而且单一的类可以实现几个接口. C#也使用true和false作为布尔常量. C#的内存管理由底层的.NET框架负责. 一个基本的C#类中包含数据成员, 属性, 构造器和方法, 属性可以是静态或者实例成员. C#是一个强类型的语言, 它的数值类型中有些可以进行隐式转换, 但是其它的必须是显式的转换. 程序被编译成标准的二进制可执行文件, 但是C#的源程序并不是二进制可执行的形式, 而是一种中间语言, 类似于字节码. 如果一个程序保存成一个以cs为后缀的文件, 那么编译器也能将它编译成可执行程序. 虽然扩展名是.exe, 但是没有.NET的时候仍然是不能被执行的. C#的编译结果不是标准的二进制形式, 而是由.NET的CLR执行的中间代码. C#中也有预编译指令, 有|#define|等, 但是没有了|#include|. C#中也有一些操作符重载, 而且数据类型有值类型和引用类型两种.引用类型特点是不自动创建新的分配单元.int, byte是特殊的值类型, 称为简单类型. 所有的值类型都继承自System.ValueType类型, 所有有关的引用和类型都继承自System.Object基类. 方法可以支持可变数目的参数. 注意, C#语言的效率仅是能够与Java相抗衡, 而不足以与C或者汇编相近. 各版本的特性 在2.0版本起, 支持Python那样的yield迭代器类型. 从3.0起, 则支持LINQ, 也就是语言集成查询, 可以在LINQ上下文中作为关键字. 从3.0起, 支持了匿名类型, 使用var关键字即可声明, 因此可以局部变量类型推断. 从3.0起, 还支持了lambda表达式. 从4.0起支持了动态对象, 使用dynamic关键字声明, 而且有具名参数与可选参数, 而且可以更方便地与.COM组件交互. mono几乎百分之百地实现了C#, 所以是一个不错的编译器, 使用 mcs hello.cs 可以直接编译出.exe文件, 使用 mono hello.exe 则可以直接从虚拟机里面运行它. LINQ 它是微软的一项技术, 目前可以支持VB.NET与C#. 新闻报道 根据2014年11月13日的新闻，微软表示将开源.NET，包括整个.NET的核心类别，ASP.NET5.0、.NET CLR、Just-In Time Complier、Garbage Collection以及Base Class Libraries等技术。这一开源让.NET正式推出，使得.NET平台在开源世界以后甚至会优于Java的平台。个人感觉这一新闻比较重要。而且ASP.NET 5.0最好能与Mono计划融合。 C\(\sharp\)编程语言 C\(\sharp\)是基于.net平台的，但是关键还在于它是ECMA规范。C\(\sharp\)之类的项目是由Anders Hejlsberg主持开发的。这之后，作为.Net概念的发起人之一，安德斯·海尔斯伯格被任命为微软.Net的首席架构师，主持.Net的开发工作。 C\(\sharp\)也是强类型的语言，而且声明变量采用|var|关键字，因此具有类型推断的能力。C\(\sharp\)也是多范式的，支持函数式编程语言。 C\(\sharp\)的类型系统称为Common Type System (CTS)。此类型系统中，所有的类型（包括整数等原语类型）都是System.Object的类的子类。这样一来，每一个类都有一个ToString()方法。 CTS把数据类型分成两个范畴。一个是引用类型，另一个是值类型。Instances of value types do not have referential identity nor referential comparison semantics - equality and inequality comparisons for value types compare the actual data values within the instances, unless the corresponding operators are overloaded. Value types are derived from System.ValueType, always have a default value, and can always be created and copied. Some other limitations on value types are that they cannot derive from each other (but can implement interfaces) and cannot have an explicit default (parameterless) constructor. Examples of value types are all primitive types, such as int (a signed 32-bit integer), float (a 32-bit IEEE floating-point number), char (a 16-bit Unicode code unit), and System.DateTime (identifies a specific point in time with nanosecond precision). Other examples are enum (enumerations) and struct (user defined structures). C\(\sharp\)的库使用ECMA的规范，The C# specification details a minimum set of types and class libraries that the compiler expects to have available. In practice, C# is most often used with some implementation of the Common Language Infrastructure (CLI), which is standardized as ECMA-335 Common Language Infrastructure (CLI).也就是在CLI的基础上执行的。 C#也是ISO/IEC 23270:2006规范。 上面是关于C#的类型系统的介绍：In Microsoft’s .NET Framework, the Common Type System (CTS) is a standard that specifies how type definitions and specific values of types are represented in computer memory. It is intended to allow programs written in different programming languages to easily share information. As used in programming languages, a type can be described as a definition of a set of values (for example, “all integers between 0 and 10”), and the allowable operations on those values (for example, addition and subtraction). The specification for the CTS is contained in Ecma standard 335, “Common Language Infrastructure (CLI) Partitions I to VI.” The CLI and the CTS were created by Microsoft, and the Microsoft .NET framework is an implementation of the standard. 也就是说，CTS类型系统是ECMA的规范。 Value types directly contain their data, and instances of value types are either allocated on the stack or allocated inline in a structure. Value types can be built-in (implemented by the runtime), user-defined, or enumerations. Reference types store a reference to the value’s memory address, and are allocated on the heap. Reference types can be self-describing types, pointer types, or interface types. The type of a reference type can be determined from values of self-describing types. Self-describing types are further split into arrays and class types. The class types are user-defined classes, boxed value types, and delegates. Boxing:Converting value types to reference types is also known as boxing. As can be seen in the example below, it is not necessary to tell the compiler an Int32 is boxed to an object, because it takes care of this itself. Unboxing:The following example intends to show how to unbox a reference type back to a value type. First an Int32 is boxed to an object, and then it is unboxed again. Note that unboxing requires explicit cast.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[密码学原理与开源工具(日期未定)]]></title>
      <url>%2Fencryption%2F</url>
      <content type="text"><![CDATA[加密及密码体制原理介绍 在进行相关的渗透的时候, 可能需要使用SSL. 即使不是从事渗透, 但是为了安全起见, 我们还是使用OpenSSL工具加强数据安全性. 无论如何, 这是密码学的一个应用, 它可以起到十分强大的作用. 事实上是所有的文件加密的重要的, 几乎是唯一现代化的方法. 密码学的一些常识我们必须了解. 现体密码体制中, 密码算法都是公开的, 保密指的是密钥的保密, 而不是算法的保密. 因为研制一个算法是非常麻烦的, 且作为学术上的东西, 它必须还要为人广泛地知道. 这也许体现了人类活动的一个基本准则, 那就是学术开放重要于人类活动. 也就是说, 原理是人类共有的, 应用的不同, 只是人们理解上的差异. 核心的知识是人类共知的, 而那些不为了所知的, 只是用于短期需求, 且没有长久的价值. 密码体制中, 大概有这样几种类型, 加密, 哈希与签名. 它们各自有一套原理. 其中加密又分为对称加密与不对称加密. 不管它们是如何实现的, 我们都可以用通用的公式来说明. 假设加密方有加密函数 \(E\) , 解密方有函数\(D\) , 原消息 \(M\) ,而所使用的密钥是 \(K\) , 那么加密解密过程分别是: 加密过程\[E(M,K) = C\] 解密过程\[D(C,K) = M\] 在加密解密函数相互配套的情况下, 双方均需知道 \(K\) 的值. 在发送的时候, 加密方只在不安全信道上传输密文 \(C\) , 解密方只需要使用 \(K\) 解出密文 \(C\) 为 \(M\) . 我们可以分析, 实行加密的过程是算法规定的, 因此任何人都可以. 但是一个攻击者将因为无法知道和解密方相同的 \(K\) 而不能伪造与解密方通信—如果它对 \(K\) 一无所知而又试图发送密码, 那么解密出来的, 往往是随机的文字, 以致于攻击者自己也不知道解密方将会看到什么消息, 因此这种攻击就失去意义. 对称加密的主要问题在于如何达成一致的密钥. 由于 \(K\) 需要保密, 因此得事先由发送方与接收方秘密约定, 或使用额外的安全信道. 尽管如何, 对称加密因为速度上的原因, 以及能够配合其它体制使用, 因此也颇有应用. 主要的对称算法有DES, AES, RC4等. 非对称加密一定意义下等同于公钥体制. 将体制下, 密钥分成公钥与私钥两个部分. 它们是成对出现的, 且公钥可以公开发布, 只是人们很难从公钥 \(K_1\) 推出私钥 \(K_2\) .加密与解密过程分别为: 加密过程\(E(M, K_1) = C\) 解密过程\(D(C, K_2) = M\) 符合这一原理的方法有RSA(基于因子分解), ElGamal(基于离散对数)等. 另外, 离散对数问题可以用于密码协商, 进一步保证前向安全. 基于它的著名协议是Diffie-Hellman密钥协商协议. 协商基本过程是, \(A\) , \(B\) 双方各自选择仅自己知道的数字(即使对方也不知道), 根据离散对数分别计算明文. 各自接收到对方的明文后, 再计算一次可以得到相同的数字. 该数字即为协商的结果. 该方法的特点是双方各自不知道对方的密码, 但是却可以维持一个仅能双方知道的加密信道. D-H协议的主要问题是协议中没有关于通信双方身份的验证, 因此可能被一个中间人物在协商时截取, 形成一个代理. HASH技术原本是为了方便和提高速度, 而对数据完整性校验, 但与密码体制结合起来, 也可以用于数字签名. 主要的HASH函数有MD5, SHA1等. 配合HASH进行数字签名的原理是, 双方本来就已经协商好了密码体制. 这个时候, 规定消息格式由消息体和HASH两个部分规范地组成. 根据具体情况, 如果消息可以明文传递, 那么就发送消息明文和加密后的消息HASH, 对方自动计算消息HASH, 并与解开发送方加密的HASH对比就可以了; 如果是密文加密, 亦是类似. 公钥算法的特点是太慢, 因此实际使用公钥的时候, 常用公钥算法传输会话密钥, 再用对称算法加密传递批量数据. 公钥的发布是公钥体制的核心. 一般设立权威中心(CA), 由CA以数字签名的方式签发公钥, 即证书. 证书中包含有公钥, 持有人信息, 用途说明, 有效期, 签发人的数字签名等. 有了对方的证书后, 可以让对方签名来看看, 如果对方发过来的消息中, 能够签出这个公钥验证的名, 则可确认对方应当有对应私钥; 否则对方就是假冒的. 注意, 持有证书的人虽然能够验证签名者的真伪, 但是却不能通过消息推导出签名者的私钥—否则证书体制将会面临重大缺陷. OpenSSL简介与基本使用 OpenSSL是使用非常广泛的SSL开源实现. 由于其中实现了为SSL所用的各种加密算法,因此OpenSSL也广泛被视为开源的加密函数库—更保况它的确提供了接口函数. OpenSSL学习的基础环境是openssl命令行. 输入 openssl 命令, 即可进入. 在其中可以执行OpenSSL所提供的各种功能. 比如, 生成随机数, 产生密钥对. 其中较为简单的HASH验证, 产生随从数就不说了. 只是最重要的密钥与加密. 要使用OpenSSL, 我们要知道它有哪几个方面的基本用途. 第一个是非对称加密, 第二个是对称加密, 第三个则是信息摘要算法. 其实信息摘要算法是很简单的, 也就是我们所说的MD5等HASH算法. 对称加密算法 对称加密算法的基本流程是, 在一定的对称加密算法的支持下, 输入密码, 指定输入文件, 然后得到一个输出文件. 将输出发送到另外一台机器上, 在另外一台机器上应用相同配置即可解密出文件. OpenSSL提供的主要的工具是 enc 命令. enc -e用于加密, enc -d用于解密. 执行命令 openssl enc -des -e -a &lt; source.txt &gt; source.txt.des 进入对话框, 输入密码之后就可以生成加密后的文件了, 再使用 openssl enc -des -d -a &lt; source.txt.des &gt; source.txt 就可以恢复想要的 source.txt 文件. 对称加密之间的不同, 主要在于所选用的对称加密算法, 比如 -des . 使用对称加密的时候, 其实也应当注意, 一个长度较少的密码, 是容易被攻破的, 因此不妨选用更长位数的密码. 这样, OpenSSL可以使用 -k , -kfile 选项从命令行选项, 或者从文件中得到密码. 不用在线输入. 非对称加密算法 非对称加密算法的应用范围更广. 而且也有助于产生更长的密码. 非对称加密的原理已经介绍过了. 因此在本地产生钥匙对是最基础的. 对应OpenSSL命令为: openssl genrsa 1024 &gt; hawk.key 产生ASCII编码的RSA钥匙对. 可以用 openssl rsa -noout -text &lt; hawk.pem 查看包含在 hawk.pem 当中的公钥与私钥的值. 为了更安全起见, genrsa 还支持将生成的钥匙对使用对称加密算法加密, 比如加上 -des 选项后, 以后要再想用这个钥匙对, 必须输入一个密码才行. 不管怎么说, 第一步产生钥匙对的工作总算是完成了. 此时用 openssl rsa -pubout &lt;hawk.key &gt;hawk_pub.pem 可以仅导出RSA中的公钥的那个部分, 直接引用 hawk_pub.pem 以发布公钥. 对于DSA, 需要在生成密码的时候提供一个参数. 因此过程是 openssl dsaparam 1024 &gt; dsaparam.pem openssl gendsa -des3 &lt;deaparam.pem &gt;private.pem ## 生成密钥 openssl dsa -pubout &lt;private.pem &gt;public.pem ## 导出公钥 这要比RSA方式复杂一步. 产生了钥匙对, 便可以分别使用私钥与公钥对文件签名与验证了. 比如 ## signature openssl dgst -sha1 -sign private.pem &lt;file.txt &gt;file.txt.sgn ## verify openssl dgst -sha1 -sign public.pem &lt;file.txt.sgn &gt;file.txt 不过我们不一定是对整个文件加密, 而是更有可能是对文件的摘要加密. 注意, 这是对文件签名与验证. 前提是接收方有正确的公钥. 如果一开始得到的是窃取者的公钥, 那么窃取者就能伪造发送方与接收方通信. 信息摘要算法 信息摘要算法对于验证文件有时是非常有效的. 对于较弱的验证, 比如看从网上下载的一个文件与服务器一样与否, 可以用|openssl sha1 file.txt|得到SHA1值, 然后与服务品的上对比. 信息摘要算法的另一个应用是保存用户的密码, 前提是保存用户密码的地方, 其它人不能任意修改相应的摘要. 在用摘要算法保存密码的时候, 还可以加上一些噪声, 防止被用常用词摘要表的方法攻破. 密码管理是 passwd 命令, 它可以以UNIX标准的方式加上一个密码, 以及加上一些噪声. 在服务器存储密码的时候特别有用, 比如 openssl passwd -1 -salt 分别以password为输入文件, 和以使用摘要算法后的密码为输出文件. OpenSSL还有其它的许多功能. 有用到的时候可以参考其手册. GnuPG工具 GnuPG也算是密码学工具. 相对于SSL, 大概长处在于封装了一整套的方案. 面对主流的应用, gnugp直接提供了相应的命令, 相对于密码学工具, 更侧重应用. GnuPG可以完成几乎全部现行密码体制. 对称加密解密, 非对称加密解密, 数字签名与认证等. 由于已经有了OpenSSL的背景, 我们讲GnuPG的应用. GnuPG基本上可以看成是管理本地的公钥私钥的工具. 不仅可以管理自己创建的钥匙对, 还可以管理从网上下载的公钥私钥. 甚至可以发展成一个集团认证的工具, 因为对于一个签名的文档, 使用者还可以自己再加上一个签名, 从而让用户知道已经有很多人对这一个公钥认证过, 因此大大增强了信心. GnuPG的基础命令有|gpg –gen-key|与|gpg -k/-K|, 分别用于生成钥匙与查看本机的所有的钥匙. GnuPG管理它们的时候, 对钥匙文件使用 Key_ID 标识. 也就是说, 使用哪个文件, 通过 Key_ID 来指定. 导出公钥 示例命令: gpg --export --armor Key_ID &gt; Key_ID_pub.pem gpg --export Key_ID &gt; Key_ID.gpg 分别表示导出ASCII格式与二进制格式的公钥. 同时, 导入另人的公钥, 使用 gpg --import Key_ID_pub.pem 公钥总是要发布出来才有意义, GnuPG提供的命令可以直接将公钥发布到网上, 以及从网上的服务器上下载公钥. 这里有一个可用的公钥服务器 keys.gnupg.net . gpg --keyserver keys.gnupg.net --send Key_ID 从服务器上下载相应的公钥, 则可以调用 gpg --keyserver keys.gnupg.net --recv-keys Key_ID 其实使用默认服务品的话, 可以不用指定 keyserver 的, 默认服务器可以在.gunpg/gpg.conf文件中配置. 钥匙管理 按照GnuPG的基本的意思, 应该是把公钥导出, 在本地有一个私钥就行了. 但是有时候, 因为重装系统等原因, 可能需要导出以迁移私钥. 方法是: gpg --export-secret-keys --armor Key_ID &gt; Key_ID.pem 直于在另一台机器上导入私钥, 则是同样的道理. 从上面的流程, 我们可以看出, 一个完整的 Key_ID 文件中, 不仅有公钥与私钥, 还有用户相关的信息, 以及加密私钥的密码, 只有提供了密码, 才能从 Key_ID 中提取重要数据. 因此一个 Key_ID 可以用于多种用途, 非对称加密, 签名均可. 吊销证书 该功能可以看成是 Key_ID 机制的扩展. 当一个符合要求的证书因为某种原因, 状态发生变化的时候, 可以根据吊销证书被取消. 当然, 创建吊销证书的, 必须是发布机构, 也就是知道私钥与密码的那个人. 产生相应 Key_ID 的吊销证书后, 在相应的时机, 导入此证书, 便可以使相应 Key_ID 的证书失效. gpg --gen-revoke Key_ID &gt; Key_ID.rvk.pem 导入吊销证书的方法, 与导入一个公钥使用相同的命令. 对称加密 默认GnuPG使用的是非对称加密的方法. 所以要想使用对称加密, 虽然原则上与OpenSSL相同, 但是参数形式要稍微长一些, 或者难记一些. ## 对称加密并生成filename.asc文档. 不带armor, 生成gpg二进制格式. gpg --armor -c filename ## -c 等同于命令 --symmetric ## 对称解密时输入相应的密码即可 gpg --armor -d filename.asc ## -d 等同于 --decrypt 选项 非对称加密 既然在 .pem 文件中, 所有的要素都准备了, 那么非对称加密也就不困难了. 使用 gpg --armor -r Key_ID -e filename 解密的时候, 与对称加密的时候相同. 只不过解密的时候, 需要存有私钥的Key_ID文件. 数字签名 对文件进行数字签名也是很简单的, 示例如下: ## 对文件签名, 并且将文件签到输入文件中 gpg --sign filename -o filename.gpg ## 生成文件与HASH分开的签名 gpg --detach-sig filename -o filename.sig 也可以通过类似 --armor 的选项, 导出ASCII格式的签名的文件, 这样更易于在互联网上传播( --clearsign 选项). 至于验证签名, 则可以使用 --verify 选项. GnuPG还有其它很多用法, 比如在一个公钥上签上自己的名. 这里就不多讲了.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从磁盘启动的过程与SYSLINUX]]></title>
      <url>%2Fbootstrap-syslinux%2F</url>
      <content type="text"><![CDATA[磁盘启动原理 PC在启动的时候是从执行ROM当中的代码开始的。这些代码常根据机器的不同而分布在不同的位置。PC上这种初始化代码称为BIOS(基本输入输出系统)。在PC里有几种不同的BIOS固件。如主板BIOS,显示卡BIOS,以及网卡BIOS. BIOS通常让用户选择从哪一个设备引导。一旦确定引导设备，BIOS就加载在该设备开头的512字节的信息。这个512字节的段称为MBR.MBR中包含一个程序，它可以执行中决定从哪个位置（哪个分区）加载boot loader(也就是引导程序)。 实际上在一个磁盘设备上从0x0000到0x01bd这446字节为MBR代码，从0x01be到0x1fd这64字节包含有4组分区表信息DPT.在0x01be处的值为引导标志，值为80代表活动分区。而MBR中的0x01fe到0x01ff为结束标志，内容总是0x55aa. 每一个引导程序要求使用的MBR是不相同的，但其中分区位置对于每一个MBR都是相同的，一般来说，在为一个设备安装上引导程序的时候，仅覆盖前446字节中的一部分。 MBR成功执行后一般会进入到第2到第63扇区执行额外的启动代码，进一步创建引导程序环境。对于GRUB来说，boot.img里的内容被复制到MBR中，负责把第二扇区加载到内存中的0x8000位置并执行（称为diskboot.img）。而第二diskboot.img的功能则是加载GRUB的启动映象kernel.img.（kernel.img从第二扇区开始，到第63扇区结束）。 最终当然还是要进入具体的某个分区。因此在启动器中分区实际上是从某个扇区之后开始的。根据MBR中的信息可以确定每个分区的开始位置，因此理论上当然能够通过前63扇区把分区开始处的代码加载到内存并执行。 在某分区上的引导程序具有读取分区文件系统的能力，因而可以像一个操作系统那样使用特定的配置文件或者加载特定的配置。一般来说，引导程序的相关模块都位于该分区的boot目录下。实际上我们是通过引导程序定位我们需要启动的内核，以及启动时向内核传递的参数。 SYSLINUX创建可引导设备 首先应下载并解压SYSLINUX软件。之后的步骤先以linux为例。 进入到SYSLINUX的软件目录，然后执行 $SYSLINUX$/linux/syslinux -i /dev/sdXn 这表示把syslinux安装到一个设备的特定分区当中。当然我们可以查SYSLINUX手册以向syslinux程序传递在该分区的安装目录。 之后我们需要将SYSLINUX的MBR映象写到设备的MBR当中，并将SYLINUX所安装的分区设置为活动分区： dd conv=notrunc bs=440 count=1 if=mbr.bin of=/dev/sdX parted /dev/sdX set 1 boot on 最后就是把内核映象复制到sdXn分区的适当位置，通过syslinux.cfg文件将内核映象的启动信息告知SYSLINUX引导程序。就等着在启动时SYSLINUX搜索syslinux.cfg文件了。 在WINDOWS下所做的工作与linux下实际没有什么不同。只不过在WINDOWS下面分区是通过盘符指定的。 $SYSLINUX$/win32/syslinux.exe --mbr -a X: 然后直接复制内核映象，创建内核启动配置参数。 如果使用EXTLINUX,则命令更为简单一些。先把它安装到特定目录下，EXTLINUX会在分区的引导扇区写上引导信息，然后在该设备的MBR上写入SYSLINUX的MBR引导程序。 SYSLINUX系列引导程序 SYSLINUX系列的引导程序有SYSLINUX, ISOLINUX, PXELINUX与EXTLINUX. 其中的SYSLINUX只能安装在FAT或者FAT32分区下，ISOLINUX只能安装在ISO 9660/EI分区下，EXTLINUX只能安装在ext2/ext3/ext4/btrfs分区下，PXELINUX则是用于从网络位置启动内核。 相比于从本地磁盘启动，PXELINUX要麻烦一些，不仅需要TFTP,还需要DHCP等服务。更何况还需要特定的硬件支持。 刚才介绍了使用syslinux创建可启动分区的方法，extlinux与此类似。一般来说我们如果设置一个空白磁盘为可启动设备，首先要使用分区工具，然后使用格式化工具产生一个适合引导程序扩展功能的分区文件系统。为了更好地了解引导程序。我们借助于linux强大的设备虚拟能力介绍引导程序的安装与使用。 创建磁盘映象 首先创建一定大小的空白文件： dd if=/dev/zero of=hdd.img bs=1M count=100 然后将这个空白文件虚拟成一个设备 insmod loop.o losetup /dev/loop0 hdd.img 在使用losetup命令的时候，好像连root权限都不需要。 挂载这个设备后使用fdisk工具分区。进入fdisk的专家模式，使用p查看分区开始的位置（在start列下面）。计算出偏移值为Start*512bytes.实际上应当乘以sector size这一个参数，在主界面下使用p命令可以看出其大小。通常为512字节。 然后缷载该设备，重新从偏移位置挂载设备，这次挂载的就是刚才对应的分区了。 如何创建一个可引导光盘映象 使用ISOLINUX工具。除此之外还需要mkisofs工具。 首先创建一个 CD_root 目录，把所需文件都拷贝进去。然后创建isolinux子目录。将SYSLINUX软件包里的isolinux.bin以及相应的模块，配置文件都拷贝进去。 之后在 CD_root 下面创建所需的内核与软盘映象，之后使用以下命令创建光盘： mkisofs -o bootable.iso -b isolinux/isolinux.bin -c isolinux/boot.cat \ -no-emul-boot -boot-load-size 4 -boot-info-table CD_root 其中的boot.cat是用于光盘文件系统的目录文件。 SYSLINUX配置文件的查找 启动时ISOLINUX会尝试从三个目录中查找isolinux.cfg:/boot/isolinux,/isolinux/以及./。在syslinux中有根目录和家目录的概念。根目录是所在的分区，而家目录是启动文件所在的目录。 从4.02开始，ISOLINUX的也可以以syslinux.cfg作为配置文件名。如果在当前查找目录中没有isolinux.cfg,先在当前目录查找syslinux.cfg,失败再查找下一搜索目录。 SYSLINUX与EXTLINUX的查找配置文件也是按照以上的顺序。EXTLINUX与ISOLINUX类似，在查找extlinux.conf失败后查找syslinux.cfg,然后在下一目录中查找。 SYSLINUX配置文件的格式与含义 全局选项当中： DEFAULT [module]: 所使用的菜单系统 PROMPT [01]: 关闭选项时，仅在shift,alt,caps,scroll按下时进入SYSLINUX命令行 UI [module] [options]: 用于设置菜单模块和菜单模块参数，会覆盖PROMPT NOESCAPE [01]: 生效时，忽略shift,alt,caps的动作 NOCOMPLETE [01]:生效时，忽略TAB动作 IMPLICIT [01]: 失效时，仅加载在label中出现的内核映象 ALLOPTIONS [01]:生效时，允许用户修改内核参数 TIMEOUT [int]: 用户没有动作的时候，菜单显示的时间（单位是1/10秒） TOTALTIMEOUT [int]: 所有选择所花费时间加起来不超过的某个数值。 CONSOLE [01]: 是否向终端输出信息 FONT [name]: 加载一个.psf字体文件，如果其中有unicode字符字体将被忽略。影响除版权所有这一行文字外的所有文字（因为后者是ldlinux.sys产生的）。 KBDMAP [keymap]:加载一个简单的键盘布局 SAY [message]: 在加载指定内核时在屏幕上显示的提示信息 DISPLAY [filename]: 在启动的时候显示指定文件里的内容 F[1-12] [filename]: 指定按次序要显示的文件，当功能键被按下时才显示 创建一个标签： label &lt;command name&gt; menu label &lt;label name displayed&gt; [&lt;menu default&gt;] kernel ... append ... ... 标签选项当中： ONERROR [cmd]: 当内核启动失败时执行的命令，实际上还是传给APPEND. KERNEL [executabe]: 使用该菜单项后所执行的SYSLINUX模块，内核映象，以及其它的自举程序。 LINUX [image]: 效果等同于KERNEL选择，不过专门用于启动linux映象。 APPEND [options]: 该选项指定了向KERNEL中所示程序传递的参数。 INITRD [files]: 该选项指定linux内核启动时所需的initrd文件，等同于在APPEND中添加initrd=[files]选项。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[人工智能语言介绍]]></title>
      <url>%2F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%AF%AD%E8%A8%80%2F</url>
      <content type="text"><![CDATA[本章单独作为一章，而且并不是用作附录。因为人工智能与程序语言是一体的。每一种语言实际上都可以看成是智能的一部分。而我们的目的是设计出更智能的语言或者程序。为此当然需要了解可计算性理论以及计算复杂性理论。 发现一个优点，就是如果在学习人工智能的时候学习几门语言，要比自己在没有任何指导的情况下看语言入门的书要容易得多。如果直接学习Prolog,我想我会找不到里面的重点。但是在知识表示中顺便介绍了Prolog,我就觉得用它来写程序很自然。 本书第十三章先是一般地介绍了语言的分类，然后介绍了LISP, Scheme, Prolog, POP-11, 以及略微谈及了脚本语言。也许结合七周七语言，让自己对于语言的理解的高度再上一层吧。至少我觉得本章第一节讲语言分类的时候，像是在高屋建翎。由于人工智能本身就说自己写的程序很可能只能在特定情况下被使用，所以人工智能的算法库也不多。这反映了人工智能问题的复杂性，需要使用不同的语言来解决。于是在人工智能领域，我们也更倾向于使用设计得更好的语言，如是不能描述我们的问题，与其使用不合适的语言编程，还不如写一种合乎于我们要求的语言。 这里所介绍的AI语言，现在看来其实是一些通用的AI语言，也就是使用普遍的编程语言来心量实现AI一样的任务。这种方法对于理解一般编程语言是怎样实现智能的也有一定的好处。但是个人并不认为因此这些语言就是智能的了。所以我们在这里我可以看成是以AI应用为背景的对于编程语言的一个综合介绍吧。 Prolog程序设计 前面我们已经讲过了Prolog在知识表示与推理中的基本运用。现在我们考虑的是作为一门编程语言的Prolog. 一个事实是，Prolog解释程序很容易用Prolog语言本身实现(有点像GCC编译器自己编译出来自己，而LISP语言可以轻易地写出LISP编译器一样)。Prolog语言很适合于开发基于知识的系统，以及计算机代数系统。它的问题求解的能力依然是解决知识领域问题的一种重要语言。 越来越发现，编程的时候我们只有一个工具而不去借鉴别人的东西。这是不符合学习的一般规律的。应该减少盲目的摸索，把编程看成是知识传承与改进的领域。这样才会把自己的能力提得很高，而且掌握那些不会过时的部分。Prolog语言用于CAS的实例现在我们根本没有看到，而我现在对此有兴趣，那么该怎么办呢? 当然应先参考别人怎样尝试解决问题的，利用了语言的哪些机制，而不是觉得自己现在就可以做出来成果。 前面我们讲Prolog用于知识表示的时候，并没有讲到它的数据表示。实际上，以大写字母开头的单词代表变元外，还有数值类型与原子类型(相当于常量)，一个以单引号括起来的字符串也代表一个原子。而需要注意的是，现在Prolog的数值是整数类型。 除了基本元素还有列表与元组，可以嵌套，而且列表上有合一规则。 除了这些结构外，Prolog也提供了一组常用的外理数据的谓词。比如append()，length()，member()，列表操纵等。在Prolog语言中， length([a,b,c], Length) 用于把Length的值赋成列表\([a,b,c]\)的长度，而 length([a,b,c],3) 用于判断列表的长度是否为3.也就是说，在Prolog中，函数值的接收与对值的判断是同样的一个形式。 事实与规则在Prolog知识库中出现。而在推理的过程中实现求值。这些功能在前面我们已经用过了。 最后，在推理的过程中，可以使用trace.跟踪计算的过程。 在Prolog中，把一个表达式赋给一个变量，可以使用 X is 3+3 **2. 这样的形式。注意使用的是is运算符。 Prolog中，可以使用小数，这个时候，小数视为常项。 人工智能语言概述 首先，人工智能算法可以由众多语言实现，但是有些语言更适合于特定的问题。对于神经网络或者遗传算法之类的数字人工智能问题，用C这样的语言是很高效的。对于依赖逻辑谓词的关系问题，Prolog较为理想。从历史上看，LISP是人工智能的基本语言。 程序设计语言的本质都是使程序员利用一台计算机解决问题，但是如何解决问题则可以千变万化。每种编程语言提供相同的功能，但是以不同的方式实现。(我们一般只考虑图灵完备的语言。) 主要的语言类型，或者说它们的特性，有函数式，命令式，面向对象，逻辑，并发这五个衡量的方面。之所以是这五个方面，因为它们大致决定了一门编程语言的基本面貌。用这几个标准可以更直观有效地对语言进行分类。在基本分类的基础上，我们再考虑求值方式，类型系统，性能与效率等因素。 人工智能早期，系统开发的重点是LISP这样的符号语言，以及Prolog这样的逻辑语言。但是实际上许多语言都能用于人工智能的开发。但是有几种范式对于语言的选择比较有影响。 那些LISP过时论的持见者，如果不能看到它现在的应用规模，它用于解决怎样的问题，那么它就没有资格起到决定作用。如果它没有掌握到语言发展的规律，我们就说那个人的话没有话语权。 函数式程序设计 第一种范式是函数式程序设计。这类语言深植于\(\lambda\)-演算的理论框架，具有诸如高阶函数，一等函数，递归，副作用少，连续，以及闭包等诸多特征。 与命令式语言相比，函数式程序设计依赖的是数据上函数的实施，而不是依赖于改变存储器和状态的命令的顺序执行。 高阶函数是函数式程序设计的基本特性，它意味着可以将一个函数作为输入，也可以返回一个函数作为输出。这个概念在数学上较为常见，比如求导函数。比如在Python中，可以使用map把一个函数作为参数作用于列表中的每个元素，甚至C语言也支持传递函数的入口指针。 但是C与Python其中的区别是，在函数式程序设计中，函数是作为一等对象或者一等函数。在一等函数里，我们可以把函数简单地当成数据。一等函数是有值的，就像其它任何数据结构一样。一等函数的一个重要表现是动态函数，也就是在运行期建立。C语言并不支持动态函数。 现代语言都力求支持多编程范式，因此对它们的分类也就越来越困难了。 下面是Ruby中一等函数的例子: def mul_by(factor) return Proc.new(|n| n*factor) end mul_by_2 = mul_by(2) mul_by_2.call(8) 其中mul_by()函数接受factor参数，返回相应的乘积函数，然后用mul_by_2作为一个函数对象，使用它的call方法计算函数值。 函数式语言中，通常支持函数调用自身。它是函数式语言中典型的实现循环的方法。比如在LISP中的使用递归计算阶乘: (defun fact (n) (if (= n 1) 1 (* n factor(n-1)))) LISP的特殊性不只是它采用函数式设计，而也是因为它的运算表达式都是前缀形式的表达式。以前以为理解LISP代码与写LISP代码都很难，但是现在觉得括号也没有引起想象中的太大的混淆。 闭包是函数式程序设计中与一等函数相关的一个很有用的特性。被传递到不同的词汇上下文使用的动态函数(有时是匿名的)被称为闭包。在计算机科学中，闭包（Closure）是词法闭包（Lexical Closure）的简称，是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。 闭包的特殊性在于它引入了已有函数中的变量，当我们返回一个内部的函数的时候，虽然外函数结束，但是我们不能释放掉此函数里面的参数(因为它被闭包函数使用)，所以需要编程语言进行额外的处理才能支持闭包。 命式式程序设计 命令式程序设计把计算过程看成是改变程序状态的语句的顺序执行。最早的命令式语言是1954年开发的FORTRAN语言。FORTRAN语言位于一棵庞大的语言树的根部，BASIC,Pascal,Modula,C,Ada以及Python与Ruby这样的语言都可以看成是从它而来的。 汇编语言与机器语言也可以看成是命令式语言。而机器语言指令不仅改变存储器的状态，也改变机器的状态。 命令式语言通过循环提供迭代的能力。有时候它们也提供递归，但是它们的递归显然没有函数式语言高效。 面向对象程序设计 面向对象的语言的基本特征是类，对象，继承，封装与多态。类是定义了行为和属性的抽象实体，对象是类的实例化。继承是一个类继承其它类的特征的能力。这样，我们就能够创建定义默认行为的基类，然后建立修正这些行为的子类。封装指的是类可以陷藏它内部操作的细节。多态指的是基类的行为方法被父类的行为方法取代。 逻辑程序设计 逻辑程序设计于1958年由John McCarthy首次提出(!)。它基于规则的模式导向进行，以达到某个目标。虽然逻辑程序设计基于数理逻辑，但是它在数理逻辑能力上有很多的限制，特别地，逻辑程序设计可以实现熟知的Horn子句。Prolog,G&quot;odel,Oz,Mercury都是支持逻辑程序设计的语言。 人工智能语言选择参考 在人工智能整个领域，单种语言通常不能提供必须的特性。在专家系统中，POP-11,Prolog与LISP这样的语言较常见，动态应用程序上LISP,Scheme,Dylan较常见，而计算机视觉几乎总是C/CXX.自然语言系统可以选用Prolog或者Oz,而演化系统常用C与DSL. LISP语言 LISP是与FORTRAN,COBOL一样古老的早期语言之一。同时它也是最独特的语言之一。其数据与LISP程序都是以表的形式表示。程序与数据以相同的方式表示。 John McCarthy(现供职于Stanford)于1958年在MIT提出了LISP语言的基本思想。1960年公开发表了设计LISP语言的文章，不久之后语言被实现。McCarthy的符号系统使用一种方括号内的M表达式，但是这种符号系统在早期实现时即被S表达式取代。虽然LISP本身被认为是一种过时的语言，但是它仍然拥有许多重要的思想理念，因而值得学习研究。 在LISP中，一切事物都是表。表可以是空表，包含空表的表，包含单个原子的表，包含多个原子的表，包含表的表，以及作为结构的表(混合表)。 LISP表达式采取表的方式表示，是采用前缀表示法。每一个LISP表达式都会返回一个值，而且事实上，一个LISP函数可以返回任意个值。 LISP中还有提供判断的谓词，比如atom用于返回它的参数是否是一个原子，返回true或者false. LISP的赋值也有多种方法，常见的是采用setq方法。用于将一个值赋给一个符号，或者将一系列的值赋值给一系列的符号。比如: (setq score-1 95 score-2 100) (setq thedate &#39;(&quot;April&quot; 13 1968)) 其中在表开头前使用单引号，表示不要对此表进行求值后再赋值。LISP语言的另一种赋值方法是let. LISP的表处理是其核心的机制。前面已经说过用setq建立一个表(是建立一个表的同时对变量赋值)。 函数cons用于通过两个参数构千定个表，也就是把第一个参数作为第二个参数(表)的第一个元素。比如(cons 1 ())返回(1)，而(cons 1 cons(2 ()))返回(1,2)。 对构造表的一种更简便的方法是list.它表里面所有的参数合并成一个表。如(list 1 2 3)将返回(1,2,3)，而(list 1 '(2,3))将返回(1 (2 3))。 需要注意的一个原则是，如果没有加上单引号，那么LISP就会对表进行求值，也就是把表视为一个函数。所以(2 3)在LISP中被求值，函数名为2,而3作为参数，甚至(&quot;Apple&quot; 18)这样的形式，如果不加单引号的话，也会把&quot;Apple&quot;当成一个函数来求值。 LISP提供了一些基本的表处理函数，如car用于得到表的第一个元素，cdr用于得到表的除了第一个元素外的表。使用append可以把两个表连接起来。 注意LISP可以对任何表求值，只要在解析的时候没有加上单引号。 将一个程序作为数据的方法是setq,比如(setq expr ‘(\* 5 5))，表示把expr赋成表'(\* 5 5)(未求值)。然后调用(eval expr)来计算expr的值(25)。 使用print方法输出(此时函数返回被输出的值)，使用if作为条件判断。cond则相当于其它语言里面的case语句。 (setq name &quot;Elise.&quot;) (setq greet (cond ((equal name &quot;Marc&quot;) &quot;Hi,Marc.&quot;) ((equal name &quot;Megan&quot;) &quot;Hi,Megan.&quot;) ((equal name &quot;Elise&quot;) &quot;Hi,Elise.&quot;) ((equal name &quot;Jill&quot;) &quot;Hi,Jill.&quot;) (t &quot;Hi you.&quot;))) (print greet) 这里，当name等于各个不同值的时候，把greet设置成不同的值。然后使用greet显示出来。最后的t代表true 的意思，相当于case的默认部分。 LISP每个求值都有返回，返回的都是一个表。 在LISP中，使用defun宏建立函数。格式是: (defun func-name (parameter*) &quot;Optional string to describe function&quot; (body-form)) 在LISP中，各个不同的词法成分完全通过空白字符以及括号分隔，名称都是可以任意取的。 这里只略微讲它的基本特性。作为编程语言的一面，可以参考LISP的有关书籍。 一个编译器很简单的语言一般都是好的语言，可以供程序员自由地开发。 Scheme语言 Scheme是20世纪70年代在MIT创建的，是LISP语言的一种新的变体并支持诸如命令式与面向对象等多种程序设计范式而设计的，不仅仅是一种函数式语言。 Scheme是Gerald Jay Sussman和Guy Steele, Jr.的一系列论文的综合成果。这些论文着重研究程序语言的设计思想，特别是一种既高效又不受任意规则约束的简单语言的设计。这些论文演化出的语方包括这门语言的体系结构，若干操作原语和以库的形式实现的其它成分。 看来我也对设计语言很着迷。但是不应该纯粹只是一种兴趣，还要使这种语言具有优良的性能。需要了解程序设计语言的本质，才能设计出来不致使自己都厌烦的语言。 程序的本质是什么? 上面说的，体系结构，操作原语与函数库，我觉得是一个语言的核心。我曾意识到，许多语言到最后都变成像汇编那样的长串的操作，比如像TeX那样只由一些内置宏组成，像m4那样的内置宏。但是就是不知道叫什么名子。现在知道，一个程序的功能，或者说代码的语义，所代表的操作，很大程度上决定于原语。 Scheme语言确实很简单，因为全部语言描述大约50页，另有100页的关于库的讨论。同样地，Scheme也有多种实现。 Scheme与LISP一样，都是易于学习，难于掌握的。但是像这样的语言，如果我们最点接触，那么慢慢地有了经验，就会比后来再集中学习好得多。 Scheme作为LISP的一种方方，数据与程序的表示都是相同的。在数据表示上，除了支持原有的表类型外，还支持整数，实数，字符串，符号以及其它一些类型，相当于说扩展了能够识别的类型。Scheme的数学表达式与LISP是相同的。Scheme会将数学符号识别成表示数学运算符的原语，并且使用所谓的前缀表示法。 极端地，在m4语言当中，任何记号都被当成字符处理，这种类型系统就很单调。而Scheme内置了针对实数加法的运算符，我们就称它的类型系统中有实数。也就是说，一门语言的类型系统指的是它内置了那些不同的操作，这些操作又作用在哪些词法单位上。 在Scheme中的谓词有null表示判断表是地为空表，如果用于判断，这些谓词后面都紧跟一个?号。返回的值为\#t或者\#f。如果期望检查内存中的两个对象是否相同，可以使用等价运算符eq?。 在Scheme当中，全局变量使用define赋值，如(define pi 3.1415926)，而局部变量使用(let (var-list) (exr))的形式来表示。比如(let ((pi 3.14159256) (r 5)) (\* pi (\* r r)))表示在计算表达式(\* pi (\* r r))的时候，用3.1415926代表pi,用5代表r. 在Scheme当中，构造表同样可以采取cons与list过程。表示对未被求值的表进行合并，结果是一个不被求值的表，比如(list \a’(b c))返回值是’(a (b c))`。 Scheme基本的表的操作过程与LISP语言相同，也是car与cdr过程。与LISP相同，Scheme也提供了合并算子，比如cadr代表先car,再cdr,cdar代表先cdr再car.除此之外，也可以使用list-ref提取它的第N个元素，比如(list-ref '(a b c d) 2)代表提取它的第三个对象'c(因为编号从零开始)。 而length()返回表的长度。 Scheme支持if与cond这样的表达式。除了以递归实现循环与迭代外，Scheme还提供了类似于do那样的循环与迭代。除此之外，还提供了map函数，用于将一个函数作用于列表中的每一个对象，如:(mapa (lambda (x) (\* x x)) '(0 1 2 3))。Scheme提供两种类型的函数，原语和过程，原语可以理解为内置过程。在语法上，使用(define (proc arg1 arg2) (body-list))来定义函数，与LISP原版稍微不同。 可以使用write或者display函数进行输入与输出。 POP-11语言 POP-11是一种著名的多范式语言，具有函数式语言的许多特性。POP-11因为具有垃圾收集器而被划为函数式语言，但是它像许多命令式语言一样具有块结构语法。POP-11还是面向堆栈的，在语言设计方面具有第四代语言相对独特的功能。 基于堆栈的另一个语言只能想到PostScript了。 POP-11是爱丁堡大学在人工智能研究中进行POP系列语言开发的产物，于20世纪70年代中期在PDP~11/40计算机UNIX操作系统上实现。POP-11在语言设计方面已达到最先进的水平，它不但有函数式功能，还具有面向对象性能与一个图形库。POP-11是一个专为教学而设计的语言，虽然它功能很强大，但是却没有广泛用于软件产品的开发。 POP-11的有益之处是，它在单种语言中支持命令式程序设计，逻辑程序设计以及函数式程序设计，这通常被视为是艰巨的任务，而POP-11却能很好地完成。 在互联网上，这样的语言的资料还真不好完成。至少中文的维基百科上面就缺少这些资料。只能从英文网页寻找。而且关于POP-11的资料实在是太少了。几乎只能上英文官网上面查找。安装过程也比较奇怪。而且现在还不能编译出来带图形界面的版本。最后，能用就行了，安装完成后，输入poplog pop11就可以进入交互式环境了。POP-11的后缀名也是.p,不过为了避免重复，还是使用p11作为后缀吧。不幸的是，listings宏包还没有POP-11的语法高亮。不过现在POPLOG是一个SOURCEFOGRE上的项目，名为OpenPoplog,希望它可以让POP-11发展壮大吧。 POP-11的一个比较全面的描述是支持多种范式的程序设计，对每种范式都有相应的概念。但是在这里显然只能讨论有助于说明语言的基本特性的那些机制。 数据表示(类型系统) POP-11包括多种数据对象，从数值(整数与小数)，到字，串，表以及向量。其中的表可以是复合的，可以包含其它的对象或者表。向量数据类型包括一组标准操作的类，用户可以进一步创建自己的向量类。字是用双引号括起来的，不知道它与串有什么区别。串是用单引号括起来的，它与其它语言中的字符串有更大的相似性。 当然了，在POP-11中，用方括号表示表，用大括号表示向量。 谓词 对于给定的一个对象，POP-11提供了dataword()函数用于识别其数据类型。如果在一行语句后面添加上=&gt;;，作用是告知解释器输出表达式的结果。如dataword(5) =&gt;;。(这里光说不能讲明白，找一个POPLOG程序试一下就知道了。) 下面是POPLOG的一个交互式输入示例: 15:48 kael~$ poplog pop11 Poplog Version 15.6.4 setting poplib poplib set to /usr/local/poplog/current-poplog/Poplib Sussex Poplog (Version 15.64 Mon Oct 24 00:15:10 BST 2011) Copyright (c) 1982-2009 University of Sussex. All rights reserved. Setpop : dataword(&quot;zoe&quot;)=&gt; ** word : dataword(5)=&gt; ** integer : 抄终端代码实在是太难看了，要多难看有多难看。 表达式:由于POP-11是一种多范式的语言，我们可以使用多种方式定义表达式并求出其值，像5+7=&gt;;，*(3,4) 这样的形式都是允许的。前缀表示与后缀表示都是可以的。通过两种方式，POP-11同时支持命令式编程与函数式编程。 变量:在POP-11中使用关键字 vars 声明变量，可以用它一次建立多个变量，如matlab中那样。变量之间用逗号分开，语句结束用分号分开。(用分号结尾的句子可以抑制向终端输出，Sage也有这样的功能)。变量的类型是动态确定的，它可以被赋予任意的值，比如 [a b c] -&gt; x (使用 -&gt; 作为赋值运算符(因为 = 代表的是相等测试(逻辑或算术相等)))。 同样地，POP-11提供了表处理功能。对于一个表，可以使用 &lt;&gt; 连接两个表，合并成新的表，并赋给新的变量。(使用pr(var)的方法在终端输出一个变量的值)。除此之外，还可以使用 [x ^^list1 y ^^list2 z] 这样的表达式，来重新组成一个表，其中运算符 ^^ 表示将表的元素提出来，各并到新表中。 POP-11的表处理，还有hd()，tl()，length()函数，分别相当于Scheme的car,cdr与length. 条件语句 ~ POP-11的条件语句采用命令式块结构模型。形如if-then-endif这样的形式，因而不再使用括号块。类似的命令式结构，还有until-do, do-until, repeat, while-do与for等等。不过尽管POP-11支持许多迭代方法，但是事实上，有些仅仅是语法糖(那些语言的附加成份，但是不不扩展该语言的表达能力的语句)。 POP-11支持maplist()作为其它语言中的map过程。用于将函数应用到一个表。而在POP-11中，过程的定义与块结构语言一样，使用define-endfine的结构，不过POP-11的函数定义是很广的，可以向过程传递多个结果，也可以返回多个结果(就和Python的语法一样)。 模式匹配:POP-11提供一组完美的模式匹匹功能，用于逻辑程序设计或者自然程序设计过程。POP-11的匹配是通过matches关键字实现的。比如: [ [tim 41] [jill 35] [megan 15] ] =&gt; mylist; vars age; mylist matches [ == [jill ?age] == ] =&gt; 其中matches匹配的是列表中的每一个元素。如果有等于jill的项，那么返回真值，并且将age变量的值赋给符合要求的匹配(使用?代表我们的意愿)。 其中的==用于表示模式在列表中出现的位置不限。这种模式匹配对于开发自然语言系统来说特别有用，如著名的Eliza程序。 比如: [I hate you] -&gt; inp_sentence; if inp_sentence matches [I ?verb you == ] then [why do you ^verb me] =&gt; endif; 它表示在遇到指定的模式的时候，把中间的verb提取出来，然后返回输出。 也告诉我们，匹配的时候用问号，而引用变量的匹配的时候用^号。 POP-11内置的输出语句是printf,它的参数的类型是一个串(不是字)。 对POP-11的学习就先到这里吧。实际上，如果要达到可以自由试验的地步，应该知道怎样使用程序的交互式控制台，怎样从命令行运行一个源文件，怎样编译出来结果，以及怎样编译成库。这样才算是比较完美。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[LaTeX的编程原理]]></title>
      <url>%2Ftex-tokens%2F</url>
      <content type="text"><![CDATA[第二节 书籍排版与普通排版 %%% 这部分实际上是介绍tex的输入与词法规则，算是编程基础 当使用计算机排版，我们首先要知道传统排版与使用计算机输入字符的区别。本来计算机上面的字符并不是专门为了排版而设计的。为了使用现有的计算机键盘输入TeX的源文件，我们需要对原来的键盘符号进行一个重新定义。 单引号，双引号 键盘上，左单引号与右单引号是区分开来的。一个是好像重音符号的东西，另一个就是普通的单号号。但是直接键入的时候，TeX将这个符号理解成左单引号。显然我们不能使用ASCII上的双引号排版双此号，因为那样无法区分左右。所以两个连在一起的左单引号代表左双引号，而两个连在一起的右单引号代表右双引号。 这种方式总让我想到那个m4编程语言，也使用` 与'代表成对的单引号。这样的标记有一个明显的好处，那就是我们可以利用它实现块的嵌套。而且我们可以根据引号的方向就可以看出来被括起来的文本是在这个括号的前面还是在这个括号的后面。 连字符，短破折号，破折号，减号 在键盘上它们有一些相像。通常直接键入-产生一个连字符，--代表一个短破折号，而使用---代表一个破折号，最后的一个减号只在数学模式当中使用，方法是$-$。连字符常用在复合单词当中，短破折号常用来表示一个范围，比如page12--23.。其实也就是短破折号常用在表示数字范围上面。破折号是作为一个标点符号来看的。经常用于区分两个句子或者一个句子中不同的短语成分。我们可以想象，假设在符号\(X\)前面有\(A\)，后面有\(B\)，那么连字符将\(A\)与\(B\)视为一个word,而短破折号将\(A\)与\(B\)视为一个number，破折号将\(A\)与\(B\)视为两个短语。至于减号，则是附加了运算符的意义。 按照长度从长到短来说，破折号&gt; 减号&gt; 短破折号&gt; 连字符。 在英文中，hyphen表示连字符，dash表示破折号，minus表示减号。在常用的文献当中，有时候也使用连字符代替短破折号以代表从第XX页到第YY页。不过，我们还是严格按照TeX当中的规定吧。以后就用--表示从第多少页到第多少页。 ex2.1 [怎样键入单引号，双引号，连字符，破折号，短破折号，连字符] 方法如上。 ex2.2 当你在一行中连续键入四个连字符时会得到什么结果? 按照最最长记号识别原则，应当是在第三个连字符后面断开，结果为一个破折号与一个连字符。 在排版精良的书籍中，两个相近的字母有时候会连在一起，称为组合字。组合字常用在ff,fi,fl,ffi,ffl这样的组合当中。主要是提高可读性。我们可以以find为例查看一下排版效果(默认为根据单词的组合情况自动排成组合字的)。如果要取消组合字，可以在字母中间加上一对大括号，表示从这里断开分组，将前面的词视为一个完整的排版单元。 在TeX当中，除了这样的调整外，还有字距的自动调整，比如\(V\)与\(A\)在合在一起的时候，会自动调整它们的间距，以使得排版更好看一些。 一般而言，TeX直接排版的时候就好像在打字机上键入书稿一样，但是在前面所提到的情况，以及其它的一些细节会做好调整。 如果我们的键盘上没有左引号或者又引号，可以使用控制序列\lq,\rq代替。注意TeX在识别记号的时候是遇到非字母符号的时候结束。如果控制序列后面是一个空白字符，那么控制序列后面的空白字符会被忽略，如果想使本控制序列结束，而后面的空格不被忽略，可以使用一个转义的空格，如\rq\rq\。 ex2.4 好了，现在你知道怎样得到相邻引号的排版方法了吧。 在单引号与双引号连续排版的时候，我们不能简单地敲入''',{'}''等其它的任意设想的符号，按照习惯，在两者连续排版的时候，应当在单引号与双引号之间加入一个窄的空格，比如'\thinspace''。 ex2.5 想一下作者为什么使用控制系统\thinspace而不是\,以解决相邻引号的问题? 为什么使用\thinspace而不是\,呢? 我觉得可能根据TeX的设计原理，在\thinspace处不会发生断行吧。在进入数学模式之前与离开数学模式的时候可能会断行。所以可以设想一个TeX源文件有一个断行点。这个断行点决定了在那些位置可以断行。 TeX的控制系列 键盘所含的字符与所期望的显然是太少了，所以一些字符不得不转义使用。在TeX程序源代码中，使用反斜杠作为转义符。实际上，TeX允许使用任意字符作为转义符，但是一般采用反斜线。主要因为它在一般文本中很少被使用。 操作系统的转义符通常是ESC按键，它与TeX系统的转义符根本不是同一个概念。 TeX系统的转义序列由反斜杠加后面的一个单词构成，单词的定义是[a-zA-Z]+,因此既不能含有数字也不能含有下划线。 常用的控制序列有\input{STRING}用于将目录名为STRING.tex的文件读入到当前文档里面并执行。而\'，\&quot;表示重音符(一个像是加拼音中的二声，另一个是上面加两个点)。而且在TeX当中使用\\并不表示换段(与LaTeX不同)，而是表示排版出反斜杠来。 控制序列有两类，前面的一类我们已经介绍过了。实际上，\'这样的控制系列就是第二类，它们由反斜杠后面加上一个非字母符号构成。 ex3.1 在\I'm \exercise3·\\!中，控制序列有哪些? 有\I, \exercise, \\三个。 ex3.2 键入各种重音符号。 除了前面的\'、\&quot;外，还有其它的控制序列。 \' 产生一个类似于阳平的声调符号，acute accent, 尖调符号 \. 在字母上面产生一个点号， dot accent, 点调符号 \= 在字母上面产生一个，macron accent,平调符号 \^ 在字母上面产生一个^、circumflex accent,长调符号 \\`` 在字母上面产生一个\,grave accent, 重调符号 \&quot; 在字母上面产生两点，umlaut accent,元音变音符号 \~ 在字母上面产生一个波浪线 \d 下加点 \H 匈牙利元音变音符号 \t 连接两个字母的等号， \u 上面加一个类似u的东西， \v 上面加上一个类似v的东西，上声。 由于\v是一个控制系列，所以我们后面得加上一个空格或者一对大括号以使它结束。控制系列的作用域实际上是它的参数，关于TeX的控制系列如何得到参数，可以参考后面的学习主题。 在转义符后面跟一个空格表示的是一个不能被忽略的空格。它是第二类控制序列，所以在转义后的空格后面的所有字符都会被忽略。所以使用转义时，用\ \ \表示三个连续的不能忽略的空格。 一般来说，在英文中，句子之间的间距要比空格大一些。因此打字员通常使用两个连续的空格以表示句子结束。但是在TeX中，连续的空白字符作用是一样的。并且，TeX会自动判断哪里是句子的结束，并在排版时自动计算出较大的间距。 关于TeX标记的排版 TeX标记本身用\TeX控制系列产生。但是它后面是没有自动排版括号的，所以如果将TeX作为一个单词来看，我们还必须在后面加一个转义的空格。 TeX命令后面不加空格是有原因的，因为我们经常使用`’这样的括号，如果\TeX恰好后面是一个引号，如果有空格，就会产生错误的结果。 TeX系统控制系列的情况 TeX的内置控制系列大概有900个。其中有许多都是数学符号，如\pi,\Pi,\aleph,\infty, \le, \ge, \ne, \oplus,\otimes 等。 记符号也是一件不容易的事情。如果是希腊字母，小写的用全小写的英文，大写的则使用首字母大写的控制序列，至于\oplus,\otimes,则可以看成是带圆圈的加法与乘法，在群论里面经常会用到。 其中的大约300个称为原始控制系列，其中\input 就是一个原始控制系列。原始控制系列是很基本的。我们不妨看一下，\TeX,\', \oplus 这些符号都不是原始系列，所以原始系列几乎可以看成是TeX语法当中的关键词。 在TeX运行时的交互式环境下，用\show命令后跟控制序列可以查看它的类型与值。我们不如在交互式环境下面读\show``\thinspace 看一下结果。 TeX的交互式环境下面有各种不同的提示符，当有两个星号时，表示需要输入一个文件名进行处理(因此进入TeX前我们先touch一个tex文档); 当有一个星号的时候，表示我们可以正常输入控制序列了。而问号表示我们进入了程序的菜单界面，这个时候按回车返回到一个星号的状态，使用X表示退出。当使用\show命令后，以&gt;开头的行表示控制序列的含义，-&gt;这一行表示控制系列的定义。 通过测试\&lt;回车&gt;是一个高级控制序列 ex3.4 有多少个两个字符的不同控制系列? 有多少三个字符的? 逻辑上跟ASCII编码数有关。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[TeX与LaTeX的编组]]></title>
      <url>%2FLaTeX-grouping%2F</url>
      <content type="text"><![CDATA[编组 编组可以理解成计算机编程中的模块结构。编组发生作用是在编程语言层次上的，也就是每经过一个编组，编译器就回复到编组之前的正常规则。 ex5.1 得到ff不连在一起的shelfful. 方法是输入shelf{ful}.也就是在f中间加上一个编组。 ex5.2 不用转义的空格，怎样在一排中得到三个空格。 使用{ }{ }{ }吧。或者{ } { }，注意编组后面的空格不会被自动忽略。 为了使控制序列作用在特定的文本上，我们也使用\centerline{}这样的结构。 虽然编组的功能很强大，但是也容易使文档变得难读。幸好在普通文稿当中不必使用太多的编组。 括号的作用有多个，一个是把多个单词看成一个结构，另一种是提供了一个局部模块结构。不应当认为大括号仅有一个作用。 ex5.3 键入下列内容会得到什么结果? \centerline{This information should be {centered}.} \centerline So should this. 它的结果是，第一条命令产生一个居中的文本块，但是第二行将只有一个单词S。第三行变成了一o开头。 注意第二行不是一个单词，因为TeX控制系列默认将后面的一个字母而不是单词视为一个单独的参数。 ex5.5 定义一个控制系列\ital,使得用户键入\ital{text}来代替{\it text\/}.与\it相比它有什么优缺点。 显然使用\def\ital#1{ {\it #1\/} }它的不足只是放在后面，并且总是有一个斜体校正，它的所有的特点都跟它的封装形式有关。 TeX的宏定义与m4差不多，过多的括号里面，只有最外层的被去掉，内层的括号得到了保留。 TeX的参数的处理 与C语言不同，在编组当中改变即使是全局变量，当走出编组的时候全局变量也会恢复成原来的样子（这有一点像是有硬堆栈变量的计算机）。使用\global命令可以做到这一点。比如将计数器加一的操作，显然通过普通方法是不行的，在块里面需要使用 \global\advance\count0 by 1 其中的advance表示对指定的计数器加上特定的值。\count0是TeX内部的一个计数器。 分组 另一个分组的命令是\begingroup{GRPNAME}...\endgroup{GRPNAME}. 这个可以看成是LaTeX环境的基础。如果使组正常工作，那么我们就应当避免Sa,Sb,Ea,Eb这样的情况，方法其实很简单，在Sa的时候定义一个\blockname{}名子与本环境的名子相同，Sb也同样这种做法。这样在Ea的时候，Sb定义的blockname就会消失，在读到Eb的时候检查一下b有没有被定义就可以了。 \def\beginthe#1{\begingroup\def\blockname{ #1}} \def\endthe#1{\def\test{ #1}% \ifx\test\blockname\endgroup \else\errmessage{You should have said \string\endthe{\blockname}}\fi} （具名编组的概念，有些像是Pascal语言的end for语句之类的扩展）。 从外壳中键入tex命令，出现双星号提示符，要求输入文件名，这个时候我们可以代之以输入\relax命令，进入到一个星号的状态。之后就进入排版了。 在输入完成内容后，键入\end可以结束会话，TeX会把文件输出到当前目录里面。 在第一篇TeX当中，可能\hskip, \vskip 以及后面的\hrule 我们比较常用吧。 直接的波浪线表示告诉TeX前后两个文本是连在一起的，不要在此处断行。\vfill表示用空白将本页剩下的部分用空白填满，然后用\eject把它送到输出文件。 在出现**提示符的时候，我们可以以&amp;开头表示以特定的宏格式处理文件，比如 &amp;plain \input story表示使用plainTeX的格式处理文件。一般来说，还可以在从外壳调用它的时候使用tex &amp;plain story或tex \relax这样的形式直接跳过双星号提示。 \eject 表示本页处理完毕，不代表所有的页都处理完成了。我们仍然需要使用\end来结束文本的输入。 在TeX中，由\hsize=控制本行的排版宽度(不是页面宽度)。 如果TeX发出警告，那么每段文本后面最后有一个|表示在输出的时候TeX加了一个黑色的方块。以产生警告作用。 在输出文件的时候，TeX总会产生log日志。 TeX通过给定的信息以断词。比如通过\hyphenation{gal-axy}，中间的一个-让TeX知道这是一个可以断词的位置。 错误信息与处理 TeX的错误信息是以感叹号!开始的。并提供了错误上下文。上文是读出的内容，下文是要读的内容。并在上文的最左边给出了错误的行号(X.Y中Y表示行号)。 这个时候可以键入回车，表示试图忽略本次错误，或者输入 在TeX当中，这些命令改变了交互的等级。S,R,Q分别对应于\scrollmode,\nonstopmode,\batchmode.使用\errorstopmode转成正常的模式。这些命令是全局作用的，无论它们出现在哪一个组当中。 调用宏的时候产生的错误就像编程语言里面函数调用栈的错误一样，我们可以设置\errorcontextlines设置显示出来的调用栈的深度。 TeX的工作原理 在TeX中有如下约定，一个回车类似于一个空格，一行中的两个连续空格被视为一个，无论出现在哪一个位置，并且使用一个空行表示一段的结束。 TeX的字符所属的类 256个字符被分成16类。数字编号从0到15.TeX在读入文件的时候每次读取一个记号，并对比当前记号所在的类，以决定所产生的行为。这些类及作用为: 类别 意义 默认字符 0 转义符 反斜杠 1 组开始 { 2 组结束 } 3 数学环境 $ 4 表格对齐 &amp; 5 换行 6 位置参数 # 7 上标 ^ 8 下标 _ 9 可忽略字符 10 空格 11 字母 [a-zA-Z] 12 其它字符 无 13 活动符 ~ 14 注释符 % 15 无用符 其中每类都可以包含若干个字符。当使用plainTeX格式的时候，$,%,&amp;,#,_要转义使用。此外，一些词在转义时有其它的含义，比如\~得到的是波浪重音。 在TeX工作的时候源文件中所有的部分被分成一个一个的记号，它们或者是指定类代码中的单个字符，或者是一个控制序列。也就是在读内容的时候，TeX先给字符分类，根据分类的情况作进一步的处理: \hskip 36 pt \\[1]skip3[12]6[12] [10]p[11]t[11] TeX有一个叫INITEX的版本。这个版本里面气有的字母都被认为是12,除了字母，回车，空格，delete,注释与反斜杠符号之外。 一个明显的特点是，编组符号是不能使用的。 使用\catcodeSYMBOL=N`来将字符更改到指定的类代码当中。 catcode的作用域是局部的。使用\string命令可以将控制字符分成单个的对象。使用\csnameXXXX\endcsname可以将一个字符记号列表变成一个单独的控制系列。只要它不与TeX的原始控制序列相冲突。这个时候，控制系列的名子完全来自于后面的字符，比如 \csname TeX\endcsname 我们不能使用\csname\TeX\endcsname这样的格式，因为\TeX在被调用的时候会被宏展开成其它的东西。 \string宏可以看成是读取后面的非空白字符并按照原样显示，它可以用在我们的\message{\stringXXX}命令当中，以便正确显示出向用户提示的信息。 注: 当\csname用来第一次定义控制系列的时候，那个控制系列在重新被定义之前等价于\relax命令产生的效果。 使用\let命令可以给一个记号赋值，使用 \ifundefined{TOKEN}&lt;if_true&gt;\else&lt;if_false&gt;\fi 可以完成一个复杂的判断逻辑。比如 \ifundefined{TeX}&lt;true_text&gt;\else&lt;false_text&gt;\fi 表示在\TeX宏未被定义或者为\relax的时候被展开成，否则被展开成. \let的语法是\let\TOKEN=\VALUE 除了\string用于得到记号外，还可以使用\numberNUM用于得到一个小数，使用\romannumeralNUMBER得到一个用小写罗马数字表示的数(如\romannumeral24得到xxiv)。并且可以使用\numberREG来得到一个内部寄存器里面的数字。 \uppercase{token_list},\lowercase{token_list}用于完成记号的转换。 ex7.8 想一想，\uppercase{a\lowercase{bC}}得到的记号列表是什么 这可能是TeX语法最为特殊的一点了吧。它的展开不是从内到外逐渐展开的，而是从外到内按照记号逐个分析出来的。发生的过程是，首先\uppercase宏看到了它的一系列参数。这些参数被识别成记号的列表，a, \lowercase, {, b, C, }，各自都是完整的单位。这个时候，每一个列表被分类。被uppercase宏作用，就变成了A\lowercase{BC}。然后继续向前读入字符并排版，转成Abc. 这个过程可能很特殊吧。仔细想一想，它跟m4宏还是很相像的，不过m4宏把它们都当成字符，而TeX还分类处理这些记号。 ex7.9 TeX有一个内部整数参数叫做year,它等于任务开始时当前年的数字，看看怎样用\year以及\romannumeral和\uppercase对所有运行在2003的任务给出后面的版权表示。 根据前面的介绍\uppercase{\romannumeral\year}显然是不行的，因为uppercase在展开的时候，首先得到它的参数，而它的参数还没有被展开，为了解决这个问题，必须使用\expandafter宏，让里面的宏先展开，让uppercase得到宏展开后的参数。 正确的答案是 \copyright\ \uppercase\expandafter{\romannumeral\year} TeX的语法的特殊性现在有一点了解了。但是还差很多基础的知识，等看到后面更多的控制系列之后再看它的语法结构吧。 字符输入 很少有键盘能够提供256个字符，而且有的字符已经有其它的用处，所以我们使用下面的char命令得到任意的字符。格式是: \char&lt;NUMBER&gt;得到当前字体的相应字符。注意是当前字体中的字符。 在TeX刚设计的时候，一个字体文件就最多只有256个字符。在TeX内部，字体的代码总是以ASCII格式被调用的。b的内部代码，这样就总是98. Knuth喜欢使用斜体表示八进制数，使用打字机字体表示十六进制数。个人的习惯不同吧。我觉得都使用正常字体就行了，Knuth的字体使用风格有些复杂。 八进制数使用右单引号引导，而十六进制数使用&quot;引导。比如\char'142与\char&quot;62与\char98是等效的。 定义char还有一个比较方便的方式，这时候不用使用\def&lt;SEQ&gt;{\char&lt;NUM&gt;}这样复杂的形式，而是直接使用\chardef&lt;SEQ&gt;=&lt;NUM&gt;。 有些人的键盘上直接有\(\leq\)，\(\geq\)这些字符，它们的生活还真是比较方便啊。 像回车等换行字符的ASCII可以使用^^M这样的形式来表示。^^后面实际上还可以跟两位十六进制数字，用于表示指字代码的ASCII字符。 TeX系统读入的规则 TeX的输入是一系列的“行”，当TeX从里面读入文本的时候，它就处于三个状态中的三歧的一个: 新行N,行中间M,跳过空格S. 在每行的开头它处于状态N,但是大部分的时间它处在状态M,当读入一个控制词或者一个空格之后它进入状态S,这个时候再遇到空格就会被忽略。 出现在行尾的任何空格都会被删除。当TeX在任意的状态读到一个第零类的字符的时候，它就会搜索这个控制序列的名子。如果行中没有其它的字符，那么定义这个序列的名子为空。如果接下来的一个字符不是属于第11类，那么它读入一个字符作为控制系列的名子。如果是属于第十一类，那么继续读，直到读到一个非第11类的字母为止。作为控制序列的一个记号。在读完记号后进入到处理第十类字符的状态S,如果读的记号为空，那么进入状态M当中。 TeX在任意状态遇到第7类字符，并且接下来还是一个第7类字符，也就是遇到了^^，如果后面跟一个小于128的字符，那么^^被去掉，并且从c中加上或减去64.于是^^A就被解释成ASCII为1的字符。但是如果后面跟的是0123456789abcdef,那么读取两位字符，然后使用十六进制代码对应的符号替换^^xx.当替换完成后，TeX返回到原来的位置继续开始。 比如，使用\T65X得到的结果与\TeX结果相同，因为65代表的就是字母e. 在上面的状态下，如果遇到的不是三字符或者四字符，采用另外的处理办法。在读入一个^后，下面的字符如果是1,2,3,4,6,8,11,12,13类中的一个字符，或者第七类的字符，但是不能理解成上面的三字符或者四字符，那么它给字符一个类代码并且进入状态M. 如果遇到的是第5类(行尾字符)，那么它就放弃本行剩下的所有的内容但是如果在状态N的时候遇到了行尾字符，那么行尾字符就被转换到控制系列\par.如果处于状态M,那么行尾字符转换成第10类(空白)记号。如果处于状态S的时候遇到了行尾符，那么行尾的字符就被忽略。(同时转到状态N?) 如果遇到第9类字符，那么直接忽跳过它，就好像没有它一样。 遇到第10类字符的处理: N或S时，第10类字符被直接跳过，并且保持当前状态，处在状态M的时候，字符被转换成第10类的记号，并设此记号代码为32.然后进入状态S.空格记号当中，字符代码总是32. 我们不妨看成这就是TeX程序的词法分析。在词法分析的时候它得到了记号的类型与记号的值。 如果TeX遇到了注释符，它就不再读入当前行剩下的内容。 遇到无用符(第15类)的时候，跳过此字符，打印出错误消息，并仍保持当前的状态不发生改变。 如果当前行没有要读入的内容了，就进入下一行并且进入状态S.但是如果是\input文件结束，或者\input的文件给出了\endinput,那么TeX返回到\input文件读取结束后的状态，就好像是从读完input的内容一样。 ex8.2 回答下面简短问题，看看你对TeX的读入规则的理解程度: a.第5类和第14类的不同在什么地方 b.第3类和第4类的不同在什么地方 c.第11类和第12类的不同在什么地方 d.活动符后面的空格要忽略掉么 e.当一行以注释符%结尾的时候，在下一行开头的空格被忽略了么? f.一个可被忽略的字符能出现在控制系列的名子中间吗? 答:a.第5类是换行，第14类是注释，两者都结束了当前行，但是换行会被转成第10类(空白符)的代码或者一个\par控制系列。但是第14类的字符永远不产生任何记号。 b.第3类是数学类，第四类是表格类。它们产生不同类型的代记号。在后续的处理当中它们是完全不同的。 c.类似于b.第11类是字母，第12类是其它符号。但是只有第11类的字母有组成较长的控制系列的能力。 d.不能被忽略掉。活动符是第十三类，读完它后处于状态M,后面的空格不能被忽略。 e.是的，当注释符里面的内容结束后，TeX进入状态N,任何位于行首的空白字符都会被删除的。 f.不可以。控制系列是连续读取在第11类中的单词，遇到其它类就是结束对控制系列名字的读取。从而起到了分割的作用。 ex8.3 再次看看有关\vship的错误信息，当TeX报告说\vship是一个未定义的控制序列的时候，它输出了两行上下文，表明它正在读入文件story的第二行的中间部分，在遇见错误的时候，TeX处于什么状态，它下一个要读入什么字符。 我们可以按照正确的路向分析。它读入一个控制系列后处于状态S,会忽略掉后面的空白的字符(第10类)，因此它下一个要读取的是非空白字符。 ex8.4 给定plainTeX格式的类代码后，从输入行$x^2$~ \TeX ^^62^^6得到什么样的记号? 这得好好分析。首先数学模式正常排版，读完$后进入M状态，活动符是有效的，所以波浪线后面的空格不能被忽略。接下来读\TeX,在读完\TeX之后，进入状态S,因此后面的空格都被忽略，接下来读^^62,得到字母b,再接下来读记号^^6,得到字母v. 我们完全可以把这种分析过程理解成词法分析，分析之后形成了记号的类型与值的线性序列。 ex8.5 想想正好有一个三行的输入文件，第一行是Hi!,其它两行都是空的，当TeX读入这个文件的时候，按照plainTeX的类代码将会得到什么记号? 这个时候处理的方式是，处理成[11]H[11]i[12]![10] [0]\[S]par.空格是第一行的回车引起的。 据Knuth自己的表述，类代码写成数值格式主要是为了防止人们过度使用\catcode.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用python下面的enthought和matplotlib绘图]]></title>
      <url>%2FPythonPlot%2F</url>
      <content type="text"><![CDATA[关于matplotlib的一些问题 安装模块的问题 一直不了解模块到底是什么东西，它与对象有什么样的区别。到了现在才差不多把模块比成一个可以加载与控制的子程序。在Python这样的动态类型里面相当于扩展功能。相当于在C语言程序里面使用了其它的库。 这么说来，模块的编译原理理论应当是与子程序密不可分的。以前甚少将动态语言里面的模块与C语言这样的传统语言里的程序联系在一起。那仅仅是因为自己觉得C语言这样的程序是连接到二进制的库，而动态语言是导入源代码。而库与源代码是绝对不同的事物。这说明自己还是抱着以前形成的概念，以为在二进制与源代码是绝对分离的。但是在开源世界源代码与二进制通常并不存在异步的现象。两者还是非常相近的。 在开源的世界里淡化了库与源文件在用户与程序员角度上的差别。这个观点应当好好地思考一下。在Shell里面是没有什么模块的，它们使用的都是脚本与函数这样的概念。基本上只是使用另一个编译单元或者运行实体的一部分代码，这部分代码只是一个源文件里面很少的一个成分，基本上我们调用一次函数后就不再用它了。但在Python当中，我们不如认为一个模块可以以解释的方式出现，也可以以编译的方式出现。或者以混合的方式出现。这并不阻止我们使用一个模块。 于是使用模块就好像是在C语言里面加载动态链接库一样。大致来说就是如此。但是模块在脚本文件里面通常有更多的应用。也就是如果我们在文件a里导入一个代码，通常我们在a文件里面大量的功能都是通过库来实现的。但是在C语言里面并不能感受到这一点。 在C语言里面并不怎么关心库是怎样导入的。这大概是因为C是一个系统级的语言。通常而言如果我们要使用C库，需要一个头文件一个库文件就可以了。由于了解C语言的人数是那么地多，所以导入C库的方法就变得几乎不用任何思考了。 但是脚本语言的应用还是没有C那么多。脚本语言里的模块，虽然功能上与C还是那么地相象。但是所用的指导理论至少在形式上与C的差别还是比较大的。类似于C,模块也有自己的命名空间。但是在Python当中，模块是以一个对象的形式存在的。 在C语言里面也没有接触过怎么编译与安装模块，似乎那是不用考虑的，只要我们有头文件与库文件就可以了。但是那只是模块的产品，我们如何根据源代码生成库呢。 还有，Python里面的库是可以有很多的层次的关系的。这一点在C语言里就更没有体现了。CXX里面还有命名空间的概念的。可是以前学习CXX的时候都没有怎样讲命名空间。我想设计CXX时，命名空间那个时候还是为一解决函数调用重复而设置的一个机制，并没有太多其它的意思。但是脚本语言里面，命名空间得到了广泛的应用的同时，可能也有了一个理论的基础。不过，由于模块这个词比较陌生，在理解时用C语言的头文件加上库文件理解就是一个相当必要的方法了。 Python的库的安装 以matplotlib为例吧。安装一个模块的基本过程是: 检查要安装的模块所需的依赖关系是否满足。我们可以视为当前系统上面是否有相应的头文件与库文件。但是C语言里面还没有见到过。我们就把模块想象成C语言里的动态链接库吧，它不仅是需要一个编译器，还需要其它的库。我们知道C语言里面单独发布一个动态链接库版本是不可想象的。伴随一个动态函数库发布的通常还有其它的依赖的关件。不过造成这一现象可能更多是策略的原因吧。 对于matplotlib来说，检查的主要是numpy模块。要在动态语言里面检查模块是否被安装了，可以在执行解释器的时候导入该库，然后调用该库的 __version__ 函数。因为在Python里面，一个模块可以通过一个对象的方法进行访问。 import numpy print numpy.__version__ 模块与函数库的区别还在于，函数库是脱离编译器运行的。但是模块却是在解释器下源代码被解释器执行的。 在Python里面，对象占据着重要的地位。在导入模块的同时，不如就视为创建了一个模块访问对象。我们通过它访问到模块里面的各种数据结构，还可以通过里面的函数定义一个其它的对象。在Python里面不用声明变量类型。这是很有用的，因为模块里面对象的类型可能是非常长的一个名子。 在WINDOWS下面使用一个安装好的exe文件就可以了。 Python的库有时候需要编译。我们不如假设Python的模块不只是可以被解释，也可以直接先被编译出来，这样可以进一步加快速度。 matplotlib也是如此。如果我们从源代码构建它，可能就需要添加freetype,libpng,tk,pyqt,pygtk,wxpython等组件了。有了这些支持我们最终构建出来模块在被执行时所必需的程序，配置或接口实现等。 matplotlib的具体依赖可以查看INSTALL文档。与unix下面的其它文件基本相同。 编译模块 matplotlib里面实际上提供了一个Makefile文件。但是make help并没有显示出结果，也就不敢随便用它。按照上面的说明，编译的时候执行命令: python setup.py build 这是很简单的。因为我们还在没有configure的时候就已经编译出来了，到最后我们应该把文件安装到哪个位置呢。C语言的库来说并不成问题，一来有configure的prefix指出目标目录，并且unix系统搜索C库的位置我们也是知道的。但是Python就不同了。我们可能安装的并不是标准位置。但是先不管它。 安装模块 安装模块实际上相当于保证主程序，也就是python里面在import命令被执行的时候能够找到相应的模块。一般来说，模块能不能被导入仅仅是取决于它们是否在搜索路径里面。而Python的搜索路径除了当前工作目录外，就是在安装Python的时候的标准的路径了。 不同的系统有不同的定义吧。在我的系统上/usr/lib64/python*里面有python的标准模块。但是仍然没有发现matplotlib被安装在了哪里。 可以通过sys模块的 exec_prefix 与path变量得到关于python解释器的一些信息。模块文件可以是.py, .pyc, .pyo, .pyd, .so. 结果按照这种要求。在/usr/lib64/python2.7/site-packges里面找到了matplotlib. 假设Python安装在了 $PREFIX 下，可执行程序在 $EXEC_PREFIX 。下面，那么一般先找 $PREFIX/lib/pythonX.X 文件夹(Python可以向系统提供自己格式的库文件)，找 $PREFIX/lib/pythonX.X.zip 有的时候 $PREFIX/lib/pythonX.X/plat-linux2 也会被设置。动态加载模块的路径放在 $PREFIX/lib/pythonX.X/lib-dynload/ 下面。其它模块的默认安装路径一般是 $PREFIX/lib/pythonX.X/site-packages/ 。整个模块组织成了一颗树的形状。这颗树的根由库的搜索路径合并而成。每遇到一个子文件夹可能这颗树就向下延伸一层。 在sys模块里面的path变量里显示的是模块的ROOT的来源。而sys模块的本来含义并不是操作系统，而是Python解释器里的相关变量。 检查模块是否可用 这部分通常要运行一些测试脚本来完成。有时候如果没有的话，我们可以尝试导入我们安装的库，看看有没有异常出现。 自动测试应该还是有一些技术可言的。个人觉得应该使用脚本以及高度自动化的工具完成这些任务。说明一下，自己还想到使用m4宏处理器写一个简单的TeX前端，用于包含了复杂选项的TeX变成一些容易设置的选项的集合。 注：unix下面的应用程序都可以这么来看。一个应用程序的目录总是符合unix下面目录的规范的，库安装到 $PREFIX 的lib/下面，诸如这些规定。对于Python来说也是不例外的。因此对于matplotlib包来说，它不必什么都看Python安装在哪里。它可以认为它就是一个库，因此它的库与模块就安装在 $PREFIX/lib/python 下面，它的文档就安装在 /share/doc/$LIBNAME 下面。 关于IPython交互式解释器 matplotlib的pylab在运行show()时有时会不出现结果，那是因为我们当前可能并未关联到图形库。要想显示图片通常在shell里执行 ipython -pylab=qt 之后，使用 run $script_name 然后输出Python相应的代码进行。 使用IPython也算是能够提高工作的效率吧。不过也许只有在IPython里面才可以直接使用run命令了。这对于执行脚本是很有好处的。 在使用pylab的时候，绘图的后端决定了图片在哪里被显示。在ipython里面可以使用debug命令进入调试。 matplotlib的其它问题 其实可以使用setup.cfg对matplotlib的安装进行更详细的配置。我们不用从网上找资料。因为源代码包里的INSTALL等文档就是最好的说明。就连setup.py脚本也有很好的可读性。 也许以后自己应当学会从源码包里面读英文文档了。在网上找资料实在是太麻烦了。而且如果有可能，软件的使用教程也应当从附带的doc里面查找。 matplotlib绘图的基本方法 读过了书里的第5章的文档，觉得matplotlib的确很伟大。但是自己还是觉得不应当手动从无到有地使用pylab绘制图表，而是应当通过其它的科学计算软件调用它。这样绘制出来的图表才有意义。不然就纯粹是为了玩了。 我们不介绍其它的模块了。matplotlib是Python最著名的绘图库。但是pylab能在numpy或者scipy里面集成接口。 调试的方法 几乎每一本书都说Python的调试功能很强大。但是我却觉得Python的错误显示很复杂。大概是我不会使用堆栈吧。在ipython里面调试时，先运行程序。如果出现错误，程序会返回。这个时候调用debug返回到出错的时候的堆栈，使用u命令在堆栈中一直向上，直到出现本层次模块里的错误为止。 其实ipython的错误提示是我见过的最好最详细的提示了。中间有高亮又有各个源代码文件出错的行号。不过相比之下，python里的错误输出可能是最难读的了。可能是堆栈太多的时候必须有一定的提取文件中关键错误的方法吧。 ipython调试的时候显示的高亮什么的特性在Sagemath里也得到了应用。 matplotlib绘图的时候有一种基本的方法就是使用 import matplotlib.pyplot as plt 这样可以直接使用pyplot模块提供的绘图函数功能。 把模块导入成对象，可以这么理解，导入一个对象相当于找到一个能够在运行期间为我们干活的人。这个人可以做相应的输出，我们可以调用它里面的相应方法，或者根据它的功能创建一个工作对象。 另一个则是使用matplotlib的pylab模块。其中包括了许多NumPy与pyplot模块里面的绘图函数，可以方便快捷地进行计算与绘图。pylab可以直接通过 import pylab as pl 进行。 书里面实际上介绍了三种绘图的方法。有pyplot,pylab,这样直接调用模块的方法，也可以是调用pyplot里面的绘图API进行绘图。 pyplot的面向对象的绘图方法与机制 我们不如这样理解pyplot的工作过程。在刚开始的时候创建了一个模块访问对象，也就是在import pyplot as plt里面说明的plt这个名子。通过这个名子我们访问到绘图所需的一切要素。plt里面有自己的成员与数据，它的直接成员与数据通常都是用于调整绘图环境里面的配置的。真正绘图的时候，总是通过具体的绘图对象完成的。 我们不如称做是一个绘图对象关联了一个模块访问对象。我们可以通过plt创建，显示绘图对象，切换当前绘图对象这些操作。 绘图对象里面最基本的就是图表，其次是子图。当我们调用plt的绘图函数plot()的时候，总是在figure与axes对象上面绘制的。 一个模块访问对象plt里可以管理多个绘图对象。一个绘图对象里面也可以有多个子图。在pyplot里面，通过plt.figure(N)的方法访问指定序号的图表。当序号不存在的时候该图表会被自动创建。 如果我们在ipython里面测试，我们就会发现调用plt.figure(1)的时候会出现一个绘图窗口。接下来的绘图就是在这个窗口里面进行，而如果再调用plt.figure(2)就会创建另一个绘图窗口，里面有另一个图表。这时再调用plt.figure(1)并不会出现新的窗口。相当于模块会自动判断当前绘图区存在与否。 一个图表对象的类型是Figure。默认情况下，模块访问对象plt会创建一个图表，并将它作为当前的图表。plt的figure()函数也可以接受其它种类的参数。总而言之，plt的figure()函数完成的工作是创建图表，管理，导出当前绘图模块所属的某个图表对象。以及选择当前的模块访问对象绘图时所在的图表。 使用plt的gcf()函数获得模块的当前图表对象。类型是matplotlib.figure.Figure。无论以前面的哪种方式，返回值都是一个图表对象，我们就是在这个图表对象里绘制图表的。 这样一来，我们就不需要在figure里面绘图，然后再进行显示了。plt里面封装了访问当前figure的方法。调用名称与figure对象里的类似。 一个图表可能会有多个子图。子图用Axes对象来表示。pyplot并不是在一个Figure对象上直接绘图的，而是在一个Axes里面绘制函数的图象。plt模块封装的plot()，xlabel()等方法几乎都是针对于模块访问对象的当前子图而起作用的。 使用plt.gca()得到当前的子图。而使用plt.subplot()函数可以创建子图(实际上是在当前的Figure对象里面创建子图)。subplot的函数调用是subplot(Rows, Cols, Index)。该调用的含义是假设当前Figure对象被分成Rows*Cols的网格。使用编号为Index的区域绘制子图。Index的编号是从左到右，从上到下，编号从1开始。 如果Figure对象判断不同的subplot的区域有重叠，前面的被重叠的子图将会被清除掉以绘制新的子图。否则就继续添加新的图表。 函数subplot()返回它创建的Axes对象。调用gca(Object)可以使这个Axes()对象成为当前的对象。如果子图已经存在，subplot并不会将先前的子图覆盖，而是返回符合那个标号的子图。比如下面的代码: plt.subplot(111) plt.subplot(111) 第二个语句并不会清除掉第一条语句里的subplot,而是返回第一条子图创建的对象。 当Figure与Axes对象都决定好之后，真正的绘图就开始了。 绘图的时候坐标系的选择 matplotlib设置了四组坐标系。各个坐标系的大略描述如下: 窗口坐标系: 左下为(0,0)，右上为(W,H)。坐标以像素为单位。 图表坐标系: 左下为(0,0)，右上为(1,1)。坐标以英寸为单位。 子图坐标系: 左下为(0,0)，右上为(1,1)。本身是没有单位的。 数据坐标系: 根据不同的坐标系有不同的表达形式，在笛卡尔坐标系下面通常是\((XMIN, XMAX)\)到\((YMIN, YMAX)\)。本身没有单位。但是我们可以根据物理量来设置。 在屏幕输出的时候才用到窗口坐标系。我们不妨将图表坐标系看成是与平台无关的。决定了对象的实际的大小。 在实际绘图时，一旦终端被确定了，绘图程序的窗口坐标系也就相当于是确定的。于是根据这种关系，一个图表被显示到桌面上，或者是输出到一个文件当中。而单以纯数据表示而论，在运行的时候，所有的图形的位置在图表坐标系里面的安排都是固定的了。 不同坐标之间的变换都同样地依赖于本对象的二维仿射变换矩阵的定义。 假设ax是一个Axes对象。那么它有一个transData用于决定从数据坐标系到窗口坐标系的变换。函数 ax.transData.transform((3, 5)) 将返回点(3,5)在变成窗口坐标系后所在的位置。 注: 返回类型是一个ndarray对象。而且这个函数也可以一次调用返回多个点在窗口坐标系里面的位置。 下面我们以Figure下在的tranFigure变换为例了解Python的实现。 在交互式命令行下直接输入f.transFigure()将可以看到它里面的一些对象。其中第一项里面的Bbox描述了这个Figure的物理大小信息。比如\([0,0]--[8,4\)，单位是英寸。而在Affine2D里面的就是那个变换矩阵了。经过分析不难发现，对角线上的第一个元素就是所谓的X方向分辨率，第二个元素就是Y方向分辨率。我们也可以通过直接查看 f.transFigure._boxout._transform 得到真正的变换矩阵。 上面的代码实际上还只是一个Affine2D对象。调用它的 get_matrix() 方法才能得到以numpy.ndarray形式表示的矩阵。 而Axes对象在Figure里面的位置可以通过 Axes.get_position() 方法得到。其结果是在图表坐标系里面的位置(注意Figure坐标系从左下角的(0,0)到右上角的(1,1))。如果子图是以2*3行分隔的，那么最后一个子图的坐标通常就是(0.66,0)-(1.0,0.5)。不过实际上子图与图表边缘之间还是有一定间隔的。 根据这一信息我们自己就可以计算出来Axes对象如何转换成窗口坐标系了。就是拿前面的坐标系，乘以Figure的变换函数。这步工作Python是不会每计算一个点就运算一次的。因为Axes提供了 ax.transAxes._boxout 对象，它里面存储了变计算后的结果。 一般来说，一个子图对象里面只有一个数据坐标系。于是我们可以通过Axes对象访问数据坐标系的transData对象。该对象指出了数据坐标系里的点如何进行变换。 transData由transLimits与transScale构成。transLimit描述了该数据坐标系的坐标范围，比如(-5,-5)-(2-3)。而transScale表示transData将数据坐标系转成Axes对象坐标系里面的缩放大小，通常都是1.于是数据坐标系里面的某个点转成一个窗口像素。 使用这些概念主要用于处理不现的坐标系表示方法，以及不同的刻度标准。 关于绘图操作 如何调用label,line,axis等对象这里就不说了，因为它们是一些很繁锁的东西。 matplotlib绘图的背后原理 matplotlib的绘图的三个层次(这种三层次模型也可以用在其它的语言里面)是: backend_bases.FigureCanvas backend_bases.Renderer artist.Artist Renderer与Canvas知道如何处理底层的绘制操作，比如在QT界面上绘图或者使用PostScript在PDF文件里面作图。Artist对象处理所有的高层的结构，如图表，文字与曲线等绘图元素的绘制与布局。通常我们只是与Artist对象打交道，而不需要关心底层是如何实现绘图的细节的。 Artist对象有简单类型与容器类型两种。有点像是GUI里面的Component.简单类型的Artist对象是标准绘图元件，如Line2D, Rectangle, Text, AxesImage等。但是容器类型则包括了其它的简单对象，如Axis, Axes, Figure等。我们不如把Artist看成是一个桌面绘图管理器。那么以前所学过的Metapost语言便就是用于产生这些复杂对象的绘图原语言。它们能够在更底层的意义上提供编程方法，因而更容易绘制出来其它的对象。 Asymptote与Artist相比，多的只是一种灵活的方式。Artist虽然也是用编程语言实现，但是封装的内容与对象比较繁杂，底层不够清晰。而Asy使用清晰的底层数据结构，让我们可以自由地决定插值等操作。 我们也可以直接使用Artist对象绘图。利用Artist的特性的关键在于我们使用Artist提供的许许多多绘图对象，通过调用它们的方法设置它们的属性，进而描述出图形里面各个元素的关系。 一个Axes对象里面包含了其它的简单的对象，因为Axes是容器类型。使用Axes的lines可以得到在该子图里面的所有曲线列表。我们可以通过该函数返回对于这个曲线的引用以便我们能够单独地调整该line的属性。 Figure对象与Axes对象都有一个patch属性作为它的背景。这向我们说明Figure对象对于绘图的理解是描述性的，只有在调用实际的绘图引擎的时候，才会将背景显示出来。该背景是一个Rectangle对象。通过它我们可以设置背景的背景颜色，透明度等等属性。 Artist的对象有一些通用的属性，比如透明度alpha, label, visible等。所有的属性都可以通过 get_ 方法或 set_ 方法读写。而可以通过任何一个Artist对象的set()函数与get()函数设置一个对象的多个属性。 模块访问对象提供了getp()函数用于返回一个Artist对象的各种属性。比如通过 plt.getp(plt.gcf())我们就可以得到当前图表对象的所有属性名与值。在交互式ipython里面我们可以参考这些输出通过前面说过的set方法加以改变。 在matplotlib里面，Axes是绘图的核心。它包含了许许多多的Artist可显示对象。 matplotlib的配置文件 matplot工作是类似一个应用程序。检查配置文件的顺序是，当前配置文件，用户家目录下的配置文件，应用程序里面的配置文件。配置文件实际上是一系列的变量与值。在依次读取这些配置文件的过程中，如果前面的配置文件已经设定了这个值了，那么后面配置文件里面的值就不再生效。于是配置文件的优先级是当前目录最高的。 配置文件的读取也有一些规律。Bash从/etc里面读取配置，最终也是用户目录里面的配置脚本生效的。不如引入配置文件优先级这个概念。一个应用程序在工作的时候，假设从一列可选的列表里读取每一个配置文件。高优先级的配置文件是说，如果配置项目出现在某一个配置文件里面，而其它配置文件里面有相同的配置项目的时候，前者会对程序起到真正的作用。于是Bash里的配置文件中，系统目录是第一读取的，并具有最低的优先级。matplotlib里面，系统目录是最后读取的，具有最低的优先级。世界真是奇妙。 matplot配置文件可以通过 matplot.get_config_dir 得到当前生效的路径，使用 matplotlib.matplotlib_fname() 得到最优先的那个配置文件。 而 matplotlib.rc_params() 用于读取配置文件里的每一项(默认是返回当前使用的配置文件里面的项目)， matplotlib使用rcParams变量保存当前的配置。如果要修改，可以直接令 matplotlib.rcParams[$hash_key] = $value 以让参数成为当前绘图参数。 matplotlib.rc()函数接受一些参数设置并将它写入rcParams变量。如果要恢复默认的配置文件里面的内容，可能需要rcdefaults()选项。 显然matplotlib是不支持直接从matplotlib里面直接修改配置文件里的内容的。因为这些配置文件可能权限比较高，或者干脆就是系统目录下的配置文件，不允许用户修改。 在实际的应用中使用一个库 在python里面导入模块使用import命令。而使用reload(modulename)可以重新加载这个模块(让里面的数据复原)。 中文字体的显示 在matplotlib里面一个是使用Fontmanager选择字体。这对于有些绘图方法特别有用。比如plot()的xlabel()这些函数，都可以接受一个font=可选参数。这个时候选择一个字体属性就可以了。 但是这种方法明显的缺陷是缺乏统一性。如果我们需要绘制多种图，或者需要学习多种图的绘制参数，每一个都要学习就变得代价太高了。所以我们还是用统一的方法吧。 统一的方法是matplotlib的rcParams参数。这些参数让我们选择字体的字族等参数。具体可以通过rcParam.keys()找到。字体大小也可以找得到。如果我们要显示中文。那么我们应当检查以下的做法是否被完成了。 1.虽然Python对于unicode的支持很好。可以直接通过u“”使用unicode字符串。但是这样还是不能够保证直接解析出来多字节编码。尤其是采用unix的magic来运行脚本的时候，编码必须被另外指定。这种方法就是所谓的W3C编码指定方法。 这种方法比较自由，也就是在前面的几行里面出现#-*- coding: utf-8 -*-这样的字符就可以了。下面的编码就会自动被认为是unicode文本并采用了utf-8编码。 2.需要支持中文的字体才能显示出来中文字符。如果没有这样的字体，通常并不是显示乱码，而是是空格或者方框代替。但是一个字体里面总是只包含特定的几个语言里的编码，很少有字体可以包括所有的文本。于是换字体似乎是必然的。不幸的是，Python没有LaTeX那样的复杂的字体种类。同一时间加载的只有一个字体文件。所以我们如果要使用不同字符区域位置的字体，最好还是自己换用字体。 3.系统下使用fontconfig管理字体。大概其它的应用程序也使用了这样的接口，所以可以使用某种字体名，而不需要通过字体文件访问指定的字型。如果我们要改变matplotlib的文件，除了通过fontconfig查询系统字体之外，大概也能够使用fc-list管理字体文件。 4.当将字体嵌入到图表的时候，注意字体的大小。这个是很关键的。对于显示效果有重要的影响。一般而言，如果我们要在图表里面使用字体，一定要确定我们希望图表的输出大小。这个问题在下面的笔记中会讲到。 讲求实际大小在计算机可以自由放缩文本的时候似乎显得有点过时。但是人的眼睛视野大小总是一定的。我们虽然可以放大与缩小图象。但是同一时间内我们的焦点只是集中于图象的某一区域。这个时候采取放大镜的做法也许对我们更好一点。虽然我们可以这么做。但是随意地放大与缩小字体还是缺少一种科学上的价值。我们应该时该记着我们想输出的字体是有多大的。 实际上这些问题大概还是视觉范围的问题。比如我们在看书的时候，因为离得近，虽然很小，但是也能看清楚。可是如果是在屏幕上，那么小的字体就不行了。我们不妨做一个计算。假设我们眼睛离书是30厘米。而字体的大小是11pt。换算成厘米表示，字体的大小就是0.38cm.也就是说，我们平常见到的印刷体也就是0.4cm左右的大小。但是如果是在屏幕上显示，我们的距离变成了80cm.这时的11pt相当于在30cm处看到一个0.15cm大小的块。于是我们可以说，我们的眼睛实际上可以看到小的物体。但是如果我们一直使用较小的字体，对于我们的眼睛也会造成一些压力。大概这就是为什么使用电脑伤害更大吧。 原来自己对于这些东西一直没有什么概念。但是现在才发现问题的所在。那么以后在使用显示屏的时候，就要注意到自己是在多远的距离下看多大的物体。其实距离这么远的话，将屏幕的字体调大一些也是很合理的。 原来的时候自己一直以为在纸上是多大，在显示屏上就应该是多大。这样自己的感觉会好一些。但是今天终于发现，原来显示屏上的内容是不可以相信阅读效果的。但是由于显示屏上照样以11pt的大小显示，那么我也就没有什么办法了。可惜的是，计算机在这么大的时候分辨率不够。 注：业界总是认为高分辨率屏幕没有什么作用。但是它们的确有很大的作用。因为我们通常在显示屏上看到的并不是与看书时文本的大小，所以如果分辨率更高一些，就能够以更华丽的字体显示。而且，图片的大小也可以进行调整。 注：如果我们不使用桌面显示器。那么最终的效果应当是我们每天都在看书。 关于绘制饼状图 也许饼状图在科学计算里面遇到的并不多。但是在人际交流里面用的还是很多的。这些活动包括政治活动，商业活动。反正是在向不是一行的人解释东西的时候很有用。 饼状图调用的是pie()函数，它与plot()函数的作用是类似的。但是pie()函数只给出了一个返回值，而且输出的结果不可进行广泛调整的。比如它就不支持传入font=参数，以致于我们必须得事先设置rcParams. 饼状图在显示比例上是很好的。它的主要参数是一列正则化的数据。是数值类型的。至少可以计算出来一个百分比。一般来说，还需要一列标签文本，以辅助显示。至于阴影线与突出显示，就没有那么重要了。 文档与绘图，是一系列基础的技能。它相当于古代能够写字的人与不会写字的人之间的区别。只有自己能够创造出来这些东西，才相当于有了这样的表达工具，不然就只是一个平平常常，只能从事体力劳动与重复劳动的人。其工作也就不能显示出任何的创造性。 ENTHOUGHT公司的几个科学计算软件 这个公司的软件还是比较难得到的。我们要首先知道git.但是git对于断点续传的支持是很差的，所以我们就要在国内这么差的网络上进行数据的处理了。于是我们就很难得到。但是我们得到以后还得看说明去安装它。为此应当先去构建它。在构建过程中有几个库我们的机器上可能是很难得到的。 现在知道，ETS需要至少需要freeglut,vtk,swig,hg这些软件。但是通常情况下不可能是完备的，于是我们通过逐步测试build的方式解决这一系列的问题。 Cython以及相应的distutils库也是Python所需要的。这些库应当受到足够的重视。 国内的现状大致如此。为了更好地研究一个问题，有时候必须采取一些极端的手段才行。可是这些手段有时候让人追寻了好久好久。最后找到的还是一个不全面的解答。我想自己需要静下来多想一想为什么。 Matplotlib的设置 默认方法仍然是使用.matplotlibrc文件。这样输出的文件比较不错，而且也可以避免在运行脚本的时候花很长时间处理图表参数。 Matplotlib示例 好久没有使用过Matplotlib绘图了，里面的有些东西都忘记了，实在不应该啊。现在是得好好学习的时候了，因为现在及以后会使用很多这样的方法的。 首先是matplotlib的配置问题。这是一个.matplotlibrc文件决定的。配置的方法可以参考matplotlib的官方网站http://matplotlib.org/users/customizing.html。在实际中我们用到的更多的是对于图形的大小的控制。因为我们要输出文件放入到文章当中。其中的选项figure.figsize, figure.dpi, savefig.dpi, savefig.format是在matplotlibrc里面应该指定的。不然每次输出的时候都可能要设置一下，太麻烦了。 折线图 Matplotlib最简单的方法应该是用折线顺次连接起来 \(y\) 轴上的数据了。这个时候 \(x\) 轴对应的坐标就是元素在列表中出现的次序。代码与效果分别如下: #!/usr/bin/env python # Plot a list of numbers with pyplot import sys import re import matplotlib.pyplot as plt plt.plot([1,2,3,4]) plt.ylabel(&#39;some numbers&#39;) plt.savefig(&#39;../img/&#39;+re.sub(&#39;.py$&#39;,&#39;.pdf&#39;,sys.argv[0])) image 散点图 散点图只不过使用了两个数组。另外，还可以接受点的形状作为第三个可选的参数。使用axis选项可以设置坐标轴的显示范围。 #!/usr/bin/env python import sys; import re import matplotlib.pyplot as plt plt.plot([1,2,3,4],[1,4,9,16],&#39;ro&#39;) plt.axis([0,6,0,20]) plt.savefig(&#39;../img/&#39;+re.sub(&#39;.py$&#39;,&#39;.pdf&#39;,sys.argv[0])) image 代码中的ro代表使用红色圆点来表示。与MATLAB有几分相似。其它的选项还有，r-- 代表红色虚线，bs 代表蓝色方块，而g^代表绿色三角形。 import sys import re import numpy as np import matplotlib.pyplot as plt # every sampled time at 200 ms intervals t = np.arange(0., 5., 0.2) # red dashes, blue squares and green triangles plt.plot(t,t,&#39;r--&#39;, t,t**2,&#39;bs&#39;, t,t**3,&#39;g^&#39;) plt.savefig(&#39;../img/&#39;+re.sub(&#39;.py$&#39;,&#39;.pdf&#39;,sys.argv[0])) image]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK与OpenJDK的安装与使用]]></title>
      <url>%2Fplatform-jdk%2F</url>
      <content type="text"><![CDATA[OpenJDK的官网上面的安装手册 在openjdk官网上面的资料http://openjdk.java.net/install/index.html How to download and install prebuilt OpenJDK packages JDK 7 Debian, Ubuntu, etc. On the command line, type: sudo apt-get install openjdk-7-jre The openjdk-7-jre package contains just the Java Runtime Environment. If you want to develop Java programs then install the openjdk-7-jdk package. Fedora, Oracle Linux, Red Hat Enterprise Linux, etc. On the command line, type: su -c &quot;yum install java-1.7.0-openjdk&quot; The java-1.7.0-openjdk package contains just the Java Runtime Environment. If you want to develop Java programs then install the java-1.7.0-openjdk-devel package. JDK 6 Debian, Ubuntu, etc. On the command line, type: sudo apt-get install openjdk-6-jre The openjdk-6-jre package contains just the Java Runtime Environment. If you want to develop Java programs then install the openjdk-6-jdk package. Fedora, Oracle Linux, Red Hat Enterprise Linux, etc. On the command line, type: su -c &quot;yum install java-1.6.0-openjdk&quot; The java-1.6.0-openjdk package contains just the Java Runtime Environment. If you want to develop Java programs then install the java-1.6.0-openjdk-devel package. BSD Port For a list of pointers to packages of the BSD Port for DragonFly BSD, FreeBSD, Mac OS X, NetBSD and OpenBSD, please see the BSD porting Project’s wiki page. JAVA的环境变量设置 当安装好相应的JRE与JDK之后，一般Java的路径位于/usr/lib64/jvm/java-1.7.0-openjdk下面。注意如果只安装了JRE,那么这个目录就只有JRE一个子文件夹。 JAVA_HOME 就是上面的那个目录， JRE_HOME就是前面那个目录的jre子文件夹。一般而言我们还需要设置可执行文件的路径，以及需要加载的库文件。比如另外: export JAVA_HOME=/usr/lib64/jvm/java-1.7.0-openjdk export JRE_HOME=$JAVA_HOME/jre export CLASS_PATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib.dt.jar:$JAVA_HOME/lib.rt.jar export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin 这就就完成的环境配置。一般情况下，还需要执行一下java -version命令调试一下看看是否正常工作了。 JDK的相关的安装 随着版本的向前演变，程序的安装的方式也在不断变化。相对来说，JDK的安装还是比较容易的。我们只需要从官方网站上下载JDK，直接解压到/usr/lib/jvm目录下，然后更新目录即可。 比如下面就安装并配置好了JDK8 sudo bash cd /usr/lib/jvm tar zxvf jdk-8u25-linux-x64.tar.xz -C ./ ##然后配置环境变量 vim .bashrc export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_25 export JRE_HOME=${JAVA_HOME}/jre export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib export PATH=$PATH:${JAVA_HOME}/bin 自从从Oracle收购Sun近三年来，已经有很多变化。早在8月，甲骨文将“Operating System Distributor License for Java”许可证终结，这意味着第三方将不可以依据这一许可分发他们的软件包。因此Ubuntu Linux已经开始禁用所有机器上的Oracle JDK浏览器插件，并很快会从档案中删除软件包。公司指出，禁用Oracle的插件将可以帮助提高安全性，因为这些插件已经被证实包含许多漏洞，虽然这是一个事实，但真正的原因恐怕是Sun的JDK在升级时会清理掉用户机器上自认为不安全的软件，大多数PC用户认为这样很安全，但通常基于UNIX系统的用户并不这么认为。Oracle的JDK被废弃后，OpenJDK将取代它的位置在Ubuntu及其它Linux中默认安装。 虽然很多Linux发行版现在已经自带OpenJDK，但是在开发过程中与Oracle-JDK(SUN-JDK)还是略有不同。通常，Java开发人员还是以Oracle-JDK为标准来进行开发。下面介绍一下Linux下的JDK安装与配置，这里使用的Linux发行版是Ubuntu 12.04。 由于一些Linux的发行版中已经存在默认的JDK，如OpenJDK等。所以为了使得我们刚才安装好的JDK版本能成为默认的JDK版本，我们还要进行下面的配置。 执行下面的命令： sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk7/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk7/bin/javac 300 注意：如果以上两个命令出现找不到路径问题，只要重启一下计算机在重复上面两行代码就OK了。 执行下面的代码可以看到当前各种JDK版本和配置： sudo update-alternatives --config java 注意Ubuntu的update-alternatives机制。它使得我们自己安装的软件也可以被系统很好地识别出来。 Java的版本库的管理 可以用Nexus来完成这件事件，不然Java的库在国内基本上下不来。参考网上的手册配置该应用程序。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux下DHCP服务器的配置]]></title>
      <url>%2FLinux-DHCP%2F</url>
      <content type="text"><![CDATA[DHCP的主配文件便是/etc/dhcpd.conf. DHCP服务器搭建流程分为几步，第一是编辑主配文件，指定分配的范围等。第二就是建立租约数据文件，第三就是启动或重启DHCP服务，使配置生效。 DHCP的工作过程是客户端以广播的方式向服务器申请IP地址(通过接口连接)。DHCP服务器通常本身接口已经配置好IP并在这个接口上启动了DHCP服务。于是服务器根据DHCP的相关配置给客户端提供IP,GATEWAY,DNS等信息。并且DHCP服务器将本次分配信息存入租约数据库里面。 DHCP的配置文件一般从安装源目录的一个dhcp.conf.sample文件得来。该文件包含了适用于服务器的配置，本行的#后面的内容被DHCP服务器视为注释并自动忽略。 DHCP主配文件里面分成参数，选项，声明三种类型。 参数一节表明DHCP服务器如何执行任务，是否执行任务，以及要发送给客户的选项。声明一节用于描述网络的布局，提供给用户的IP地址等。选项一节用来配置DHCP可选参数，都以option关键字作为开始。 先说参数一节里面的重要关键字。 default-lease-time 缺省租赁时间的长度，以秒为单位 max-lease-time 最大租赁时间的长度，以秒为单位 hardware 指定网卡接口类型与MAC地址(假设客户端的信息) server-name 通知给DHCP客户端的服务器名称 fixed-address ip 分配给客户端的IP地址 注意: 在客户端发出分配IP请求的时候，服务器也会根据客户端的信息决定IP的分配。所以在参数一节里面，所提供的hardware相当于筛选出来具有特定特征的客户端，并分配一个指定的IP地址。配置文件是分节的，也有局部选项与全体选项之分。 下面是一些重要的声明: subnet [network_id] netmask [subnet_mask_id] : 该区块用于指明一个网络地址资源名称。表示这些将用于DHCP的相关选项 range [start_ip_addr] [end_ip_addr] : 表明地址池里的动态IP地址范围 host [hostname] : 对主机名下面的DHCP配置，里面通常有hardware,fixed-address等参数 filename [boot_file_path] : 从网络启动时的文件的名称 最后是一些选项: subnet-mask 为客户端设定子网掩码 domain-name 为客户端指定域名 domain-name-servers 为客户端指明DNS的IP地址 host-name 指定客户端的主机名 routers 指定客户端的默认网关 broadcast-address 指定客户端的广播地址 ntp-server 客户端的时间服务器地址 time-offset 客户端与格林威治时间的偏移(时区)，以秒为单位 /var/lib/dhcpd/dhcpd.leases里面保存一系列的租约声明(包括有客户端的主机名等等信息)。 启动的时候按照一般的daemon进行就可以了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[套接字的基本概念与编程]]></title>
      <url>%2F%E5%A5%97%E6%8E%A5%E5%AD%97%E7%BC%96%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[笔记说明： 本笔记属于linux程序设计第四版。第15章关于套接字的内容。貌似之前对于TCP的工作方式有些误解。现在了解了套接字之后才开始明白自己错在哪里了。 套接字是一种通信机制。在这种机制下面C/S系统的开发工作即可以在本地单位工作，也可以跨网络进行。 这个定义并不确切的原因是我从Windows下面开始接触。把UNIX套接字与网络套接字放在一起的做法还是觉得难以接受。毕竟在用途上相差太多了。但是我想事物自有它存在的道理吧。虽然我们都想给用的十分普遍的事物起一个恰当的名称，但是很多时候是不能如愿的。套接字服务就是这样。我们不知道它们可以用到哪些方面，只是觉得它是一种通信方法，至于为什么要这么设计，就不清楚了。 套接字的创建过程 首先服务器使用系统调用socket来创建一个套接字。它是一个系统分配给该服务器进程的一个类似于文件描述符的资源，它不能与其他进程共享。 在实现当中由于都是文件，所以套接字实际上相当于创建一个特殊文件并打开它，这与虚拟设备文件从创建到使用是一个道理。 其中，本地套接字是linux文件系统当中的文件名。一般放在/tmp目录下面。对于网络套接字，则是与客户连接的特定网络有关的服务标识符（端口号或者访问点）。这个标识符允许我们进入针对特殊端口号的连接转到正确的服务器进程。 系统调用bind用于给套接字命名。然后服务器进程就开始等待客户连接这个命名的套接字。系统调用listen的作用是创建一个队列并将其用于存放来自客户的进入连接。服务器通过accept系统调用来接受客户连接。 当服务器调用accept的时候，它就会创建一个与原来的命名套接字不同的新的套接字。这个新的套接字只用于同这个客户进行通信。而命名套接字则留下来继续处理来自其它客户的连接。一旦连接建立，我们就可以像底层的文件描述符一样利用套接字实现双向通信。 第二次创建新的套接字是自己以前没有想到的。现在想来，大概在网络环境下创建套接字的时候，由套接字函数库对于连接进行了封装，以致于在服务器调用accept的时候，只能得到连接到它的套接字，这也就是说，在内核当中已经处理好来自不同IP+PORT的请求。从而自己实现了数据的分流，最后才把数据交到socket函数库。 创建一个套接字的函数原型是： #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int socket(int domain, int type, int protocol); 其中domain是套接字的类型，它可以是AF_UNIX,AF_INET,AF_INTE6,AF_IPX,AF_PACKET等等。type则是套接字的封包格式，比如SOCK_STREAM,SOCK_DGRAM,SOCK_RAW等。我们使用的IP中TCP封包格式为AF_INET加SOCK_STREAM.而UNIX套接字则选择AF_UNIX加SOCK_STREAM.最后一个protocol通常取0.而返回的整型值是套接字描述符。 绑定一个套接字的函数原型是： #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 函数的作用是将一个名称与套接字相绑定。之所以要进行绑定，是因为刚开始创建套接字的时候只是指定了在套接字命名空间中注册了这个事物。但是还没有被注册到一个确定的地址。所以我们通过bind函数向该套接字命名。名称由结构体addr指定，后面的addrlen是结构体的长度。在sockaddr当中，包含有关于套接字的一系列说明。 连接一个套接字的函数原型是： #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 其中的各项参数应当与前面所创建的套接字相匹配。返回动作的状态。 接受一个套接字的函数原型是： #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 它返回一个新的针对于该客户端的套接字。 之后对套接字的读写使用read,write或者close调用就可以了。（因为套接字描述符属于文件描述符。）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Lapack矩阵运算库]]></title>
      <url>%2Flibrary-lapack%2F</url>
      <content type="text"><![CDATA[所打印的《the lapacke interface to lapack》原来来自于大二时候学习使用LAPACK软件包，但是FORTRAN语言本身又比较复杂，因而寻找一个外在的接口函数库而找到的。不过事实上它没有发挥过什么作用，仅仅被看过一遍就被遗忘在角落里面了。现在为了把无用的东西都扔掉，整理一本笔记。 lapack原来是用FORTRAN语言写成的，后来C语言得到了广泛的应用，所以创建了面向C语言的接口，尽管可能完全重写更有可能得到更高的效率。于是到现在我们就得为了使用lapack而学习如何使用接口。 面向C语言的接口还分成两个层次。对于开发者来说，两个层次的最重要的区别是内存管理是否需要手工进行，对于调用者来说，则转化成命名的前缀与后缀的问题。其实较低级的程序员一直都很难避免陷于各种移植，各种前缀当中。 lapack的高级接口由内部的库负责内存的管理。但是中级的接口则是需要用户向一系列的库函数传递数组。两种接口均各自提供行主与列主的版本。主要数据类型与主要函数的声明都放在lapack.h文件里面。 高级接口的命名方式是在FORTRAN程序集名称上加上前缀 LAPACKE_ ，而中级接口则是加上相关的前缀的同时加上 _work 。注意在C语言接口中函数都使用小写的名子。 数据类型 （我们知道浮点数是有相应的IEEE规范的）。复数类型在C语言里面分别对应于 lapack_complex_float , lapack_complex_double。在实现中要，复数单精度浮点类型实际可能使用的是C99复数类型，可能是C语言的结构体，也可能是CC的STL模板。具体定义就要见lapacke.h了。 在lapack当中，向量是自动决定是行向量还是列向量的。但是矩阵就不一样了。矩阵的行主或者列主在传递参数的时候要通过LAPACK_ROW_MAJOR 或 LAPACK_COL_MAJOR来指明。在函数调用规范中，如果一个矩阵在经过此函数处理的时候是行主或列主的，那么其它的矩阵也要保持相同的定义。 注意使用行主的时候会比列主消耗更多的内存，因而花费更多的时间。在计算过程中行主的矩阵会转成列主的形式参加计算。（这种转换发生在向LAPACK传递数据之前。） 每个LAPACK的返回值被放在 lapack_int类型的数据中，其名称为INFO。和其它的库函数类似，我们经常得检查是否被调用的函数发生了异常，以及发生了何种异常。 错误号在LAPACKE与LAPACKE当中数值序号是相同的。 在LAPACKE高级库中有一个NaN特性，允许在调用LAPACK之前进行参数的检查工作。这种检查之后，相应的结果会在INFO变量中表现出来。通过指定LAPACK_DISABLE_NAN_CHECK 我们可以禁止进行这种检查。 FORTRAN的整数INTEGER类型一般情况下被转成 lapack_int 类型。后者又进一步变成相应的标准整数类型。但是这带来一个C语言的规定性问题。如果在一台机器上C语言整数是4bit，那么它就只能调用4bit的整数。 FORTRAN中的LOGIC类型会被同样地转成 lapack_int 类型。在LAPACKE库当中，为一系列的错误定义了枚举值。可以通过相应的名子在源代码中检查是否出现了相应的错误。 FORTRAN中函数的命名规则 使用单精度实数作为输入参数的函数以s为标识，又精度以d为标识，单精度复数以c为标识，而双精度复数以z为标识。 不过还是有一些使用混合类型的运算方式。 LAPACKE调用示例 函数调用的方法是首先使用相应的类型声明整型，然后声明使用的相关的矩阵。注意在LAPACKE当中需要使用一维数组按照行主或者列主的方式存储相应的矩阵，而不是使用指向指针的指针。 计算列主矩阵的每行元素有lda个的元素的QR分解可以参考下面的例子： lapack_int m, n, lda, info; double *a, *tau; info = LAPACKE_deqrf(LAPACK_COL_MAJOR, m, n, a, lda, tau); 其中各个元素的含义是矩阵A的行数是m,列数是n.行列式中的每一个元素是lda个（真不知道设计leading dimission有什么作用）。 当使用中层接口的时候，我们要使用存在于LAPACKE内部的内存分配与释放函数了。它们分别是 LAPACKE_malloc 与 LAPACKE_free。不过在这种情况下我们也不用自己 调用内存分配函数，这些分配与释放会由相应带work后缀的元素自己使用。 其实我们应该记住LAPACKE中不使用C语言提供的多维数组就行了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[cups打印服务介绍]]></title>
      <url>%2Fservice-cups%2F</url>
      <content type="text"><![CDATA[摘自鸟哥的linux私房菜基础篇，来源自第二十一章，除此之外也参考了cups的官方手册。 发行版一般自带了相关的配置工具，不过随着unix上服务的标准化，现在unix的打印服务都只需要cups来管理了。现在新版的发行版，都是由cups负责打印。 unix上的打印一个是本地打印，另一个是网络打印。unix的支持都是很好的，并且都能通过cups简单地完成。 unix打印支持 要使用打印机，不仅要BIOS的支持，而且还需要unix系统的支持。其中的原因是，老式的打印机使用的是25针串口，此接口必须的BIOS中设为开启状态。至于系统，则是打印机制造商得提供相应的打印机驱动，unix才能使用该型号的打印机。 HP打印机对unix的支持程度很好，所以多选择HP品牌的打印机。 系统对于打印机的支持情况可以参考&lt;www.linuxfoundation.org/en/OpenPrinting&gt;里面的一个支持列表。 打印流程 打印过程中文档从文件经过格式转换被发送到打印机。由于打印机的工作的时候只能一份一份地打印，于是就产生了一个打印队列，在打印机工作时依次从打印队列中选择一份待打印的文档进行打印。 在系统中一个打印机拥有一个打印队列。打印队列一般以打印机的名子命名。将队列内的打印作业转成打印机识别的格式，交给打印机输出的程序称为打印服务。打印服务显然要认识与沟通打印机，因此就得连上打印机与驱动打印机。常见的打印服务有CUPS与LPRng,不过以CUPS为主流。 所谓的打印机驱动程序其实就是将打印作业数据转成打印机格式。Postscript是常见的打印格式。CUPS支持这种打印格式。打印驱动程序因此有很大一部分都是Postscript打印机描述档案（PPD）。 那么，是否打印机支持Postscript后，不同打印机驱动程序所完成的工作就大体上类似了呢。 如果没有PPD档案，我们可以使用Ghostscript解释打印作业数据以让打印机认识该格式。这样仍然可以顺利进行打印。 PPD驱动程序一般放在/usr/share/cups/model下面。需要的话还可以自己从上面的打印支持中下载所有的PPD档案。 CUPS的打印支持 CUPS支持联机打印。常见的打印分享方式有若干种。一种是socket方式。这种情况下使用的是internet套接字，端口一般为9100或者35.实际上可以通过输入端口socket:/host-printer:9100向打印机传送数据。另一种是LPD方式。LPD是较早出现的打印服务，LPDng就是使用这种方式实现联机打印。利用的是串行端口。还有一种是IPP方式。它是现在比较流行的打印机打印协议。CUPS预设也是这种方式。IPP启动后打印机会启动631端口，打印数据透过这个端口传送。 打印机或者unix主机启动IPP后可以直接使用浏览器输入 ipp://printer_ip//printername 或者 http:/printer_ip:631 直接在线处理打印机设定。最后一种是SMB。协诉使用的是smb://user:password@host/printer。 设备连接以后使用相应的接口进行标识。平行串行端口一般作为/dev/lpN出现，在CUPS里使用parallel:/dev/lpN来访问。USB打印机使用格式为usb:/dev/usb/lpN. 网络打印 管理unix打印非常简单。只要启动CUPS之后，就可以通过浏览器接口进行管理了。不过要注意，用户必须启动CUPS服务，且需要root权限，默认情况下只能通过localhost管理CUPS服务，也就是不能通过网络访问CUPS管理界面。 配置过程。如果要通过网络进行打印，首先通过打印机手册设置好打印机IP地址。然后在主机上使用ping检测打印机IP可连通。之后在主机上启动CUPS服务。成功标志是存在cupsd服务，并且cupsd监听了631端口。之后打开浏览器进行cups和管理界面。 在管理界面下进行设置打印队列名，添加打印机等工作。其中关键是设置队列名，所使用的打印服务，打印机型号以及打印机所在的URL地址。 如果没有相关打印机型号的驱动，其实只需要提供好合适的PPD文件就可以了。一般没有出现这个型号时，使用Postscript的PPD文件。之后还要输入root密码。 通过管理界面设置一般USB打印机过程类似。在进行这一过程之前要求我们已经知道打印机的设备名称。知道名称后如同上面的步骤添加打印机。不过，在选择打印机服务类型的时候选择本机设备。（一般有usb之类的字符。） 这样一来本机上的CUPS只为本地文件提供打印服务。如果要进行更改，还要进入CUPS管理界面，以设置允许其它主机访问。设置完成后，本机的CUPS就会提供一个供打印用的URL地址。这个URL就是其它主机访问打印机的方式。 上面都是自动配置方式。如果手动，则主要包括手动设置CUPS配置文件，设置打印驱动程序。 打印机管理 可以通过管理界面进行设置，也可以通过CUPS提供的lpadmin命令。lpadmin的实际作用只是管理打印机与管理与打印机关联的打印队列。 lpstat是CUPS提供的观察打印状态的指令。可观察的类别有打印机，打印队列，工作状态，CUPS状态，以及其它更为详细的信息。 在真正进行打印时，lp,lpr,lpq与lprm也许最为有用。它们可以管理用户的打印队列。 如何打印 要打印的文件的页面方向，纸张类型，缩放系数，文件名都可以通过lp命令设置。而且lp命令支持一些图片文件如JPEG格式的直接打印。 查看打印机PPD所支持的格选项可以使用lpoptions -p print -l 命令。打印机会知道它所支持的打印格式。通常都能使用PDF,PS,文本文件格式。 配置虚拟打印机 一般情况下我们使用真实打印机进行打印。此外suse上提供了默认的到PDF与PS格式的输出，这样也可以产生相关格式的文档。通常情况下，应用程序如果有到PDF格式的输出，应该使用应用程序提供的PDF输出功能，然后由实际的打印机打印PDF或者PS文档。但是如果应用程序没有这种功能，则我们可以使用虚拟打印机完成这一工作。 CUPS打印体系本身就已经允许发送到打印机的文档重新定向到某个文件里，但是这样还是比较麻烦。我们不想让CUPS负责由PPD处理输出的格式发送到文件里的话，可以使用虚拟打印机程序。这样一来，由这个虚拟打印机自动负责输出的位置。 广泛使用的一个工具是cups-pdf.这个程序非常地小。下载源代码之后，按照说明编译与安装程序。过程大致为，编译源代码，复制到CUPS的backend目录里，然后将conf复制到/etc/cups里面，以cups-pdf命名。再之后把代码包里的PPD文件复制到打印模块目录下。最后重新启动cups服务。添加打印机，型号选择Virtual PDF Printer.之后的配置，比如默认页面，输出文件位置等，参考cups-pdf.conf文档。 虽然给出了这个方法，但是我们还是把它作为最后方法，如果应用程序支持直接输出PDF或者PS格式，还是应当由应用程序产生，这样的质量一般比较高一些。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[周期性进程与crontab]]></title>
      <url>%2F%E5%91%A8%E6%9C%9F%E6%80%A7%E8%BF%9B%E7%A8%8B%E4%B8%8Ecrontab%2F</url>
      <content type="text"><![CDATA[周期性进程这一部分的内容需要很多的实践才能看出来。所以这里也就仅仅是学习周期性进程的管理方式，做一个理论上的理解。实际以后当然还是需要很多的锻练的。 系统管理员应当让更多的任务能够自动完成以减轻系统管理的压力。为此应当选择适当的辅助工具。首先是能提高管理效率的系统命令。比如使用adduser来代替手动向系统中添加用户。其次是使用各种各样的自动脚本完成管理任务。这种情况下就要建立所谓的系统管理工具集或脚本集之类的工具了。然后我们也应该使用自动运行或者计划任务，以让我们有一个充分的休息机会，让那些经常重复的工作变成计算机自动会完成的工作。 关于cron工具 unix下周期执行的任务一般由cron这个守护进程来处理。在系统工作的时候它通常都会保持运行。cron在工作的时修读取一个或多个配置文件，并启动sh来完成其中的任务。因此差不多所有能够手工从shell完成的任务都能通过cron完成。 cron最初出现在20世纪70年代的UNIX家族中。linux发行版本所带的cron称为ISC cron或者Vixie-cron.它是由Paul Vixie重写的，并提供了许多新的功能，减少了使用cron遇到的麻烦。 cron的配置文件称为crontab.cron在三个地方查找crontab文件。/var/spool/cron,在SUSE上是/var/spool/cron/tabs./etc/cron.d和/etc/crontab.每个用户的crontab文件都保存在/var/spool/cron目录下，以用户的名称命名。一般每个用户只能有一个crontab文件。cron会使用文件名作为运行命令时所使用的UID. 计划任务需要权限的限制，以使得普通用户多数时候只在其登录期间有对于计算机的使用权限。更多时候，计划任务作为系统管理的手段。 在/etc/cron.d以及/etc/crontab里的文件格式与用户的crontab文件略有不同，因为前者允许以任何身份执行命令。/etc/crontab供系统管理员手工维护，而/etc/cron.d里常存放软件包所需要的crontab项目。 cron启动时检查它的所有配置文件（但cron一般随系统的启动而启动），并把它们保存到内存当中。每一分钟cron就会醒来一次，检查crontab的修改时间，并重新载入有修改的文件。然后在返回睡眠状态前执行这一分钟安排要执行的所有任务。 cron通过syslog为它的活动做日志。 crontab文件的格式 crontab文件中以#开头的行代表注释。每个非注释行包括6或7个字段，它代表的含义为： minute hour day month weekday [username] command 前六个字段都会用空白分开，但是到了command后，所有空格都算在command里面。用户自己的crontab文件中没有username项。 日期与时间格式会在很多地方用到，所以得有一个全局的思维才行。一般来说，首等应清楚表示的区间在一天以内还是一个比较长的日期。其次要确定所表示的地区。另外就是从大到小还是从小到大。我们可以这样进行分类： 时间内有时分秒，表达一天内的时间。次要的标准有时辰，早中晚等； 日期内有年月日。次要的还有星期，公元； 时区则是要遵守国际相关的规范了； 按表示顺序，有从大到小，也有从小到大，crontab里就是从小到大。 crontab每的时间字段中可以采用数值表示，可以使用通配符，可以用逗号，也可以用范围，表示的是“或”的关系。因为cron的含义即是这一分钟要不要运行该程序。crontab中的命令可以使用百分号作为换行。不过为了简便，用一个shell命令还是很好的。 更多细节见手册页crontab(5). crontab的管理 crontab filename用于把文件安装为crontab文件。它将替换用户原来的版本。更多的用法参考crontab命令帮助。 特别提醒的是，直接使用crontab命令将会要求用户输入crontab.如果这时使用C-D会覆盖掉原来的配置。因此一般要使用C-C来终止crontab程序，以免用户覆盖。 /etc/cron.allow与/etc/cron.deny这两个配置文件用于限制用户提交crontab文件的权限。有allow的时候先通过allow里的用户，未通过则禁止用户登录。无allow文件时查deny里的用户。如果都没有，就会采用cron默认的设置。在大多数系统下，默认只允许root提交crontab.因此既不在allow又不在deny里的用户会被禁止提交crontab文件。 cron的这种设置与acl还不同。在acl中，中间过程只有肯定权，没有否定权。 分析crontab程序的权限也比较有意思。可以知道它是一个setuid的程序。实际运行的时候用户是root. 为了方便管理，通常还在/etc下建立了cron.daily,cron.weekly等脚本。里面的文件会自动每天或者每周运行一次（只需写好相应命令即可）。 cron的通常用法 使用cron非常要求对系统有某种程度的理解。在unix下文件的删除工作往往得自己完成。此外，在网络环境中分发配置文件也常通过cron完成。然后，有些日志文件得自己完成分割。 其它日程安排程序 其实日程安排要比日程安排程序更好理解一些。一个好的日程安排程序关键是能不能表达日程安排的某种逻辑。相关的替代软件有anacron和fcron等。 日程安排思考 计划任务在Windows下是和开机启动混合在一起的。但是unix经常很长时间不关机的，于是就采用了开机脚本和计划任务相分隔的做法。不过因为cron守护进程一直在运行，用户当然也能够很容易地编写一个脚本运行相关的任务。比如使用一个咨询文件就可以办到只在开机的时候运行一次。我们很显然能发现。一旦计划任务程序开始运行，只要相关的脚本能根据系统状态作出某种反应，把日程安排改造成开机启动也不是一件困难的事。 习题与思考 在此次学习中，我们并没有接触到cron的配置。因此关于性能的很多问题都没有涉及到。实际上如果同一网络多台主机同时运行cron时可能会造成一些问题。所以建议cron通过调用脚本间接调用程序。而脚本里有诸如sleep 5这样的代码。 关于管理crontab的权限 一般来说一个用户因为使用不合理的crontab文件。系统管理员应当删除其crontab文件并禁止它的crontab权限。 盲目地复制一个文件夹下以.开头的文件安全么 这个当然是不安全的。一个目录的inode里包含自己和它的父目录。如果我们这样复制文件，就会使得所复制的文件追溯到它的同级目录里。 系统分析的一个应用 cron经常会和邮件系统结合在一起。除了在完成计划任务时把输出发到用户的邮箱，它还可以让用户自己通过shell发送自己感兴趣的内容。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Linux下的日志记录及其策略]]></title>
      <url>%2FLinux-Log%2F</url>
      <content type="text"><![CDATA[本章标题是《系统日志与系统文件》。因为日志在系统当中的确占有非常重的地位。原来自己没有接触过关于syslog与logrotate等工具，所以在查看日志的时候用的只是非常基本的功能。但是按照自己的需求。以后自己也要学习更多的日志分析技巧，如果要学习网络的话。 日志通常如一条一条的概要，由某个应用程序产生并提交到特定的日志系统去处理。有的日志系统比较简单，或是由应用程序服务自动管理。但是更多的时候，需要在系统范围内才能分析出日志包含的重要信息。 日志文件因为它所反映的信息类型的不同而不同。因此需要各自对待。 虽然在操作系统编程与应用程序编程，或者网络编程中也常用到日志，但是日志的最核心的功能还是在于为系统或者应用管理员提供足够的信息，以便支持某种决策。这样一来，在编程中使用的日志只是提供一种基础设施。只在站在系统管理的水平上，我们才能利用好日志记录。 几种对待日志的策略 一般情况下应用程序已经配置好所产生的日志级别。一旦日志产生就进入到日志管理这一主题之下。通常情况下，日志可以分成保存的日志与立即的日志。后者又有立即扔掉与在内存区域中缓存，或者在终端上显示。前者则可以选择转发到另一地点或者在本地保存。 计算机管理系统环境下，一般产生意义的动作只是立刻扔掉，或者定期复位，或者采取轮换，或者将日志压缩或保存到永久介质上。它们的不同完全可以由日志信息存在与时间的函数关系决定：前者总是取零，定期复位使得可追溯的日志像周期函数一样变化；轮换则是一个单调递增，而后保持不变的函数；后者则是一个不断增加的函数。 在unix下无论何种方案，都必须采用cron自动维护日志文件。 关于扔掉日志 一般来说不应当扔掉所有的日志信息。因为日志文件首先为站点提供了非法入侵的重要证据。其次还有助于分析有关硬件或者软件方面的问题。《手册》中给出的意见是所有日志到少保存一个月的时间。特别是站点环境下，可能需要很长时间才能发现入侵。此时需要退回很长时间才可以找到入侵时间。并且还需要以压缩形式保存更长时间的日志。 不过有些时候保存日志的策略有一定的政治，法律或者商业上的原因。这就得具体问题具体分析了。不过留下日志总能够提供某种分析手段，至少能够使得对事物的认识更加具体。 轮换日志文件 这种做法通常是把每周或者每月的日志信息保留在一个单独文件里，就像维护一个长度有限的队列一样。 对于一个日志文件来说，其属主通常很重要，决定着日志管理时的权限使用。日志文件的命名可以使用序号区分，也可以使用日期。在unix上可以通过date命令的+%Y.%m.%d 格式就是通常的做法。 在轮换日志的时候可能会遇到日志正在使用的情况。这种情况下正在使用的日志文件会因为文件位置的改变而自动改变。通常的解决办法是在移动日志后重新启动守护进程，以让守护进程使用新的，空白的日志文件。 比如向syslogd发送HUP信号就会导至syslogd守护进程挂起然后重新读取日志。 存档日志文件 “除非就是要避免留下书面记录，否则就应该在常规备份中包含日志文件”。并且在转储频度允许的情况下以最高频度备份日志文件。此外。我们可以为日志文件专门设计一个备份脚本以直接对日志备份进行控制。 linux日志文件 linux系统的软件包一般将其日志记录到/var/log下的文件里。 /var目录是相当重要的。在正常运行的系统里应该都存在。因为里面还会随时写入很多信息，因此应当以读写方式挂载文件系统。 linux下大多数程序将其日志发送到syslog中央系统。由syslog负责将日志写入文件或者进行转发。总之，应用程序只需要把产生的日志信息提交到syslog就可以了。 日志权限需要管理员仔细衡量。这些权限中查看权限或许最为关键。一般而言黑客会特别照顾日志文件。大多数文件因此应当设置成权限600. /var目录应当是所有用户都有权限访问的。但是用户不能在/var下删除log/目录。用户查看log/里面的内容也是允许的。但是用户不一定能查看具体某个应用程序的日志。 专门为日志文件建立一个组，以使得组里的其它成员有查看它的权限也是不错的。注意这里只是说日志属于某个组，而不是日志属于某个特殊用户。一个用户可以属于多个组，通常从组中得到的权限是各个组之和。 从一个具体的应用程序到日志文件的过程大致是，应用程序首先得使用syslog程序，这样以来就可以把日志提交到syslog系统。这一过程中得保证运行应用程序的当前用户或者进程有向syslog提交日志的权利。然后就是由syslog负责整理日志了。由于syslog是以root的身份执行，因此它总能创建出日志文件，后续的行为只需要chgrp命令修改日志所属组就可以了。特别是修改日志文件所属组的行为可以通过syslog完成。 系统日志的层次安排 /var/log下的常见日志 一般来说secure,auth.log与sudo.log文件都不应当由一般用户查看。除了读限制，应当禁止除了属主外的任何人对日志文件的写权限。 一般来说： auth.log 由su等程序产生，负责授权 boot.log 系统启动脚本的输出 boot.msg 内核消息缓冲的存储 cron cron的执行情况与出错信息 cups 与打印有关的信息 daemon.log 所有与守护进程相关的信息 debug 调试输出 dmesg 内核输出消息的缓冲 dpkg.log 软件包管理日志 faillog 不成功的登录企图 messages 经常是系统日志文件 secure sshd,sudo等，保密的授权信息 syslog 主要的系统日志文件 warn 所有的警告级与出错级消息 wtmp 二进制记录的所有登录记录 yum.log 软件包管理日志 具体文件因系统不同而有差异，并且因使用的系统日志守护进程的不同而有异。 内核和启动日志 内核的日志机制是通过让内核把它的日志项保存在一个大小有限的内部缓冲区来做到的。缓冲区具有适当的大小，既足以容纳内核引导是产生的所有消息，又要节省内存用量。一旦系统启动完成，用户进程应当能够访问内核的日志缓冲，最终处理其内容。各个发行版本一般使用dmesg命令并将其输出重定向到/var/log/dmesg.（因发行版而异）。 内核当前运行的日志是通过klogd内核线程处理的。在正常运行方式下，klogd将内核产生的日志发送到一个文件或者syslog守护进程。一般情况下syslog依照kern中的规则处理这些日志，并将其发送到/var/log/messages文件。 dmesg与klogd都有一个选项可以设置内核控制台的日志级别。这实际上是同内核进行对话。如dmesg就使用了-n选项。内核的日志级别分为7级（第7级称为调试级，输出最多）。 启动脚本的日志可以没有内核日志机制做得好。 日志管理与分析工具 logrotate logrotate用于管理日志文件，它的基本功能也就是作为一个过护进程，定期检测日志文件并对日志文件进行转储的操作。一般情况下在/etc/cron.daily下都可以发现logrotate这一个文件。也就是logrotate的计划任务。 原则上说logrotate应该在syslog之后讲述。不过我们可以把logrotate仅看成是一个定期分隔文件的程序而不去管它分隔的是怎样的文件类型，这才是它的功能的完整的应用领域。 前面我们说了logrotate在cron.daily下面定期运行。实际上在crontab中运行它的命令以及参数是 /usr/bin/logrotate /etc/logrotate.conf 2&gt;&amp;1 | tee $TMPF 所以我们知道它的功能是读取logrotate.conf文件并执行。 在该crontab文件下还执行的功能是，如果logrotate异常退出，就向syslog发送一个logrotate运行失败的cron.warning消息。 所以接下来就要学习logrotate.conf的配置了。 logrotate的主配置文件是logrotate.conf,但是在该文件中有一条命令是 include /etc/logrotate.d 所以在目录下才是针对每个程序的配置。主配置文件一般参考logrotate(8)。 针对某些文件的配置格式为： ${path_match} { ${rotate_command_list} } 表示对某一个配置文件执行哪些操作。 实在不想再学习logrotate的配置文件了。又得学习一种配置语言。想写的时候参考实时手册页就可以了。 syslog日志分发程序 系统事件日志程序 syslog最初是由Eric Allman编写的一个综合日志记录系统。syslog具有两个重要的特性。首先它能让消息按照其来源和严重级别排序；其次是能够把消息送到各种目的地，包括日志文件，用户终端，甚至是其它计算机。这给予syslog以极大的灵活性。 尽管如此syslog也有一些缺点。所以已经开发出几种替代方案。比如syslog-ng.以及圣地亚哥超级计算中心的sdscsyslog.除此之外，SUSE上使用的是rsyslog. syslog的体系结构 syslog由三个部分组成。其一是syslog守护进程，其二是库调用，其三是logger提交日志的命令。 syslog在系统启动后连续运行。懂得syslog的应用程序把日志发送到/dev/log文件，然后由syslog守护进程读取消自息并根据配置文件分发信息到目的地。syslog接受挂起信号并解释为重新打开配置文件；同时接受TERM信号并使守护进程退出。 syslog守护进程还会把它的进程PID写入到/var/run/syslogd.pid文件里。这使得向它发送信号变得比较容易，如： kill -HUP $(/bin/cat /var/run/syslogd.pid) 因为logrotate就经常要求syslog重新读取相关的日志文件。 守护进程使用/etc/syslog.conf配置文件。 其它的syslog程序通常也支持类似于syslog.conf配置文件里的语法。 配置文件的基本格式是： $selector $action 其中$selector的基本格式为$facility.$level.表示的含义是属于这一类别的某个等级的日志将会采取$action所指定的行为处理。$facility与$level都是由syslog规定好了的取值范围。一般情况下，比如cron代表来自cron的日志，daemon代表来自系统守护进程，而kern代表来自内核，local0-7代表来自本地的8种类型，user代表来自用户进程，syslog代表syslog内部消息。级别从低到高依次是debug, info, notice, warning, err, crit, alert, emerg.这些级别的具体含义由用户安排。 facility支持使用星号通配。 $action可以是一个本地文件名，或者@hostname,或者@ip,或者用户列表，或者fifoname,或者*(代表所有用户)。在$action前面加一个短划线代表写入文件后不执行sync命令。syslog对待一条日志的行为类似于一个匹配器。前面说到$selector的格式。实际上syslogd还支持语法糖的形式，允许一条匹配应用多个规则。分号表示取并区间。 具体来说$f.$l表示$l及以上，$f.=$l表示只匹配该级别， s1;s2表示选择器取并，在s1及s2之间。 syslog守护进程在启动时默认是不接收其它机器的消息的，除非是以-r选项启动的。并且syslog如果从网络接收到一条日志，无论符合哪一$selector都不会转发，除非使用了-h选项。开机时候的syslog选项可以从/etc/init.d/syslog里配置。 站点设计方案 在一个小型站点中重要的系统错误和警告保存在每台计算机的文件当中就可以了。但是在在个大型的网络中必须有中央日志记录。有了中央日志记录的话，大量的日志信息就会处于可管理的状态，而且运气好的话还能使破坏计算机安全的人无法访问到审计数据。（这要求站点级的防火墙禁止从外部向syslog提交信息。） 一般来说选择一台稳定的机器作为日志记录服务器，并且最好有很好的安全措施而且登录用户不多的一台机器。其他的计算机可以使用保存在中央主机上的通用配置文件。这样一来只需要维护两份不同的syslog.conf文件。 syslog服务器应当具有足够的安全性。其安全性可通过防火墙对于连接的控制，以及系统管理员访问的途径体现。 syslog应用 有许多程序或守护进程使用了syslog系统。并且通过logger命令，一般脚本也可以向syslog发送某些信息。如果要了解可详细的信息，可能需要查找POSIX相关规范。 logger的通常用法是 logger -p $selector &quot;${messages}&quot; 该命令可以用于调试syslog.方法是先在配置文件中添加一个指令选择器的地址，然后使用logger向该选择器写入指定的信息。 在应用的时候都忽略了权限的问题。但是我们应该知道让任何人都有发送日志的权利也是不应该的。 日志分析工具 比如swatch, logcheck, logwatch.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux下的守护进程]]></title>
      <url>%2FLinux-Daemon%2F</url>
      <content type="text"><![CDATA[守护进程的一般概念 系统提供某某服务，而提供服务的进程称为是守护进程（用英文说一个是service, 一个是daemon.） 也就是说从操作系统的观点来看，是守护进程，从IP网络的概念来看是服务。从应用的角度来看是服务。 也许可以把守护进程看成是一种持续监听某个端口的应用程序。这样以来它就总能够提供某种服务，也就不必是系统进程。也不必非是以root身份运行的程序。 unix下的守护进程分为独立守护进程与超级守护进程。在英文中一个是standalone daemon,一个是super daemon.如果一个守护进程的作用是管理其它的守护进程，那么它就超级守护进程。这种分类方法更倾向于在功能上对守护进程进行分类，是一个静态的概念。而根据运行方式的不同分成独立运行方式，与被管运行方式。 被超级进程所管理的守护进程称为被管守护进程。其执行的原理是，超级守护进程常驻内存，当有某个端口的连接操作的时候根据配置启动某个守护进程处理连接请求。超级守护进程特点是统一管理连接，而运行起来的速度比较慢，因为一次连接之后往往要求被管守护进程退出运行。 守护进程按照工作状态分为定时执行的守护进程，与信号守护进程。后者指服务被连接请求信号所触发。 守护进程所守护的不一定是网络，也可能是本地的某种服务，如打印服务。 在IP连接上，服务与端口号的对应在/etc/services中写出。每行#之后的内容作为注释，非注释行标明了对应关系，格式是： &lt;ApplicationLayerProtocol&gt; &lt;port/TransmissionLayerProtocol&gt; &lt;introduction&gt; 守护进程一般需要执行档案，配置文件，运行环境这些条件。 进程运行的PID在/var/run目录下保存。 开机脚本 守护进程一般都不是手工进行控制而运行的吧。所以要学习开机脚本的原理。 开机脚本实际上是Shell文件，具有执行权限。标准的开机脚本都放在/ete/init.d/目录之下（不是子目录）。初始配置不在/etc目录下，而是在/etc/sysconfig当中。超级守护进程xinetd的配置文件位于/etc/xinetd.conf.而被xinetd所管理的进程连接配置放在/etc/xinetd.d目录之下。各自的配置文件在/etc目录之下。各个服务产生的数据会写在/var/lib的相应目录下面。各进程的PID记录在/var/run下的PID文件当中。 开机脚本以服务名作为脚本名。规定当什么参数都不加的时候，脚本文件返回所有可用的参数。一般参数会有start,stop,status,restart等。语义和单词意思相同。可以通过直接控制脚本管理服务进程。但是也可以通过service脚本统一进行管理。貌似优势就在于不用输入脚本文件所在的路径。 被超级守护进程所管的守护进程的配置主要在 /etc/xinetd.d/* 下进行，每一个文件代表一个服务。比如rsync守护过程就是由xinetd来管理的。配置文件作为一个小节出现。格式如下： service ${service_name} { ${configurations} } 其中每一个配置都是一个var=value的形式，之间可以有空格。全局配置文件在xinetd.conf当中，括号开头是defaults. 其中的等于号可以换成是+=,-=,分别表示加入新参数，减去新参数。 注： 如果既有在xinetd当中的配置，又有自己的配置该怎么办？ xinetd的配置 以下是在/etc/xinetd.conf当中进行的配置。 xinetd当中也有log_type, log_on_failure, log_on_success.这些选项，不过记录的不是被管守护进程的运行日志，而是xinetd启动它的日志。 cps = 50 10 在一秒内的最大联机数为50，若超过数量，暂停10秒 instances = 50 同一服务的最大同时联机数为50 per_source = 10 来自于同一来源的客户端的最大同时联机数为10 v6only = no 是否只是允许IPv6通过 includedir /etc/xinetd.d 详细的设置查这个目录。 以下是在具体某个服务当中的配置，当有同名的全局设定时，全局设定被覆盖，加上，或者减去。 disable = yes | no 是否禁用服务 id = 服务的标识名 一般与启动进程相同 有时候同一进程通过不同的参数可以提供不同类型的服务，所以有必要对启动的进程名加以修改。 server = 服务所使用的守护进程 server_args = 服务所使用的守护进程启动时的参数 user = 服务启动时使用的UID,当xinetd是由root启动的时候，被管守护进程才能以其它身份启动 因为在linux如果xinetd是root,那么它所fork出来的子进程能够改变UID. group = 服务启动时使用的GID,也是当xinetd是由root启动时才有效 socket_type = stream | dgram | raw 封包时所使用的机制，stream实际代表了TCP,而dgram代表了UDP,而raw代表server要直接与IP层交谈。 怎么在IP层直接交谈？ protocol = tcp | udp 和socket_type 的意思相同，两者使用一个即可 wait = yes | no 是xinetd连接的进程可以加载多个，还是同一时间内只加载一个 注意同一时间内的连接数和同一时间内主机上的进程数是不相同的。若处理很快，只加载一个进程，也可以建立多个连接。 instances = 最大联机数 per_source = 每IP的联机数与超过联机数的中断时间 cps = 每服务联机数与超过联机数的中断时间 log_type = 以下三个和全局设置中的含义相同，应用于这个进程 log_on_success= log_on_failure= env = 系统额外的环境变量 看来每个服务都离不开进程与子进程啊。 port = 所监听的端口，如果是公共服务，应当与services中的相同 redirect = 当client对该服务有请求的时候，重定向到其它服务器 这个就相当于我说我有一个服务，但是别人用的时候，转交给其它的机器。 includedir = 在xinetd中还要包括的子配置 注意新包括的配置将直接被加到xinetd.conf当中，而不会作为该服务的子配置。 bind = 服务所绑定的IP地址，也就是当主机有多个IP的时候，可以通过哪个IP地址访问该服务 interface = 与bind的含义相同 only_from = 限定哪些网络可以连接。可以是IP/Mask,hostname,或域名 no_access = 禁止来自些网络的连接 access_times = 服务开放的时间段，格式HH:MM-HH:MM umask = 使用者的服务建立文件时使用的掩码 守护进程概述 在Linux下面没有什么持久运行的程序与一次运行的程序的区别。以前我们总是以为，开机启动的程序和作为守护进程运行的程序是不同的。其实它们的差别也并没有那么大。开机运行的程序如果不停止，那么就作为守护进程一直运行了。在Linux中，/etc/init.d里面是开机运行的程序，但是也可以用于启动守护进程与开机脚本。本质上，它们作为“服务”出现。反映的有start, stop, restart, status等语义即可。 开机创建虚拟网卡，其实同样是一种服务。这种服务在开机的时候运行，创建出网卡，在关机的时候停止服务。 USER=&quot;root&quot; TAP_NETWORK=&quot;192.168.0.1&quot; TAP_DEV_NUM=0 DESC=&quot;TAP config&quot; do_start() { if [ ! -x /usr/sbin/tunctl ]; then echo &quot;/usr/sbin/tunctl was NOT found&quot; exit 1 fi tunctl -t tap $TAP_DEV_NUM -u root ifconfig tap $TAP_DEV_NUM ${TAP_NETWORK} netmask 255.255.255.0 promisc ifconfig tap $TAP_DEV_NUM } do_stop() { ifconfig tap $TAP_DEV_NUM down } do_restart() { do_stop do_start } check_status() { ifconfig tap $TAP_DEV_NUM } case $1 in start) do_start ;; stop) do_stop;; restart) do_restart;; status) echo &quot;Status of $DESC:&quot; check_status exit &quot;$?&quot; ;; *) echo &quot;Usage: $0 {start | stop | restart | status}&quot; exit 1 esac 上面就是一个符合chkconfig规范的启动脚本。 实际中我们可能把创建网桥的工作交给开机脚本，而把配置虚拟接口的网络地址这样的任务交给network子程序。 然后使用 chkconfig --add config_tap chkconfig --level 345 config_tap on 让它启动。在Debian系的系统上，使用service命令完成这样的工作。 对于个人用户来说，登录的时候运行某一个程序才是恰当的。因此用户登入之后才需要相应的环境。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[正则表达式实践]]></title>
      <url>%2Fregex-intro%2F</url>
      <content type="text"><![CDATA[本部分内容摘抄自原来的linux笔记第三册，而原来的笔记实质是一本书的内容。书名忘了记了，反正是很详细的一本介绍正则表达式的书。在此对于作者的工作表示敬意以及歉意。 正则表达式的科班史 正则表达式发源于与计算机密切的两个领域，计算理论和形式语言。20世纪40年代两位神经生理学家Warren McCulloch和Walter Pitts研究出一种数学方式来描述神经网络的方法，它们把神经系统中的神经元描述成小而简单的自动控制单元。1956年数学家Stephen Cole Klenne在他们的研究的基础上发表了一篇名为《神经网络表示法》的论文，在其中，他们采取了一些称之为“正则集合”的数学符号来描述神经网络模型。 这个书上说的就自相矛盾了，无论怎样，神经元的研究也不能说是一开始就和计算机领域是密切相关的 之后UNIX的主要发明人Ken Thompson将这个符号系统引入了文本编辑器QED.正则表达式由此进入计算机的世界。之后Ken Thompson又将正则表达式引入了unix下的文本编辑器ed.ed最终演化为大家熟悉的grep.因为grep得名自ed中的正则表达式搜索命令g/re/p. 这个又说明了一个问题。不知道Ken Thompson对于神经网络是怎样了解的，还是说这个时候已经产生了编译原理的相关的理论了。但是可以确定的是，Ken Thompson肯定知识面非常地广。看编译原理或许也不会知道正则表达式是何时进入高级语言的。 正则表达式的一些感概 这篇是在原笔记中出现的，所以在注释当中又加了一些笔记，使得一些知识能够反映当前的认识的水平。 正则表达式应用中分为几个版本。各个版本对正则表达式的实现都不能说是尽善尽美。尤其是对于中文的支持并不是十分完善。而且关键是各个正则表达式中常含有不同的转义表示符，这使得在形式上它们并不相同，虽然对应于同一个正则表达式的理论。 所以在一个正则表达式工具当中： 正则表达式语法＝正则表达式理论＋工具实现的部分功能＋工具的转义符系统 原来通配符也是正则表达式的一种，只不过以前在windows下从来没有人说它与正则表达式的关联，所以当首次听说Perl的时候，觉得正则表达式是一个很神秘的东西。 实际上在linux的bash的学习当中，也没有人说通配符就代表了正则表达式。 从现在来看通配符作为所谓的正则表达式的一个子集。以前还一直以为通配符来自于工业的背景，所以通配符和正则表达式的关系是后来发展中才被发现的。这导致我有时以为所谓的通配符是微软的发现。这就叫“无知者无畏”。 正则表达式用于称作“模式匹配”的领域。正则表达式被应用的时候，可以提供三个方面的功能：判断，选择，替换。三个功能当然是逐层递进的。“判断”是指在一段文本当中能不能找到正则表达式匹配的模式，“选择”是说，如果有这样一个模式，将从符合模式的几个子串当中选择哪一个，“替换”是说，对于选定的文本以何种方式替代它。 凡解析一个正则表达式都应当遵守这样的规则。其中的一部分，比如最长匹配原则，就是应用于“选择”时的一个规则。 在正则表达式的模型当中，一个具体的原则指的是一系列共同的前提，和相同体系的抽象。之所以可以进行选择，前提是已经给出了一系列的候选元素可供使用。而进行判断的目的就是得到这些候选元素。 一个正则表达式的特性可完全由这三个方面来描述。判断是基础，替换则是正则表达式语义分析能力的极限。实际应用当中，三个用途成金字塔的形状。不只是因为更高级的应用是建立在低级的应用的基础上，也因为低级的层次确实有不小的用武之地，否则也只能形式正方体结构。 后者的一个典型例子就是计算机网络分层模型。 正则表达式的三个流派，主要不同之处在于元字符的使用规定，本质还是一样的。对PCRE,BRE与ERE流派同时掌握并不是什么困难的事情。大致来说，三者所加的内容有一页左右，还不及对于正则表达式工具的特殊说明。 字符组 正则表达式的特点是用变量描述字符串。 也就是说正则表达式可以用变量代表一个字符串。个人理解。 正则表达式使用的时候注意的是，对于大多数字符（普通字符），使用正则表达式匹配的结果和一般的模式匹配应当是相同的（比如经典的KMP匹配算法）。其次是普通字符具有两个含义，一个是它所代表的字符，一个是它所表示的元字符。在编译原理当中可以看到正则表达式中，单个字符匹配，写成的结果以黑体的形式表达出来，表示它相当于一个终结符。 计算机字符在显示给我们看的时候，如果有换行符，就被显示成平面结构，但是对于计算机而言并没有这个概念。我们可以想象计算机看来，字符串本身是ASCII或unicode的一串字符序列。正则表达式匹配的实际上是一个字符序列的某种子序列，不管这些字符是不是控制字符，是不是可见字符，这个完全对于正则表达式的功能没有影响。 因为正则表达式不会接受所匹配的字符串作为正则表达式匹配指令的一部分 字符组是一列字符的集合，正则表达式程序匹配这一列字符当中唯一的一个。正则表达式将其匹配结果表示成一个确定的字符。原则上一个字符组括在一个中括号当中，形如[abcde]的字符组匹配a, b, c, d, e当中的一个。当只有一个的时候退化成一个单一的形式a,它表示的就是匹配字符a. 字符组可以以范围的形式表示，如[\xAA-\xZZ]表示编码为AA的字符到编码为ZZ的字符。 因为正则表达式在一个编码集当中工作，而不是一个字符集。在工作之前，正则表达式工具要能准确识别出一个编码单位。这对于utf-8这类采用变长编码技术的编码方式来说具有十分重要的意义。 -表示连接符号，如果要匹配-这个字符，只能使用转义了。一般来说，对于-的规定是，出现在字符组当中，并且从左到右可被解释为两个字符的连接时有特殊意义，否则按正常字符处理。其实这个符合一个原则，就是正则表达式引擎尝试将其解释为有特殊含义的字符，如果失败就解释为普通字符。因此正则表达式[0-9a-z]是有意义的，因为两个减号都可以被解释成连接。 在编译原理当中出现的正则表达式比在技术当中严格多了，并且是不支持量词的。学习这个正则表达式，就要放下另一个正则表达式体系，虽然可以保留两者的关联。 字符组的第一个字母是^号时代表不匹配里面所列字符当中的任何一个。 尝试用集合的概念理解正则表达式时，字符组首先代表\(A=\{a,b,c,d,\cdots \}\).使用连接符号的时候，相当于添加了很多个字符到A当中：[abc0-2]={a,b,c}+{0,1,2}. 而使用^号的时候代表[\^abc0-2]=P -({a,b,c}+{0,1,2})。 为了更清楚地表达语义，定义\d,\w,\s分别表示数字0-9,单词与数字0-9a-zA-Z,以及空白字符[\t\n\r\v\f]（代表制表，回车，换行，垂直制表，换页） ASCII码值 二进制 十进制 十六进制 缩写 含义 0000 0000 0 0x00 NUL 空字符 0000 0001 1 0x01 SOH 标题开始 0000 0010 2 0x02 STX 本文开始 0000 0011 3 0x03 ETX 本文结束 0000 0100 4 0x04 EOT 0000 0101 5 0x05 ENQ 请求发出响应字符，以确认存在 0000 0110 6 0x06 ACK 确认回应 0000 0111 7 0x07 BEL 响铃，要求终端对用户予以提示 0000 1000 8 0x08 BS 退格，删除或叠打上一字符 0000 1001 9 0x09 HT 水平制表符（horizatonal tab） 0000 1010 10 0x0A LF 换行键，实际上是line feed,满行的意思 0000 1011 11 0x0B VT 垂直定位符号 0000 1100 12 0x0C FF 换页，form feed,满页 0000 1101 13 0x0D CR 回车，用于结束文本行 0000 1110 14 0x0E SO 取消变换，Shift Out 0000 1111 15 0x0F SI 启用变换，Shift In 0001 0000 16 0x10 DLE 跳出数据通讯 0001 0001 17 0x11 DC1 设备控制一 0001 0010 18 0x12 DC2 设备控制二 0001 0011 19 0x13 DC3 设备控制三 0001 0100 20 0x14 DC4 设备控制四 0001 0101 21 0x15 NAK 确认失败回应 0001 0110 22 0x16 SYN 同步，同步信号 0001 0111 23 0x17 ETB 区块传输结束 0001 1000 24 0x18 CAN 取消 0001 1001 25 0x19 EM 连接介质中断 0001 1010 26 0x1A SUB 替换 0001 1011 27 0x1B ESC 退出键，转义 0001 1100 28 0x1C FS 文件分区符 0001 1101 29 0x1D GS 组群分隔符 0001 1110 30 0x1E RS 记录分隔符 0001 1111 31 0x1F US 单元分隔符 0111 1111 127 0x7F DEL 删除 在dos系统当中控制符可能被显示为一些有意思的符号，比如SOH被显示为一个笑脸。 如何在键盘上映射控制字符 CTRL键的原意就是把键盘上的字符转成ASCII小64的控制字符。对于小写字母的情况，是比它的ASCII小32的控的字符，所以CTRL+I水平制表，CTRL+J换行。CTRL+M回车。键盘向计算机发出的也是ASCII码值。如果没有相对应的符号，实际是使用的新定义或者是新的控制序列。哑终端常使用控制序列。哑终端是相对于其它聪明的计算机来说，功能较为有限的计算机终端。其含义根据不同的场合而变化。 终端的概念很重要。可以从终端那里知道制表符的意思是移动到某个制表位的地方，然后进行显示。也就是说，显示器等若一个方格。所以在移动的时候就知道TAB键的工作原理了。它在移动的时候，可能的位置是0,4,8,12,…按下tab键的作用就是跳到最近的控制点上。 随着不使用纸张打印，这些字符的含义也有了变化，比如换页在屏幕终端就变成了清屏。由于单个的转义码开始不够用了，所以就有了转义序列。 分隔符和操作系统当中的记录式文件结构有不小的关系吧。介质结速EM的意思是磁带已满。ESC的最初的作用是避免其后的控制字符被控制设备解释。 替换的作用是下个可打印字符以二进制的形式被打印出来 CAN用于取消一个包的传输，NAK要求重传一个数据包。ACK表示包被正确接收。 在半双工通信的环境当中，ENQ从主站发出，表示要求从站发送下条报文，从站发送EOT表示自己完成了传输。 传输设备控制码的意义，可以使得设备之间不需要用到更多的控制线，可通过一条线路上传输ASCII实现传输控制。 DLE表示会话结束，释放线路资源。 编码为0的字符是一个特例，指的是纸带上那些没有穿孔的地方。而DEL的ASCII很特殊是因为它的ASCII全是1,这样一来，没有穿孔的地方就全部变成穿孔的地方了。因为在纸带上遇1表示穿孔，0表示不穿孔。 看来ASCII的解释可以从穿孔纸带，打印机，控制终端，现代终端多个角度。 有一个特别的字符组.号，表示匹配除了换行符\n之外的所有字符一次。 字符组在原则上允许交，并差操作并构成了正则表达式理论上用的比较多的运算。一般来说，并置就是直接连接。这一个功能是都支持的。 字符组总结：在一列集合中选择一个匹配，对字符组允许作否定，连接的操作，一些字符组可以提供范围功能。所以在正则表达式当中关于字符组的基本特性可以总结为以下的几个方面： 1. 如何选择唯一的匹配字符 2. 使用否定的方式选择唯一字符 3. 使用范围的方式选择字符 4. 有没有什么选择特定语义的字符的简记法 5. 建立在字符组上的交并差运算是否支持 运算之后还是一个正则表达式。所以对正则表达式的与或非也应当有所支持。不过这是正则表达式的理论的问题，本笔记并不能涉及到。 量词 量词用于细化对于字符或者字符组的规定，约束出现的次数。 对于正则表达式而言，每一个子表达式都称为一个模式。量词准确地说是用来表示所匹配的模式所出现的次数。表示的是这样的模式所匹配的文字匹配多少次。 也许用扩展比较合适。正则表达式返回的匹配结果是包含了次数的，也就是返回的是完整的字符串。 量词跟在它所限定的模式的后面，仅作用于前一个最小匹配模式。通用量词用{m,n}来描述。比如(pattern){m,n}表示模式pattern出现\(m\)次到\(n\)次之间的被匹配。 其实量讯号的使用有两个关键的地方，一个是如何标识它所修饰的单元，另一个是如何传入匹配的量词标识的次数。用符号表示一个是pattern,一个是range. 量词的范围是非负的数值，根据具体语言的不同，0可以省略。 一般来说正则表达式的书写是非常严谨的，不像C语言那样，参数之间可以后跟若干个空格。所以在量词之间也不要加入空格。 有几个常用的量词使用了特殊的元字符表示，表示限定的模式出现0到无穷多次，+表示所限定的模式至少要出现1次，?表示限定的模式至多可以出现1次。需要注意的是模式.在实现上效率还是比较低的，所以应当尽量避免使用。 在通配符体系当中，常有一些表示任意匹配的元字符，比如*,.,?其含义和正则表达式中的含义略微有些区别。 量词如果是一个范围，就可能有多个可以匹配的字符串。 正则表达式进行匹配的结果相当于在一个线性序列当中选择一个范围，这个范围就是所匹配的结果，有了一个这样的匹配，才会知道如何操作指定的子串。 正则表达式匹配的过程可以看成是逐个对应的问题。一个正则表达式提供了特定的信息，其信息的截止长度是到字符串的末尾。所以在匹配正则表达式re的时候，如果匹配从a开始，就从下面的字符串中逐个应用某个模式，如果在某一阶段不能匹配，就进行回溯，至到在不能回溯，而又没有将正则表达式匹配到最后的时候才返回匹配失败。 正则表达式的匹配也可以看成是一个树的匹配。每一个量词就决定了下面有多少个结点可以使用，比如a{3,5}建立的子树就有aaa,aaaa,aaaaa三颗。 量词的优先级问题。量词的优先级的标准是在有多个匹配的时候先匹配尽可能多的字符还是先匹配尽可能少的字符的问题。这个与正则表达式引擎的实现有问题，对于能否匹配不产生影响。忽略优先量词的意思是先匹配少的，匹配优先量词的意思是先匹配尽可能长的字符串。 说到这里正则表达式工作的过程完全就等价于一颗树了。能够到达树的终点说明可以匹配。但是到达树的终点可能有不同的路径，每条路径对应于一个可能的匹配。 实际应用中量词的优先顺序影响的不只是效率，更影响了最长匹配还是最短匹配的问题。如a{3,5}匹配aaaa,如果是匹配优先量词，就是aaaa,但是{m,n}形式的量词是忽略优先量词，所以匹配的结果是aaa(前面的三个a）。 多选，分组与捕获 多选的意思是在多个可以匹配的模式当中选择其中的一个，其用法是\((p1\vert p2)\). 如果中间没有分隔符，和普通匹配的效果一样。不过多选其实还有一个比较重要的副作用，就是创建模式所匹配字符串的一个拷贝。这可以通过编号引用用在后续的替换当中。分组也是用这的方法，意思是模式作为一个整体。后面所跟的量词都是作用于这样的一个整体。 捕获的目的是提取出符合模式的字符串。PCRE正则表达式当中用括号来表示开始一个捕获。之后可以通过对编号的引用使用它。编号的原则是，按左括号从左到右出现的次序决定相应模式编号的顺序。编号从1开始。如果使用了分组（括号）而不想分组被捕获，则使用语法(?:)来加以说明。 python支持\g&lt;num&gt;与\g&lt;num&gt;形式的引用。 考虑到一般脚本，也支持用$num的形式引用。 断言 断言的作用是要求所匹配模式前后必须匹配某些特征，但是其匹配不作为匹配返回结果的一部分。断言有很多类型，常见的断言有单词边界，行起始，行结束以及环视。 断言的最一般形式就是环视。另外在正则表达式当中，断言都是跟着所匹配的模式的。比如如果ptwo在正则表达式中作为pone的断言，那么一般来说，其含义是ptwo后的模式正好是pone,中间没有任何其它的成份，或者ptwo前的模式正好是pone,中间没有其它任何成份，换言之，断言是紧跟它所断言的模式的。不会说，在文本某个位置符合了某个断言，但是隔了很长的文本之后，所断言的模式才开始出现。在通常情况下这种分隔的情况也不常用。但是或许在自然语言处理当中很有价值呢。 单词边界顾名思义就是一个模式的两端是单词分隔符，如空格等等。可以作为单词边界的字符构成一个集合，这个集合用字符组\b来表示。 这样一来\b就不一定表示断言，其所匹配的字符也会作为结果的一部分。 单词边界在PCRE当中常见的是\b,\B,\w,\W分别表示其左边是单词(非单词)，右边是单词(非单词)。 这个说明PCRE的规定不太一致，因为\d表示的是一个匹配字符组，而\b却要表示一个断言。 当匹配的内容被视为一个字符串的时候，^被视为文本开始的位置，$被视为文本结束的位置。当匹配的内容被视为段落文本的时候，^被视为每行的开始位置，$被视为每行结束的位置。 不同的语言可能使用不同的符号表达这个语义。 环视的作用是加强对匹配文本模式所在位往置的限制。以所匹配文本的位置看，环视分为顺序环视和逆序环视，也就是匹配模式左端应当符合的模式，以及右端应当符合的模式。 原则上也可以通过捕获分组来实现环视的功能呀，不知道和以这种方式实现环视的功能有效率上的不同没有，还是说，环视在编译原理上和捕获分组一样？ PCRE的环视以下面四种形式实现（两种顺序乘是否）：肯定顺序环视(?=pattern),否定顺序环视(?!pattern)，肯定逆序环视(?&lt;=pattern)，否定逆序环视(?&lt;!pattern). 正则表达式的全局选项 这个是经验的问题，因为为了书写的方便而设立一定的匹配模式，比如忽略大小写的功能。 全局选项实际上也可以作为局部选项而出现，因为它们都是加在一个模式之上的。一般来说。模式主要有： 忽略大小写模式 在此模式下一个字符可以与它的大写或者小写形式替换，也就是说不再只是代表这个字符，而是相当于包括大写和小写形式的一个分组。 单行模式 在此模式下，字符串被认为是一体的，点号可以匹配\n. 多行模式 在此模式下，^和$分别匹配每一行的开始与结束 注释模式 在此模式下的正则表达式部分表示一个注释，里面的内容可以自由书写，在表达式较长或者有多行的时候可以提高正则表达式的可读性。 坦白来说，正则表达式本身确实没有什么可读性。 PCRE中在正则表达式内部设置某个模式的时候使用(?modifier)，要取消某个模式的时候使用(?-modifier)。其中i表示忽略大小写，s表示单行模式，m表示多行模式，x表示注释模式。可以多个模式进行嵌套。 注释模式下用#开始一个注释，注释直到行尾。 对于我们来说比较有意义的时一个字符组所表示的真正的含义，所以在忽略大小写模式下，并没有对于匹配字符串的整体造成太大的影响。所以单行模式和多行模式要特别注意。注意的是什么呢，注意的是^与$的含义。 正则表达式工具 sed sed命令替换的基本格式是&lt;address&gt;s/&lt;pattern&gt;/&lt;replacement&gt;/&lt;flags&gt; 比如s/suff/(&amp;ix)/g用于将suff替换成suffix sed正则表达式的中文问题 linux下unicode正则表达式的匹配情况取决于当前系统的语言环境特别是编码。在一般情况下，元字符这部分直接可以在命令中替换。标准用法是使用\xx转义。 vim中正则表达式 匹配一个中文字符可以使用[^\x00-\xffff]. sed匹配空行和空格组成的行 删除空行的模式是 /^$/d， 删除由空白字符组成的行的模式是/\s*$/d。 VIM当中的正则表达式 在VIM中使用替换命令的一些情况 没有经验真可拍，稍微有点特殊的情况就得自己猜。 换行符属于一行的行尾，而匹配模式也可以仅仅只有一个位置符号，没有特定字符。总之，正则表达式的结果不过是一个位置范围而已，有时起始位置和结束位置相同也没有什么关系。 比如： 将行尾的换行符替换成制表符：s/\n/\t/, 这说明在正则表达式中支持转义字符 在每行之前增加一个制表符： s/^/\t/. 正则表达式中对于控制字符的转义 比如%s/\n\([^\t[:alpha:]]\)/\1/g。 grep 在我的linux笔记中已经提到vi,sed,grep属于BRE流派。并且关于正则表达式的基本概念我们也都已经讲清楚了。在这里主要是如何用具体的工具实现正则表达式强大功能的问题。所以先介绍grep工具。 grep命令的功能就是在一个或者多个文件里搜索一个模式串并输出。和sed等工具相比，不必使用特殊命令（比如sed的s替换命令），因为grep的功能定位就是从文件中搜索模式(grep的名字由来就是g/re/p命令)因为更专业，所以用的时候更简单。而且unix工具的一个特点就是一个工具的功能得到准确的描述，所不同的只是实现的方法问题。 我们好好体会这一点的方式是，我们能够从定义推演出工具的设计思想来。从定义可以知道grep的功能有两个关键词，模式和文件。分别以pattern和file来代表。而向应用程序传递参数的时候又要有相应的选项，所以grep的命令语法是： grep options pattern filename(s) 加上s表示grep可以接受多个文件。 grep可以从标准输入流中搜过一个模式串。 (管道设计unix系统的特殊机制，现在我们知道管道可以看成具有特殊文件描述符的一个对象就行了。只要在程序设计中使用了这个特殊的文件描述符，就能通过管道方式传送数据) pattern是一个BRE正则表达式串。但是我们在启动grep程序之前，参数字符串还要经过shell变换处理一下。因而如果字符串比较特殊，还要经过一次shell的转义。一般要用引号括住。 示例用法： grep &quot;sales&quot; emp.lst &quot; 在emp.lst文件中搜索具有模式sales的行。输出到标准输出。 grep president emp.lst 同上，搜索的是模式president。 在grep后面的文件参数中有多个的时候，grep在输出结果每行开头会显示文件名和行号。 grep参数解析的过程我们可以看成首先试图从argv字符串中读出一个作为pattern，或者通过一个选项给出pattern，如果不能满足，就将参数解释为一个文件名。 grep的参数解析 grep的参数(理解正则表达式失配，grep程序匹配这句话的含义) -i 不区分字母大小写(ignore case) -v 显示不含指定模式的行(invert match,改变匹配模式) -n 显示行号和行内容（默认只显示行内容）（line number） -c 显示所匹配模式的行数（count） -l 只显示匹配的文件（files with matchesO）（-L的意思与之相反） -x 匹配整行的内容（即整行恰好被匹配）（line regexp） -f file 从文件中读取模式，每行作为一个模式，行之间是与的关系 -E 使用ERE模式匹配（-G是使用BRE模式，BRE是默认设置） -P 使用PERL模式匹配（并非是POSIX规范） -e pattern 将-e参数后的一个参数解释为正则表达式。（如果正则表达式以减号开头，能够避免该参数被解释成一个选项）。 -r 读取文件时在目录下递归查找。 在VIM当中可以使用转义符进行输入。而转义的规定很多都来自于C语言一系。关于转义，其中由引导符和定义符构成。一个完整的转义应当是有定义的那些转义。然而如果转义后的序列不被识别，有可能被当成正常的字符处理，也可能报错。 一些技巧 sed中如何替换空行[2013年 03月 17] 在sed当中正确使用相应的表达式就可以了。因为sed的匹配是以行为基础的。使用符号sed '/^$/d'可以将文件中的不含任何字符的行删除。 注意在sed当中正则表达式前面没有像vim那样的s字符。sed即使是替换文本，也不使用s开头。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[进程原理三：线程原理与编程、调度器]]></title>
      <url>%2F%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%B0%83%E5%BA%A6%E5%99%A8%2F</url>
      <content type="text"><![CDATA[线程的相关原理 线程的基本概念 这里所讲的线程都是用户所使用的线程，不说系统内核中存在的诸多线程。 一般来说，linux的进程已经是轻量的了，创建多个进程有时候比多个线程更容易进行协调。而使用线程库是在用户空间进行的，存在效率和复杂度的问题。 在linux下线程的实现是按照POSIX线程的规范，POSIX线程可以在内核的支持下实现，也可以在用记线程库下实现，对于linux来说，2.6版本以上的POSIX线程的相关接口最终被放到内核中实现。 在讲到进程是有提到clone函数，现在来看，这个函数相当于一个底层的接口，和POSIX提供的相关接口不在同样的层次上。因此我们只讲POSIX的线程接口。 为了防止主题分化。下面讲一般的线程的原理 线程分为用户级线程ULT和内核级线程KLT.用户级线程在操作系统看来是一个进程当中的一部分代码，和同一进程中的其它线程不可分辨。 实际中发现线程的调用很成问题啊，首先得到的两个线程PID一样的，然后貌似sleep的时间也不对。 这种混淆主要是线程比较晚出现，导致原来调度器使用的进程概念被换成线程会使系统对外的接口发生很大的变化，因而带来不便。 线程的核心我们定义为方便地共享数据，一切优点和缺点都是围绕着共享数据来进行的。 实现的一个线程只需要最基本的调度标识符，进程控制块，其它的资源都由主进程所提供。它们共享其中的资源。既然如此，也就能够通过对共享数据的读写实现线程同步，这要比进程的同步容易一些。 相应地，实现上难了，但对于开发者来说却在某种程度上容易了，所以线程还是对于程序员来说不着不小的意义。 线程的切换在操作系统看来也要比进程切换容易，因为不需要把所有的上下文都保存。 线程的一个积极意义吧，就是在多内核环境下的并行要容易一些。进程在多核环境下实现并行，最关键的如文件的共享，得改变文件缓存的机制。但是线程共享的数据结构相对来说比较高级，比如共享文件描述符，显然比共享一磁盘块本身要简单。 这里的难的容易的问题是从要设计一个操作系统的解度来说的，这个时候还没有一个现成的操作系统可以使用，但是对于学习者来讲，容易和困难缺乏意义，因为一个实现已经存在了。已经做到的事情，谁会说它很困难呢，至多可称得上复杂。 线程在一个复杂环境中特别有意义，因为程序中有的代码负责输入，有的负责输出，有的则是自行处理数据。如果让进程实现就不得不阻塞很久，所以这种场合恐怕是最适合多线程程序的。一个重要的方面就是网络应用。 个人觉得操作系统原理应该说到网络环境下线程有重要的应用。 要创建线程与创建进程表面上的不同是，创建进程可以在没有相关数据的情况下进行，但是创建线程却要在一个已有的环境下创建。这导致一个错误的认识，就是线程看起来是如此轻量，以致于很难想象还需要什么额外的工作。实际编程实现的时候，线程可以作为一个函数来执行。也就是说，一个线程负责运行特定的函数。在多线程程序中设计流程是非常困难的。Alan Cox 曾评论线程为“如何立刻让自己自讨苦吃。” linux下线程的实现 在linux下线程库的接口是一样的，在不同版本被实现为用户级线程或者内核级线程。其中的主要道理是，对于应用程序来说，区分用户级线程或者内核级线程没有多大的意义。在linux下查询线程是如何实现的，可使用命令getconf GNU_LIBRPTHREAD_VERSION查看使用的线程库的版本，如果是NPTL表示使用的是内核级的线程库。在linux当中原来的线程库被称为LinuxThread,它是用户级的线程库。 在linux之下，共享的资源有各种类型，比如环境变量的共享也是单独的一个部分，新创建的进程也可以共享其FS,但是按照线程的定义，代码段，数据区都应该是共享的。操作系统在实现的时候，要将PCB中的相应指针指向内存中的同一个页面。 讲进程的时候提到clone()函数，就当它不存在吧。也别管它是什么内核级线程的创建函数，实际中已经有一个高级库了，用不着再从底层做起。 很重要的一点，使用NPTL线程库创建的线程，PID和主线程的一样，但是TID和主进程的不同。因此它们仍然共享一个task_struct结构，所以多线程程序和单线程程序的不同之处，仅在于多线程程序当中的task_struct结构里的线程队列链里有多个成员。创建新的线程的时候，只是相当于在task_struct 当中注册了新的线程栈。 由此引起的问题是，调度时的单位是不是一个PID,因为使用NPTL内核级的线程库的时候，仍然是同一PID.所以在2.6之前的调度实体都是进程。 NPTL的设计是仍然被视为同一进程，且仍然使用clone()系统调用。不过其中也运用了内核当中的特殊支持。NPTL是\(1*1\)的线程库，使用一个pthread_create()就在内核当中创建了一个调度实体。一般来说，存在着\(m*n\)的调度，这种情况下用户线程数大于内核调度实体的数目。 这里涉及一大堆的概念。其一，我们称linux的进程为轻量进程，是因为不同的PID共享了相同的空间。而这部分仍是传统的FORK调用。进程与线程的详细情况，见下面的调度器笔记。 linux下的线程使用的就是符合POSIX的线程库，要在程序当中使用线程，使用头文件pthead.h. 使用线程的基本要求是不要使用进程的退出函数，这样会导致整个物理内存上的相关数据结构都被删除。因而带来不安全。 线程库在linux下也可以看成是一个封装，其中含有相应的，类似fork这样分配PID的代码。 一个系统中线程的数量参考：linuxThread线程库中线程数是在编译时就指定的，而NPTL支持动态的线程数，在一个IA-32系统上可达两百万个。关于线程的速度，则是如果使用NPTL,启动100000个进程只需2秒，而不使用NPTL需要15min. POSIX线程库中创建线程的方法，以C语言为例 创建一个线程的函数原型是： int pthread_create(pthread_t *thread, pthread_attr_t *attr, void *(*start_routine)(void *), void *arg); 终止当前线程的函数原型是： int pthread_exit(void *retval); 看起来 pthread_create 函数使用了一大堆的指针，其实却很简单，返回值是否为零代表成功或者失败。第一个参数相当于线程控制块，第二个是线程的属性，第三个是线程的入口函数，第四个是需要传递给该函数的参数。 UNIX函数的惯例是调用失败时返回-1,比如对于前面到的fork函数。0代表对函数来说有特殊含义的一个量，-1才代表一个调用错误，函数内部的代码无法完成所称的工作。 函数要写成 void *function(void *arg) 的形式，以便正确地进行转换。下面是一个例子。可以和fork()相对比。 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;pthread.h&gt; #include &lt;errno.h&gt; #include &lt;string.h&gt; int main(){ int ret; pthread_t mythread; ret = pthread_create(&amp;mythread, NULL, myThread, NULL); if (ret != 0){ printf(&quot;Cannot create thread (%s)\n&quot;, strerror(errno)); exit(-1); } return 0; } void *myThread(void *arg){ printf(&quot;Thread is running.\n&quot;); pthread_exit(arg); } 以上代码的重要之处如下： 返回值0代表线程正常创建了； 当调用系统提供的函数出现错误的时候，建议使用strerror,这样一来错误会发到stderr设备。而且还会提供人人都能理解的错误信息。 线程函数中退出不能使用exit()，而是用 pthread_exit() 并且参数中的数返回的是函数的退出代码。关键是这个退出号不能是一个局部变量，因为退出函数时候变量会被销毁导致错误号无法正常传出去。使用arg作为返回时的位置，是一个避免在主线程中重新定义一个变量的技巧。 编译时，首先需要定义宏 _REENTRANT ,在有的系统上（不常见）还要定义 _POSIX_C_SOURCE 宏。如果系统默入不是用NPTL实现的，编译选项为： cc -D _REENTRANT -I/usr/include/nptl thread1.c -o thread1 -L/usr/lib/nptl -lpthread 如果默认已经是用NPTL实现的，就使用 cc -D_REENTRANT thread1.c -o thread1 -lpthread 因此我们在编程上也知道了，函数使用exit()退出，return退出，还是代码执行完毕后自动退出，是有区别的。 POSIX线程的基本函数 父线程使用下面的函数等待子线程的终止，原型如下： int pthread_join(pthread_t thread, void ** status); 第一个参数标明要等待的子线程.线程的资源在父线程调用 pthread_join之后释放,相当于在进程当中子进程的资源在父进程调用wait()之后释放. pthread_self() 函数返回当前线程的标识. 内核线程 在内核引导和启动的时候，诸多的内核功能模块也会被使用，它们的地址空间是整个实地址空间，因而互相能够访问到，syslogd就是其中的一个。在ps命令下我们看到它是一个不同PID的进程结构。所以内核线程大致是以轻量进程的方式实现的。（猜测而已） linux的调度器 分类的必要性 在操作系统当中，将调度器的时候都是在讲完进程之后，讲线程之前，但是带线程的调度器的进程调度器的不同之处太多了。 进程调度的时候遵循调度的一般原理，一般来说，关键在于掌握调度算法，知道怎样给一个一个的调度实体分配CPU.但是调度器的工作实际上不只这些，它还要区分哪些是调度实体，把调度实体的相关代码和数据加载到适合于执行的位置。 原理中那样讲的不好之处是，如果是用户级线程，就认为内核没有变化，如果是内核级线程，就把进程的区域交给其它线程共享。 所以认为传统进程是一个单线程的“进程”，这种认识是肤浅的。下面将会指出实际情况。 带线程的进程模型 当一个程序不带有额外的线程的时候，生成的进程的结构和传统进程一样，包括文本段，数据段。但是一个程序如果带有线程的话，就变得不同了。这种情况下，会多出一个线程栈。这样以来就会使得对外的表现仍然是，在加载程序的时候，整个代码都会被加载以形成一个调度的实体。这样的进程和传统进程是一样的。而这时的调度器，仍然以整个进程作为调度单位。如果进程中有多余的线程，是通过KLT实现的（这里我们不能称线程为内核线程，因为这个词已经有过了定义）。那么KLT的库负责的任务就是在程序有创建线程的需求的时候利用task_struct结构当中对线程的支持，分配一个线程栈，并告诉调度器这个线程栈是一个独立的实体。可以直接在其中执行代码的。 在这一过程当中，编译器并不会感知到线程栈的存在，它仍然正常地生成有关函数的代码。当编译和连接按照流程走一遍之后，就生成了可执行文件。当程序加载执行的时候，运行到创建线程的时候，如果是KLT,就会实际上把传给它的函数的入口地址一直到结尾的部分分配到线程栈当中。告诉给调度器的也就是函数的入口地址和相关参数。因此我们认为，在KLT之下，一个线程就是一个单独运行的函数，这个函数的参数也是由线程库给出的，做完这些，函数代码就可以独立执行了，因此对于调度器来说，KLT线程是非常短小精悍的一段代码。 我们这里的程序的含义是由源代码生成的一个文件。 接下来讲ULT.虽然ULT不与调度器没有什么关系，不过对于程序执行还是有着影响，那就意味着会产生一个问题，如何让一个进程，一会儿执行这个线程上的代码，一会儿执行那个线程上的代码。 对于LinuxThread这样的库来说，实现多线程的方式估计很多人都要泪流满面了。实际对于LinuxThread最基本的是clone()出来的多个进程。 clone()函数有多个功能，其中一个最核心的功能，最准确的描述是产生一个新的进程，这个进程的地址空间始终和父进程相同。 LinuxThread库的功能主要集中在使用信号量在不同进程之间进行同步，并借此达到实现线程的目的。 以下就是澄清了的事实： clone()函数有多个功能，借助它可以实现用户级的线程库（LinuxThread），也可以实现内核级的线程库（NPTL）。如果是使用NPTL,就要做参数上的调整。这就是为什么在NPTL的介绍当中，单独把“使用clone()”作为一句话的原因，其言外之意，原来的clone()是用来实现用户级线程库的。 有句话叫“在系统看来，用户级线程相当于一个进程，内核级线程相当于多个进程”。这句话是很有误导性的。准确的意思是，1.在调度程序看来，用户级线程之间共享一个时间片。分配时间的时候是一起的。但是在调度程序看来，无论是用户级线程，还是内核级线程，它们都被调度程序作为排队的不同成员。2.在操作系统加上线程库看来，用户级线程才相当于一个单位。 解释其一，在Linux程序设计当中有这样的一句话，第417页上说，“…许多项目都在研究如何才能改善Linux对线程的支持，…,其中大部分工作都集中在如何将用户级的线程映射到内核级的线程。”。后面的词“映射”非比寻常。因此原来的线程库当中，是通过线程库把一个线程映射到不同的进程当中，线程库所做的工作就是如何调整不同进程之间的同步关系，使得在一个传统的操作系统下实现线程。因此在操作系统看来，这样的每一个线程都是一个进程，所以它们可以分别被调度。至于时间片的分配，只要在创建进程的时候，使得两个task_struct共享一个时间值，这样以来就可以在不共享PID的同时实现时间片的共享，因此是倒回到模拟实现去了。这样外在表现就好像是一个进程一样。 解释其二，我们不难理解用户级线程慢的原因了，这倒不是说自己分配数据区很慢，而是说，实际上需要创建多个“病态的”进程结构。还可以知道，用户级线程容纳的线程数是非常有限的，因为系统容纳的进程数往往不是很多。在这样的系统当中实现多线程，潜能就不是很大，因为一个用户级线程被映射到一个操作系统进程。而内核级线程库的优势就在于在不改变可容纳进程数的前提下，仅通过调整可调度单位数，就能够创建出大量的线程来，并且不占用操作系统的PID资源。 线程库和操作系统的关系需要一番思考。如果不对操作系统进行修改，操作系统的调度单位仍是一个一个的进程，线程库能做的，也只能是把程序分成多个进程，这样才能实现并行。当然，在支持KLT的系统中也可以设计出更复杂的用户级线程库。m:n的线程模型就是一个例子。 因此说，不用修改操作系统，单靠线程库就可以实现用户线程也是不恰当的，如果非要那么做，线程的效率要低于普通的进程，所以运行效率上： 内核线程\(&lt;\)单个进程\(&lt;\)内核线程之和\(&lt;\)轻量进程上实现的用户线程\(&lt;\)多个进程\(&lt;\)单个进程加上同步形成的线程。但是从实现复杂度上，进程比轻量进程易，轻量进程比线程易，KLT比ULT易。 摘自《Linux操作系统实验教程》：linux内核支持的用户线程都有一个用来维护它的task_struct 结构，该用户线程实质上是一个蛤备单独 task_struct结构的子进程。 调度的本质 以前总不能避免把一个 task_struct 看成一个调度单位，所以就认为一个结构就代表一个进程，所以ULT就是在一个进程当中，一个KLT就是占好几个 task_struct .恰恰和事实相反。 轻量进程和内核线程应该算是实现线程的不同思路。前者的地位，相当于在一个传统的操作系统当中，不适合共享数据，内核从而进行机制上的改造，使之提高创建进程的速度，如果操作系统不这么做，用户级线程也不可能在linux上出现的那么早。 因此我对内核线程的态度大为改善，以前以为它是通过创建大量的进程实现的。而这个认识被证明是完全错误的。对不起，内核线程，KLT,亲爱的NPLT. 调度的本质应当是一段代码及其数据在处理器和内存之间的移动，因此调度的对象完全不必是一个进程。这点原理书上说的是正确的。但是一个操作系统必须有确定的调度对象，这个也是无法改变的。如果我们以调度的最本质的特点来看操作系统，就知道调度的思想来自于甚至还未有操作系统的时代。只是在操作系统发展的初期，只能以进程为完整单位进行调度，所以在操作系统这时的调度反而是最不灵活的。 我们重新定义调度的对象，不再以进程作为根据。所以我们在线程调度的设计当中，更进一步了解了调度的实质。细化了调度的粒度。 所以在linux中通过调整nice值改变进程优先级的意义对于内核级线程作用就很小了，而且也不是人们所期望的改变。所以可能有必要设计一个工具函数，能够细化到对进程内部的线程调整优先级。 Linux的进程与作业管理 操作系统原理的时候从来没有讲过作业是怎么一回事，只讲到了进程及其相关的调度，现在我们就把要学的内容完整起来。 Linux是一个多任务的操作系统。在计算机看来，系统上同时运行着多个进程。正在执行的一个或者多个相关的进程称为一个作业。使用作业控制，用户便可以同时运行多个作业，并在需要时于不同作业之间切换。 Linux是一个多用户多任务的操作系统。多用户指多个用户可以同一时间使用计算机系统，多任务指的是可以同时执行几个任务。由操作系统负责管理多个用户的请求与多个任务。 最关键的地方还是这些用户请求与任务直接由操作系统所识别。 任务这个词比进程还要更基本一些，不只是传统的进程，也包括了用户作业，操作系统任务，邮件与打印作业等。它们出现的形式可以有多种多样的。这每一个单位称为一个任务。不过在Linux下面，所有运行的东西都可以被称为一个进程(调度的单位现在是线程了)。用户任务以及守护进程都可以称为进程。 对进程比较正式的定义是，在自身的虚拟地址空间运行的一个单独的程序。Linux下面进程有三种类型，交互进程，批处理进程以及守护进程。三种进程各有各的作用，使用的场合也有所不同。 一个正在执行的进程称为一个作业，然而一个作业可以包括一个或者多个命令，特别是在我们使用管道与重定向命令的时候。比如在Shell输入一串带有管道命令的命令，就执行了一个作业，然而有多个进程。 作业控制指的是控制作业中正在运行的进程的行为，如控制作业的挂起或者暂停。许多Shell都有作业控制的特性，使用户可以在多个独立作业之间切换。 一般而言，只有与作业控制相关联的进程才能被称为作业，不受作业控制的进程通常不划入作业的范围。大多数情况下，用户一个Shell只运行一个作业。 进程一般有手动启动与调度启动两种方法。手动启动又有前台启动与后台启动之分。如果使用了管道，管道里面的各个进程是同时启动的。控制进程的启动，可以使用at,batch或者cron工具，而管理当前Shell里面的作业，可以使用信号，bg与fg.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[进程原理二：进程控制块与进程详细介绍]]></title>
      <url>%2F%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86%E4%BA%8C%2F</url>
      <content type="text"><![CDATA[进程控制块 进程控制块有几种组织方式以使操作系统能够访问到。进程控制块之间的联系常有索引方式存储和链接方式存储。 linux继承了unix的传统，使用 task_struct 结构作为进程控制块。操作系统的内核空间有一个task数组，其中每个元素指向一个任务结构，又称为task向量。NR_TASKS 是task数组长度，因此决定着系经能够容纳的进程数。 linux操作系统对进程区分普通进程与实时进程，调度程序对此作出区分。 在linux内核栈中保存有 task_struct 结构的关键内容。 linux时间片的安排：进程创建子进程之后时间片的分配原则是：1.不会因创建子进程而受到奖励，也就是创建的子进程和父进程平分剩下的时间片。2.不会因创建短期子进程而受到惩罚，也就是子进程未被重新分配过时间片而结束，则剩下的时间片会归还给父进程。也就是系统认为子进程第一次分配的时间片来自于父进程。 休眠次数多的进程可能是交互式进程，但也可能是IO密集型进程。如果操作系统不能区分这一点，将会导致真正的终端交互程序响应缓慢。因此系统不是简单根椐频繁进入休眠状态来动态调整优先级，还有判断是否交互式应用的算法，task_struct 结构提供了相应的记录，以供调度程序选择其中的一些作为调度参考。 进程相关的函数 进程的基本属性是其PID.它的作用主要是可以给进程一个标识，可以快速地访问到相应的进程当中的信息。进程运行时可通过getpid()函数访问自己的PID 而进程是由其它进程创建的（.）。所以通过getppid()函数访问父进程的PID 根据POSIX的相关规范，进程之间是以组的方式联结起来。这是为了方便地通过信号管理一组用户的进程等目的。进程的组ID从父进程继承，组ID可通过setpgrp()修改，通过getpgrp()或者getpgid()获取。 进程有相关的权限，其权限来自于进程相关的用户。进程所有者是其最基本的权限来源，可以通过getuid()获取。除此之外，进程还有相关的有效用户ID和有效组ID.分别通过geteuid()与getegid()函数获取。操作系统尝试依次从相关的ID获取权限，有一个成功就返回具有权限，最后一个失败才会返回失败。 当然还有组ID,通过getgid()获取。 次序是uid,gid,euid,egid.先用户后组，先自身后额外。 对于线程来说，TGID标识了线程所在进程组的ID.单线程进程等于其PID,多线程时等于基本线程（父进程）的PID. 系统启动时的进程变化 启动过程当中，进程形成树状的结构。内核态下执行0号进程。它创建内核态1号进程。后者负责内核的部分初始化与系统配置，并创建若干个内核线程负责设备，缓存等等。之后内核态的1号进程通过execve()运行可执行程序init,形成用户态的1号进程。它按照/etc/inittab当中的配置完成系统的启动工作。在这一过程中通常创建了若干的getty进程，每个具有不同的GRP-ID,这样就使GRP-ID有了会话期进程的含义。当检测到来自相应终端的信号的时候，getty自动执行login程序登录。由login认证之后就进入到相关的shell. 注意getty在执行shell时通过execve()实现的，所以是getty进程被shell进程取代。当shell退出时，init会检查相应的终端，然后决定是否重启getty. 后面会知道execve()相当于替换掉当前进程的代码段，所以进程号没有改变。 进程的基本管理 从当前进程创建一个子进程，有三个选项创建新进程： pid_t fork(void); pid_t vfork(void); int clone(int (*fn)(void *arg), void *stack, int flags, void *arg); 三个函数最终都调用同一个内核函数 do_fork() ： do_fork(unsigned long clone_flag, unsigned long usp, struct pt_regs); 其中 clone_flag 可以是 CLONE_VM,CLONE_FS,CLONE_FILES , CLONE_SIGHAND,CLONE_PID 以及 CLONE_VFORK 等。分别表示子进程与父进程共享（是共享而不是复制）相应的资源：进程空间，文件系统，打开的文件，子进程终结时向父进程发送SIGCHLD,信号处理函数，进程标识符，父进程在子进程空间被释放时唤醒。 如果有 CLONE_VFORK ,父进程一直被挂起，直到子进程空间被释放。 在linux下创建进程成功默认是让子进程先运行。 fork()函数将父进程所有资源通过数据结构复制给子进程。两个进程的地址空间完全不再干涉。需要通过进程间通信机制通信。fork()之后相当于子进程从当前位置开始执行，开始判断。父子进程不再关联。该调用向父进程返回子进程PID,向子进程返回0错误时向父进程返回-1. 其中的错误可能为:EAGAIN,ENOMEM.第一个是进程数达到上限，第二个是内存不足。vfork()的特点是子进程共享父进程的地址空间。运行之后父进程会被阻塞，直到子进程执行exec()或exit().使用vfork时进程堆栈区是不同的。vfork方法当然产生的是新的进程，只不过在创建的时候使用的是父进程的地址空间。但是在执行exec之后，程序就使用了新的地址。其实不妨这样看：vfork程序相当于新创建了一个存在于内核当中的引用，指向父进程的数据，此时子进程对于数据的任何修改都会被父进程看到。但是使用了exec之后，子进程的数据区就指向新的位置，父进程数据区的相应引用计数值就减去1.并且解除掉父进程的阻塞状态。 理解的关键在于数据区像共享文件那样存在共享计数。 vfork的作用有两点，第一是在vfork之后，exec之前，父进程被锁住，子进程对父进程可以安全地修改。其次，如果创建子进程的目的就是exec一个新程序并运行，复制页表完全是多余的，因此vfork后比fork后调用exec更合适。 无论单独的fork还是vfork,执行之后父进程都被阻塞，在子进程exec之后，或者子进程退出后才能使父进程恢复运行的能力。 clone()用于创建线程，先不讲。 创建子进程的重要目的是执行其它的程序，在linux当中通过exec()调用实现。进程调用exec()之后原有的代码段被替换成参数指定的代码段，原有的数据段和堆栈段也被废除了。只有进程号还是相同的。exec()类有若干个函数，功能大致相同。在unistd.h当中有execl,execlp,execle,execv,execve,execvp.后缀带p表示使用PATH变量查找可执行文件，，v是表示通过char*数组传参。（最后一个是NULL）。e是表示使用指定的环境变量。 不知道是不是所有的数据都被替换了呢？那么除了进程控制块之外所有的数据都要分配，因此开销也是不小的。 几个exec函数最终都变成调用 do_exec() 。其功能是加载新程序并跳转执行。 在前面讲了如何使父进程与子进程同时运行。但是有时候父进程还想知道子进程的状态，这时的解决办法是使用wait()或者waitpid()函数。 #include &lt;sys/types.h&gt; #include &lt;sys/wait.h&gt; pid_t wait(int *status); pid_t waitpid(pid_t pid, int *status, int options); 编程方法：当不需要得知子进程退出的原因的时候，wait(NULL)即可，否则自己分配一个整型变量的空间。这个整型变量的不同比特位代表不同的含义，使用系统提供的对应的宏可以检查退出状态。 也许会有这样的疑问，子进程退出不是在系统中就不存在了么，为什么还会存有退出原因呢。这是因为虽然操作系统原理上是这么说，但是子进程PCB的释放是在wait函数中进行的，wait的原理是，等待子进程的结束。一旦子进程处于僵死状态，函数将其彻底销毁后向父进程返回。此时才真正从系统中释放子进程的PID. wait()的功能是阻塞父进程直到有一个子进程退出，函数返回其PID.进程退出的原因放在status变量当中。没有子进程时返回-1. waitpid的功能更强大，可以等待指定PID的子进程退出。只不过，取正的时候代表等待指定pid的子进程，-1代表等待任何一个子进程退出，0代表等待同一进程组中的任何子进程，小于-1代表等待进程组为abs(pid)中任何一个子进程。后两个主要是为了方便会话期程序管理其子进程。options可以取WNOHANG,WUNTRACED.其中第一个表示不要阻塞父进程，第二个与作业控制有关。选项有NOHANG,且返回PID为0代表没有发现可供收集的子进程。调用中出错返回-1. 可以理解为，是进程PID的原因返回-1,是wait中未能回收子进程返回0,其余情况返回内容函数回收的那个子进程的PID. waitpid仍然只能等待其子进程pid. 相对wait,waitpid的优点是可以等待特定子进程退出，可以非阻塞运行，可以支持作业控制。 进程退出的方法。使进程自动退出的函数是exit()， _exit() 。 #include &lt;stdlib.h&gt; void exit(int status); #include &lt;unistd.h&gt; void _exit(int status); 两个函数的关系相当于一个是C库函数，一个是系统函数。由于C语言和unix系列的密切关系，不能不讲C库函数的同时讲C库函数所使用的更底层函数。 两个函数的status用于指示退出状态。最终两个函数都是调用系统的 do_exit() 函数。在退出的进程中， do_exit() 还会使用各种退出函数，与文件系统有关的，与信号量有关的，与文件描述符有关的，与切换进程有关的，等等。 在linux的标准函数库当中，有一套高级IO使用了主存当中的缓冲区，C语言当中的printf(),fopen(),fread(),fwrite()都是其中的函数。此时使用 _exit() 会导致缓冲区当中的数据丢失，因此需要用exit()函数，它能够对缓冲区里的内容同步。 printf(&quot;output begin\n&quot;); printf(&quot;content in buffer&quot;); _exit(0); 上面的代码运行时，第二行的printf语句结果并没有显示出来。 进程的有关编程 在linux下自己管理创建的进程，一般使用的函数是fork,vfork,exec,wait,waitpid, _exit() 这一类函数。但是在C语言的环境当中，还可以使用更加高级的函数，正如在文件读写当中使用带buffer的读写函数一样。这一类函数比如说有system(),exit().其中前者的功能是将命令传给shell执行，由shell返回 畅想计算机学习 在进程当中，有关操作系统原理的那部分知识显然是给系统管理员用的。系统管理直接用这些知识来调整进程的优先级，调试程序等等，但是对于应用程序开发者来说，却是没有什么意义，其中的机制才是它们最关心的，比如创建进程用什么函数。所以实际上学习操作系统就分成了两个方面，第一个是关于操作系统的各种算法的，这对于要了解操作系统原理从而要管理整个系统的人来说非常有价值。 但是对编程来讲却没有价值。在进程当中，程序员只需要分清楚以下的问题： 1.进程中的这些区块有没有被复制|； 2.有没有哪个进程被阻塞； 3.数据区是怎样被替换，又是怎样被销毁的； 4.进程从哪个地方开始执行。 所以对于程序员来说，vfork仅是相当于一个性能优化的函数，和它们头脑中布署的逻辑层次并没有关系。 最高的层次就是把代码和逻辑完全结合起来，暂且称之为是“运算原理”这样的一个部分吧。它的作用是从计算系统的观点来思考问题，编译原理只是其中的一个入门课。 进程的管理 进程的基本管理 使用ps命令查看相应的进程是在使用操作系统命令的层次上 nice值对于进程的响应速度有重要的影响，前面已经知道了nice值的作用，控制着进程的优先级。值越大，优先程度越低。 nice和renice命令分别用于调整进程的优先级。 相应地也有nice的系统调用用于调整进程优先级，实际上unix系统下的函数调用和命令调用对应关系是很紧密的。 linux的调度算法中进程的时间片从5ms到800ms不等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[进程原理一：进程管理与Linux下面的进程]]></title>
      <url>%2F%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86%E4%B8%80%2F</url>
      <content type="text"><![CDATA[把进程管理放在操作系统中较后的位置，不是没有原因的。想一想，如果没有那么多的设备又何必设计存储管理，如果没有存储设备中内容的复杂性，又何来文件系统管理。如果没有文件系统提供那么多的资源，又何必设备多个程序，让它们按照可被调度的对象运行? 由此可见。在底层，在操作系统设计的时候，按照一个一个的模块来设计的。有了前面的准备，进程的运行才有一个良好的环境，才方便我们设计调度。 进程管理中的进程被提供了一个抽象的体例。在进程中，也许应该首先使用虚拟地址空间，区分内核态与用户态，再联系处理器的权限管理的机制。这样对于为何进程有必要存在给了一个比较好的解释。 在存储管理的层次上，可以按照所谓单一连续分配，固定分配，动态分配，分页或者分段的方法。但是这只是一个方面。这是进程的静态的结构，这时进程被看成是存储区域。但是还可以更高级地，把进程看成是运行着的文件。 多用户情况下，进程的权限可以看成是由文件的权限演变而来，而且它访问的设备，都是这样的一种抽象。所以如果把进程管理放在最后的话，我们会更能看出进程技术的复杂性。在学习路线上，先设备后进程的方法也许是很适合的。 在进程与编译技术上，刚开始的编译，只是按照实际地址空间的编译，自从有了进程与抽象之后，便可以使用可重定位的代码了。这样编译的技术也就可以更进一步。有了这些，我们才可能进一步讲解在操作系统之下的虚拟机，调试，安全优化这些内容。 进程与子进程的同步 使用_exit()系统调用或者exit()库函数终止进程，或者等待进程代码执行完毕的时候退出，或者使用return()语句。通常并不直接使用系统调用。因为与_exit() 相比，exit()还执行了更多的清除工作。 void _exit(int status); void exit(int status); 当一个进程创建一个子进程的时候，大多数情况下，紧跟其后的是调用exec语句。exec的用法这里不讲。 等待进程死亡的系统调用是wait()。它的效果是在父进程执行它的地方被阻塞，直到有一个子进程死亡，wait得到它的状态返回，父进程因此继续执行。wait的不好之处是在这之前父进程可能创建了多个子进程，wait返回时，父进程并不知道是哪个子进程结束了。 子进程先死亡的时候，子进程的进程表不会立即被释放。除非是init进程，有定时清理defunct进程的功能。 wait(int *exitstatus); 为了改进这一状态，可以选择使用waipid()函数代替。 pid_t waitpid(pid_t pid, int *stat_loc, int options); 第二个参数保存退出状态。options参数取WNOHANG,WUNTRACED,WCONTINUED之一或者其中的组合。有NOHANG的时候立即返回，不会阻塞。pid是所等待的进程。但是有些有特殊的意义。比如-1代表进程一直阻塞；0代表等待进程组中任何一个进程的死亡；\(pid&gt;0\)时表示所等待的进程；\(pid&lt;0\)时绝对值表示等待PGID等于pid绝对值的进程（组领导进程）死亡。 进程组是Berkeley小组提出的一个概念，利用它可以控制一组具有共同特性的进程。组中每个进程有进程组标识号PGID,其值等于进程组领导者的PID 不同shell中的特性也不一样，比如在Bourne Shell里，其中运行的命令与shell的PGID相同。C Shell, Korn Shell, Bash Shell中，处于同一管道的命令组成一个独立的进程组。具体来说。支持作业控制的Shell才会像后者一样。 一个用户可以有多个进程组，只有一个进程组在前台，它连接到会话的控制终端。在按下CTRL-C的时候，我们实际上是向前台进程组里的所有进程发送SIGINT信号。因此在一堆管道命令当中，我们也可以使用一个CTRL-C. 当后台进程组试图从终端读取数据的时候，终端驱动程序会发现这种行为，发送一个信号，挂起这个进程组。 使用环境变量 环境变量是进程地址空间的一部分。在创建子进程时父进程的环境变量会传递给子进程。保存在一个外部变量里。使用如下的语句声明它： extern char **environ; 这个指针数组的每一分量是name=value的形式。 POSIX规范定义了如下的两个函数分别用于求取和设置环境变量的值： char *getenv(const char *name); int setenv(const char*envname, const char * envval, int overwrite); 其中overwrite的含义是：非零值代表如果已有环境变量，其值被覆盖。 和C语言非零值代表true的约定是一样的。 程序设计中的进程控制 进程控制块是进程存在的根据，在进程控制块中有许多的内容可以使用。内容在上个笔记中已经有介绍了。 创建进程使用fork()函数，返回 pid_t 类型。向父进程返回子进程PID,向子进程返回0.父进程从从那时创建fork()调用的下一行开始。 使用 pid_t 类型的一个好处是，我们不知道 pid_t 的真正类型是什么，因而也就无需考虑这个类型的加法减法有什么意义了，反而落得清静。 进程号相关的方法getpid()与getppid()分别获取当前进程ID和其父进程ID. 进程用户属性getuid(),getgid(),geteuid()与getegid()。 设计父进程和子进程的机制可以稍微从POSIX的规定中看到一些，比如说，因为多用户的环境下所有的进程如果彼此独立的话，对于系统程序设计是一个挑战。 进程控制的确是一个技术思路的问题，而非一个科学上的问题，不仅如此，很多在操作系统原理上学的也是几个技术实现，并不能称上是计算机科学。 进程创建的机制 一个进程的创建明显有三个阶段，需要调用三个重要的系统调用或系统函数。它们分别是fork,exec,wait.当我们在shell里执行一个命令${CMD}的时候，shell会另外创建一个shell进程，新创建的进程映象载入${CMD}映象，${CMD}进程开始运行。SHELL父进程等待${CMD}的执行结束，并获取${CMD}的退出状态值。 对于进程之间的关系来说，以下的属性比较重要： 进程的真实UID和GID 进程的有效UID和GID 进程启动时所在的目录 所有由父进程打开的文件描述符 环境变量 其中有效UID与有效GID和SUID和SGID有关。对于有些设置了SUID或SGID属性的程序有用，用于一个程序以它的UID和GID启动，而不是当前用户。 操作系统原理讲的很简略的，没有讲过进程之间父子关系这些东西。但是我们可以自己把它理解成人为加上去的属性，不影响进程的调度。 当一个进程死亡的时候，会立即转入僵尸状态，直到它的父进程从进程表中获取它的状态值。然后内核从进程表中删除这个记录。处于僵尸状态的进程是一个无害的子进程，但是我们不能终止它。 倘若在子进程之前，父进程已经死亡，此时这个子进程成为一个孤儿，内核将指派init成为所有孤儿进程的父进程。而特殊之处是中有所有子进程都死亡之后，init才会死亡。 由此我们补充进程的几个阶段当中，一旦执行完毕，并不会直接就从PCB中消失，而是还要经过一系列的处理过程。 僵尸进程和孤儿进程的不同定义。 关于进程有很多的主题，在操作系统当中学习的是进程管理，并发控制，进程调度，在这里学习的是进程控制，虽然也是进程管理的一部分但是没有包含在操作系统原理当中。 对于进程的理解 学习的进程实际上并不是最深层的原理。进程本身的机制还是我们不能了解的。所以就当操作系统为我们提供了进程这样的一个机制。在其中我们进行进程的创建和管理等等工作。 计算机程序运行状态分为内核态和用户态。我们把进程想象成什么比较好呢？在原来的环境下，正如天地始于混沌一样，代码是不分彼此的。后来为了独立出来问题才有了这样的分别。计算机之所以成为计算机而不是计算器，本质在于其理论上的通用性。在原来的操作系统理论当中，引入多道程序设计的目的是提高运行的效率。这个方面的因素不能说没有吧。但相对来说，计算机的功能整合其实发生了很重要的作用。 我们这样反思在计算机初期的发展原理。当时具有中央机与外围机，中央机的作用只是进行所谓的运算。这样一来就有了“单道”的程序环境。随着输入速度的提高，在实践中开始暴露出许许多多的问题。计算机当时没有什么理论性，或者说其理论还是作为业余人员的兴趣在被谈论，并未指导用于计算机的工业制造。工业上真正的变化是因为计算机速度的提高，使输入和输出跟不上计算性能，所以当时的首要问题和现在相反，是计算能力不能满足科学的需求，但这是因为人们不能在输入和输出上跟上计算机。 在这种情况下首要的任务自然是对外围机进行整合，由更加高速的设备和控制逻辑代替某些人工操作。其中蕴含着可以实现通用计算的机会。因此计算机才开始进入整合的时期，才进行输入，运算，存储和输出的整合。在这种情况下当然一个紧密相关的系统的产生就是不可避免的了。既然如此，就不可能不让众多的功能聚在一起。在这种融合下，首先发生的变化就是和运算器，数理逻辑结合在一起。两个发现方向，其一，实用科学的计算需求，其二，人们对于可计算性的思考，之间的结合，是促使计算机原理化的第一动力。 其次才是多道程序设计的产生。这个现象并不是遇然的，前面的理论已经为它的产生做好了准备。多道程序发生的第一因素是中央机和外围机对应不同功能需要使用不同的程序逻辑实现。在实际发展当中，我们还看到60年代的机器，越来越显得中央机太快，因此在我们的输入进行提高的同时，针对计算机空闲的现象，还试图在同一中央机当中添加多道程序，以提高运算器的使用效率。所以多道程序设计的原理在这个时候已经需要成熟。 所以多道程序设计的必要性至少在计算机实体与计算性理论相结合的时候，多道程序就已经实现了。甚至在90年代，我们从WINDOWS作为DOS上的一层外壳，也能看出多道程序设计在萌发阶段的表现。典型的就是操作系统还只是一个软件中间件，程序员和使用者能够清楚地看到硬件结构。 因此我们把进程想象成一群有交往关系的个体。这些个体要生活在同样的一个环境当中，我们需要合理安排，否则因为它们非常笨，会导致什么事情都做不了。它们做不了事情，我们的生命也就失去了意义了。 所以原始的方法是我们在一个较弱的界面上实现一个较强的功能，但是我们拥有了相当程度的知识之后，就要想办法使整个系统有很高的整合度，特别是需要很简单。 以我们的观点来看，计算机是我们认识世界的窗口，其中的有些道理和人类世界是相通的。 进程最基本的一面 我们先讲的是进程机制。所以整个事情有显得没有什么必然的联系。实际上却是还有一些思想在其中的。 首先要看到进程的结构为什么是这样的。底部的细节已经是是为我们屏蔽了的，比如分页机制与分段机制，还有虚拟内存。所以现在我们以编程人员探寻进程的实质为理由学习操作系统。然后我们就可以进行抽象了。 那么程序执行的实质过程是什么呢？编译器封装了很多的细节。所幸可以根据汇编语言来进行推测。其结果就是所谓的数据段，文本段，BSS段。 学习汇编语言的恰当时机个的认为是在学习了一门不太高级的高级语言如C之后，因为C语言的实用性最高，和汇编语言比较容易联系起来，技术性比较强，反观JAVA等就比较复杂，还得学习编译原理之后才会有一个比较明确的理解。所以学习一个面向过程，甚至直接学习汇编，皆是面向机器编程所需，这样以来，可以很好了解操作系统提供特性，执行的过程。更因为学习嵌入式实际上也算其中有操作系统，而其中的代码就和机器比较紧密，所以我们知道操作系统原理应该在裸机上学，在一个屏蔽了机器细节的机器上学习。这个和编译器生成的中间代码是处在同一个层次。 所以整个计算机课程学习的过程就是中间代码可以算是一个分水岭。在其上生长了丰富的思想，在其下生长着各种性能的器件。 数据结构在一门编程语言和操作系统之间。 所以操作系统的进程一开始涉及的是进程段的分配。而内存我们很容易就可以想象成一个线性的地址序列，所以也没有什么困难的地方，即使我们将内存想象成一个一个的空格组成的空间也可以。 接下来就涉及进程空间的分配。内存只有一条，但是我们在编程的时候由于都要转化成操作符和操作数的络式，所以地址就成了一个重要的问题。操作系统的解决手段相当于说，自己当成一个中介，代表每个进程进行分配。这就像一群人有东西要分，但是没有人出来做协调，于是就有一个比较聪明的人站出来给大家出谋划策，当然不是无条件的，它本身也要占据一些资源，不过结果在家都能满意。这说明这人确实有才能，不过目的却并不怎么光明磊落，就像微软在DOS上加了一系列WINDOWS的库让大家用一样。 操作系统利用的是硬件提供的机制，形成的是进程空间这样的一个抽象。背后利用的当然是分段或者分页。我们就当操作系统在执行程序代码的时候自动对程序的地址进行变换，就可以了。或者干脆说，被体系拦住了。 在硬件上我们知道有MMU等机制。 进程因此被操作系统所管理。操作系统使用的数据结构称为进程控制块PCB. 操作系统完成对进程的抽象 但是进程不需要知道它的存在，完成自己的事情就可以了，所以如果把计算机系统看成一个人的生命周期，开关机和保存状态都和生命的存在有关，但是一个进程的灭亡，只是相当于一个细胞的死亡。重要的器官还都存在着。 对于一个人而言，就知道，会玩游戏只是会一个程序，它终究是会死亡的，我们使用计算机的意义不在于那个程序，而在于我们使用那些功能，留下了那些重要的数据。或者说，我们的思想有什么收获。 所以现在我们开始讨论一个有限生命，这就不得不拿出生理学的淡定态度来。 在操作系统看来进程有四个部分，进程控制块，进程程序块，进程内核栈，进程数据块。 一个一个解释这些内容显得好琐碎，这样说吧，一个是进程控制块为操作系统所用，相当于进程的身份信息。其余的内容都相当于进程告诉操作系统哪些在执行时用到，哪些是先注册好的资源。这样系统知道在执行切换的时候如何安排，因为就相当于一次旅游，操作系统要把人送到目的地，人总要说，自己有哪些行李是要带到那个地方使用的。 在unix看来，后三个具有RWX类的权限，各自为R-X RW-RW-。这是因为在unix看来，写不只是向硬盘中去写，内存，甚至寄存器也有这样的概念。所以unix操作系统的权限设定是从头到尾的，任何可能的位置都赋予了相应的权限。 缺少其中任何之一就不称为进程，如果只有前三项就称为线程，如果用户空间共享，则称为用户线程。如果没有用户空间，就称为内核线程。 所以线程的定义是非常不严谨的。 在实现的时候，由于进程程序块里的内容不会被改变，所以系统也可以透明地让其它的进程使用，只是开始的位置可能不同而已，没有必要记录下所有的内容。 与操作系统原理的对应是，程序段代表其中的内容会被取指令所操作。数据段则是进程地应程序加工处理的原始数据或者中间结果。进程控制块是系统统一管理调度进程的一个数据结构。 所以说系统与进程的地位就有些混乱了。有时候操作系统好像过分控制了进程。对此我只能说这种不公正对特进程的现象只能是操作系统自身的原因，一个好的操作系统，应当能够让用户保证对自己来说有意义的程序得到最好最恰当的调度。 先不考虑读写磁盘，只考虑程序执行过程中涉及运算的那个部分。]]></content>
    </entry>

    
  
  
</search>
